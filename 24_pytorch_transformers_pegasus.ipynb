{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e1dbe-f484-4304-8001-f10b5e0321c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef39394-5986-44bb-a6d6-84957a492ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, gc, sys, time, collections, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict, Optional, Union, Any, List, Tuple\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.utils.data as D\n",
    "from torch.utils.data.dataset import Dataset, IterableDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertModel\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertModel\n",
    "from transformers import Trainer\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from transformers import TrainingArguments\n",
    "from transformers.trainer_utils import EvalLoopOutput\n",
    "from transformers.trainer import logging\n",
    "from transformers.file_utils import is_torch_tpu_available, is_sagemaker_mp_enabled\n",
    "from transformers.trainer_pt_utils import find_batch_size, nested_concat, nested_numpify, nested_truncate, nested_detach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c54d1-55c1-4701-9fde-692cf4450c84",
   "metadata": {},
   "source": [
    "### Folders and Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c75e83-4760-4511-bf31-a144abfc01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/home/commonlit/data/')\n",
    "assert DATA_PATH.exists()\n",
    "MODELS_PATH = Path('/home/commonlit/models/')\n",
    "if not MODELS_PATH.exists():\n",
    "    os.mkdir(MODELS_PATH)\n",
    "assert MODELS_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b25934-3c16-4cb0-ab3b-6d95223432f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commonlit_lm\t\t       test.csv        train_duo.csv\n",
      "commonlitreadabilityprize.zip  train-orig.csv\n",
      "sample_submission.csv\t       train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12796f2-c49a-4d32-9f38-0ecdec520539",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH/'train.csv')\n",
    "test_df = pd.read_csv(DATA_PATH/'test.csv')\n",
    "sample_df = pd.read_csv(DATA_PATH/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179a075d-6fa8-4cf4-b703-db4f09c9649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patty concluded to move very slowly, thinking ...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patty concluded to move very slowly, thinking ...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>At last the game was concluded, as Roger Farri...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>2c26db523</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>So what is a solid? Solids are usually hard be...</td>\n",
       "      <td>0.189476</td>\n",
       "      <td>0.535648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>cd19e2350</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>The second state of matter we will discuss is ...</td>\n",
       "      <td>0.255209</td>\n",
       "      <td>0.483866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>15e2e9e7a</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Solids are shapes that you can actually touch....</td>\n",
       "      <td>-0.215279</td>\n",
       "      <td>0.514128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>5b990ba77</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Animals are made of many cells. They eat thing...</td>\n",
       "      <td>0.300779</td>\n",
       "      <td>0.512379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2848 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          url_legal  \\\n",
       "0     c12129c31                                                NaN   \n",
       "1     c12129c31                                                NaN   \n",
       "2     c12129c31                                                NaN   \n",
       "3     c12129c31                                                NaN   \n",
       "4     c12129c31                                                NaN   \n",
       "...         ...                                                ...   \n",
       "2843  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n",
       "2844  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2845  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2846  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n",
       "2847  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n",
       "\n",
       "           license                                            excerpt  \\\n",
       "0              NaN  When the young people returned to the ballroom...   \n",
       "1              NaN  When the young people returned to the ballroom...   \n",
       "2              NaN  Patty concluded to move very slowly, thinking ...   \n",
       "3              NaN  Patty concluded to move very slowly, thinking ...   \n",
       "4              NaN  At last the game was concluded, as Roger Farri...   \n",
       "...            ...                                                ...   \n",
       "2843  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n",
       "2844  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n",
       "2845  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n",
       "2846  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n",
       "2847  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n",
       "\n",
       "        target  standard_error  \n",
       "0    -0.340259        0.464009  \n",
       "1    -0.340259        0.464009  \n",
       "2    -0.340259        0.464009  \n",
       "3    -0.340259        0.464009  \n",
       "4    -0.340259        0.464009  \n",
       "...        ...             ...  \n",
       "2843  1.711390        0.646900  \n",
       "2844  0.189476        0.535648  \n",
       "2845  0.255209        0.483866  \n",
       "2846 -0.215279        0.514128  \n",
       "2847  0.300779        0.512379  \n",
       "\n",
       "[2848 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efffba57-a6ab-4210-8391-5f2fccb3fd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>21ea485fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A little within the wood there was a fair cast...</td>\n",
       "      <td>-1.302688</td>\n",
       "      <td>0.450399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>a04741371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The king dwelt for many months in Nottingham, ...</td>\n",
       "      <td>-0.714009</td>\n",
       "      <td>0.506864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>5cb5ab998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When they drew near Nottingham, all the people...</td>\n",
       "      <td>-1.541347</td>\n",
       "      <td>0.478166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>622f6215e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About this time there was living in Nottingham...</td>\n",
       "      <td>-2.054284</td>\n",
       "      <td>0.538084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id url_legal license  \\\n",
       "231  21ea485fb       NaN     NaN   \n",
       "233  a04741371       NaN     NaN   \n",
       "234  5cb5ab998       NaN     NaN   \n",
       "235  622f6215e       NaN     NaN   \n",
       "\n",
       "                                               excerpt    target  \\\n",
       "231  A little within the wood there was a fair cast... -1.302688   \n",
       "233  The king dwelt for many months in Nottingham, ... -0.714009   \n",
       "234  When they drew near Nottingham, all the people... -1.541347   \n",
       "235  About this time there was living in Nottingham... -2.054284   \n",
       "\n",
       "     standard_error  \n",
       "231        0.450399  \n",
       "233        0.506864  \n",
       "234        0.478166  \n",
       "235        0.538084  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['excerpt'].str.contains('Robin Hood')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13ba276-1696-40d2-b05f-8f5f31e79c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A little within the wood there was a fair castle, with a double moat, and surrounded by stout walls. Here dwelt that noble knight, Sir Richard Lee, to whom Robin Hood had lent the four hundred pounds to redeem his land.\\nHe saw the little company of outlaws fighting their way along, so he hastened to call them to come and take shelter in his castle.\\n\"Welcome art thou, Robin Hood! Welcome!\" he cried, as he led them in. \"Much I thank thee for thy comfort and courtesy and great kindness to me in the forest. There is no man in the world I love so much as thee. For all the proud Sheriff of Nottingham, here thou shalt be safe!—Shut the gates, and draw the bridge, and let no man come in!\" he shouted to his retainers. \"Arm you well; make ready; guard the walls! One thing, Robin, I promise thee: here shalt thou stay for twelve days as my guest, to sup, and eat, and dine.\"\\nSwiftly and readily tables were laid and cloths spread, and Robin Hood and his merry men sat down to a good meal.',\n",
       "       'A little within the wood there was an imposing castle, with a double dig, and surrounded by stout walls. Here dwelt that phantastic knight, Sir William Jones, to whom Trevor Blanford had lent the twenty hundred dollars to redeem his land.\\nHe saw the little company of small criminals fighting their way along, so he hastened to call them to come and take shelter in his castle.\\n\"Welcome art thou, Trevor Blanford! Welcome!\" he cried, as he led them in. \"Much I thank thee for thy comfort and sympathy and great kindness to me in the forest. There is no man in the world I love so much as thee. For all the proud Sheriff of Kendall, here thou shalt be safe!—Shut the gates, and draw the bridge, and let no man come in!\" he shouted to his retainers. \"Arm you well; prepare yourselves; guard the fortress! One thing, Trevor, I promise thee: here shalt thou stay for fifteen days as my guest, to sup, and eat, and dine.\"\\nSwiftly and readily tables were laid and cloths spread, and Trevor Blanford and his jolly men sat down to a good meal.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['id'] == '21ea485fb']['excerpt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f5b0bd8-527e-4b89-9082-f0780c9ae28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1303   -3.351956\n",
       "1304   -3.351956\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['id'] == '0bf29d257']['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5cd025a-a37c-4aaf-a192-ac278264a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9b62eb3-cedd-4629-a726-173588d6a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b48a945-271e-4c18-afac-e0a4c9194e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_df['target'],bins=100,kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a192f15-ce61-4b3a-8a1c-38a63b26d05d",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "127e2c8b-20ad-40b0-8c2f-6f1a595e5e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG():\n",
    "    model_name = 'google/pegasus-xsum'\n",
    "    batch_size = 18\n",
    "    max_len = 256\n",
    "    save_dir = f'trained/{model_name}'\n",
    "    num_workers = 4\n",
    "    epochs = 30\n",
    "    pretrained_transformers_model = f'/home/commonlit/models/{model_name}_lm/best_lm'\n",
    "    num_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96543b31-4546-4bfc-a3fa-b4793194c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CONFIG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab8b20-6c63-4d51-b6fe-39ff141ad03e",
   "metadata": {},
   "source": [
    "### Prepare Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42787f35-115b-4258-925f-6575f3063924",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbbc9a60-4c04-447a-9ddc-e5125688f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = int(np.floor(np.log2(len(train_df))) + 1)\n",
    "train_df.loc[:, 'bins'] = pd.cut(train_df['target'], bins=num_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0769b07-e9ea-42b7-95a6-5becf82dd824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bins</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.411708</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.969369</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.526589</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.106393</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.653016</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.201392</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.748612</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.309794</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.130016</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.560802</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.978923</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.399764</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target      \n",
       "          mean count\n",
       "bins                \n",
       "0    -3.411708    44\n",
       "1    -2.969369    79\n",
       "2    -2.526589   172\n",
       "3    -2.106393   269\n",
       "4    -1.653016   367\n",
       "5    -1.201392   420\n",
       "6    -0.748612   484\n",
       "7    -0.309794   411\n",
       "8     0.130016   312\n",
       "9     0.560802   184\n",
       "10    0.978923    83\n",
       "11    1.399764    23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['target', 'bins']].groupby(['bins']).agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f7c55d-a9c2-4e76-a7ef-42acd56f7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=cfg.num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f70453a0-e80b-4953-95cb-fd06547c6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (t_, v_) in enumerate(kf.split(X=train_df, y=train_df.bins.values)):\n",
    "    train_df.loc[v_, 'kfold'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b311fb49-dfdc-43e7-a89a-182b731c879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['kfold'] = train_df['kfold'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de386c06-bb90-4034-b290-cd03cb61cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop('bins', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89e6e9bd-9ae3-4871-a47d-37ed129634fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patty concluded to move very slowly, thinking ...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patty concluded to move very slowly, thinking ...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>At last the game was concluded, as Roger Farri...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.646900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>2c26db523</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>So what is a solid? Solids are usually hard be...</td>\n",
       "      <td>0.189476</td>\n",
       "      <td>0.535648</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>cd19e2350</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>The second state of matter we will discuss is ...</td>\n",
       "      <td>0.255209</td>\n",
       "      <td>0.483866</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>15e2e9e7a</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Solids are shapes that you can actually touch....</td>\n",
       "      <td>-0.215279</td>\n",
       "      <td>0.514128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>5b990ba77</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Animals are made of many cells. They eat thing...</td>\n",
       "      <td>0.300779</td>\n",
       "      <td>0.512379</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2848 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          url_legal  \\\n",
       "0     c12129c31                                                NaN   \n",
       "1     c12129c31                                                NaN   \n",
       "2     c12129c31                                                NaN   \n",
       "3     c12129c31                                                NaN   \n",
       "4     c12129c31                                                NaN   \n",
       "...         ...                                                ...   \n",
       "2843  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n",
       "2844  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2845  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2846  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n",
       "2847  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n",
       "\n",
       "           license                                            excerpt  \\\n",
       "0              NaN  When the young people returned to the ballroom...   \n",
       "1              NaN  When the young people returned to the ballroom...   \n",
       "2              NaN  Patty concluded to move very slowly, thinking ...   \n",
       "3              NaN  Patty concluded to move very slowly, thinking ...   \n",
       "4              NaN  At last the game was concluded, as Roger Farri...   \n",
       "...            ...                                                ...   \n",
       "2843  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n",
       "2844  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n",
       "2845  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n",
       "2846  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n",
       "2847  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n",
       "\n",
       "        target  standard_error  kfold  \n",
       "0    -0.340259        0.464009      0  \n",
       "1    -0.340259        0.464009      0  \n",
       "2    -0.340259        0.464009      0  \n",
       "3    -0.340259        0.464009      0  \n",
       "4    -0.340259        0.464009      0  \n",
       "...        ...             ...    ...  \n",
       "2843  1.711390        0.646900      4  \n",
       "2844  0.189476        0.535648      4  \n",
       "2845  0.255209        0.483866      4  \n",
       "2846 -0.215279        0.514128      4  \n",
       "2847  0.300779        0.512379      4  \n",
       "\n",
       "[2848 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "103dd81f-fd3d-4b5a-b7ca-1f8d36cabfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.340259\n",
       "1      -0.340259\n",
       "2      -0.340259\n",
       "3      -0.340259\n",
       "4      -0.340259\n",
       "          ...   \n",
       "1195   -3.229761\n",
       "1206   -3.213909\n",
       "1209   -3.338291\n",
       "1213   -3.070718\n",
       "1220   -2.853298\n",
       "Name: target, Length: 570, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['kfold'] == 0]['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc39df9c-9c72-45f8-ac6c-50b87ea3ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_df[train_df['kfold'] == 0]['target'],bins=100,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa178d20-5a74-4533-8643-ea7f8d4b15d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_df[train_df['kfold'] == 1]['target'],bins=100,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf3e0ed2-719d-483c-976f-173b19c8070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 7, 2, 4, 6, 8, 10, 1, 0, 3, 5, 11]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_list = list(range(num_bins))\n",
    "random.shuffle(bin_list)\n",
    "bin_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370fd3a4-9d7b-42be-b31c-2f6c6c15a3a0",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d57cfc8c-551e-4f67-91f8-5aec7002d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_score(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "def rmse_score_2(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18e1c48e-da7e-4a1e-b91e-c9c5a262a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10)\n",
    "b = np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "883bd02c-7ab8-4fdc-bb6e-42e6c98a0935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33474555587961674, 0.33474555587961674)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_score(a, b), rmse_score_2(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d96bf65-b75e-468d-83e2-1d60792baebd",
   "metadata": {},
   "source": [
    "### Prepare train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e601b365-a123-4a1d-bd31-3e6aeeee2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split(fold = [1]):\n",
    "    valid_df = train_df[train_df['kfold'].isin(fold)]\n",
    "    valid_text = valid_df['excerpt'].values\n",
    "    valid_target = valid_df['target'].values\n",
    "    training_df = train_df[~train_df['kfold'].isin(fold)]\n",
    "    train_text = training_df['excerpt'].values\n",
    "    train_target = training_df['target'].values\n",
    "    return train_text, train_target, valid_text, valid_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8575c418-6c76-409c-9ce2-f907a92764d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2278, 570)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text, train_target, valid_text, valid_target = create_split([0])\n",
    "len(train_text), len(valid_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8c638-0a6f-4b0b-baab-9422908e0343",
   "metadata": {},
   "source": [
    "### Prepare Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34addbcd-c989-475e-9c61-72b2e3ddf8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trained/google/pegasus-xsum/tokenizer_config.json',\n",
       " 'trained/google/pegasus-xsum/special_tokens_map.json',\n",
       " 'trained/google/pegasus-xsum/spiece.model',\n",
       " 'trained/google/pegasus-xsum/added_tokens.json',\n",
       " 'trained/google/pegasus-xsum/tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "# Save the tokenizer so that you can download the files and move it to a Kaggle dataset.\n",
    "tokenizer.save_pretrained(cfg.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10cea73f-5dd2-42f2-bc8d-454190f84655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When the young people returned to the ballroom, it presented a decidedly changed appearance. Instead of an interior scene, it was a winter landscape. The floor was covered with snow-white canvas, not laid on smoothly, but rumpled over bumps and hillocks, like a real snow field. The numerous palms and evergreens that had decorated the room, were powdered with flour and strewn with tufts of cotton, like snow. Also diamond dust had been lightly sprinkled on them, and glittering crystal icicles hung from the branches. At each end of the room, on the wall, hung a beautiful bear-skin rug. These rugs were for prizes, one for the girls and one for the boys. And this was the game. The girls were gathered at one end of the room and the boys at the other, and one end was called the North Pole, and the other the South Pole. Each player was given a small flag which they were to plant on reaching the Pole. This would have been an easy matter, but each traveller was obliged to wear snowshoes.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict = tokenizer(train_df['excerpt'].values[0],\n",
    "                                return_tensors='pt',\n",
    "                                max_length=cfg.max_len,\n",
    "                                padding='max_length',\n",
    "                                truncation=True)\n",
    "decoded = tokenizer.decode(encoded_dict[\"input_ids\"].squeeze())\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eab4041e-0b2d-41d6-94a3-6e3646e3427f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d093a87-1edd-4e0b-8545-5e97a91a7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(t):\n",
    "    return t.flatten().long()\n",
    "\n",
    "class CommonLitDataset(nn.Module):\n",
    "    def __init__(self, text, target, tokenizer, max_len=128):\n",
    "        self.excerpt = text\n",
    "        self.target = target\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],\n",
    "                                return_tensors='pt',\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length',\n",
    "                                truncation=True)\n",
    "        return InputFeatures(input_ids=convert_to_list(encode['input_ids']),\n",
    "                      attention_mask=convert_to_list(encode['attention_mask']),\n",
    "                      label=torch.tensor(self.target[idx]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a038b280-5d95-4a08-b3c6-da445770f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_valid_ds(tokenizer, train_text, train_target, valid_text, valid_target):\n",
    "    train_ds = CommonLitDataset(train_text, train_target, tokenizer, cfg.max_len)\n",
    "    valid_ds = CommonLitDataset(valid_text, valid_target, tokenizer, cfg.max_len)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13ae453b-84a5-4a13-a2fc-00e5562a95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode.keys(), target.shape, encode['input_ids'].shape, encode['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddf1a2cf-19d7-42c1-ac39-83a8bb2655bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode['input_ids'][0].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed362b-cd1d-4d1a-b343-6ecddef7e324",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c02b525-14b7-45ee-bf22-24d1cea9c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "863d53eb-7874-4bef-8b6a-d542749f7dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/pegasus-xsum were not used when initializing PegasusForCausalLM: ['model.encoder.layers.15.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.15.self_attn.k_proj.weight', 'model.encoder.layers.12.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.13.self_attn.out_proj.weight', 'model.encoder.embed_tokens.weight', 'model.encoder.layers.13.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.14.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.13.self_attn.q_proj.bias', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.13.fc1.bias', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layer_norm.weight', 'model.encoder.layers.14.fc1.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.15.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.13.self_attn.k_proj.weight', 'model.encoder.layers.14.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.14.final_layer_norm.weight', 'model.encoder.layers.12.final_layer_norm.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.15.fc1.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.14.fc2.bias', 'model.encoder.layers.12.fc1.bias', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.14.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.12.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.12.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.15.self_attn.v_proj.weight', 'model.encoder.layers.15.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.14.self_attn_layer_norm.bias', 'model.encoder.layers.14.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.12.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.13.self_attn.out_proj.bias', 'model.encoder.layers.14.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.12.self_attn_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.13.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.14.self_attn.v_proj.bias', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.12.self_attn.k_proj.bias', 'model.encoder.layers.15.fc2.bias', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layer_norm.bias', 'model.encoder.layers.12.self_attn.out_proj.bias', 'model.encoder.layers.13.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.14.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.12.fc2.weight', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.13.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.13.final_layer_norm.bias', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.14.self_attn.k_proj.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.13.fc2.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.15.fc1.bias', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.13.fc1.weight', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.12.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.12.fc2.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.12.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.15.self_attn.q_proj.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.13.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.13.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.shared.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.14.self_attn.q_proj.bias', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.15.self_attn.out_proj.bias', 'model.encoder.layers.12.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.15.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.13.self_attn.v_proj.weight', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.15.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.14.fc2.weight', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.15.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.14.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.15.fc2.weight', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.12.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.15.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.13.fc2.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.14.fc1.bias', 'model.encoder.layers.12.fc1.weight', 'final_logits_bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.15.self_attn.out_proj.weight', 'model.encoder.layers.2.fc2.bias']\n",
      "- This IS expected if you are initializing PegasusForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PegasusForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PegasusForCausalLM were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['lm_head.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# You can use a Transformer model of your choice.\n",
    "# transformer_model = DistilBertModel.from_pretrained(cfg.pretrained_transformers_model)\n",
    "transformer_model = AutoModelForCausalLM.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1f92770-7aa6-4ff0-b656-33f6b4d00bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer_out = transformer_model(input_ids=encode['input_ids'].squeeze(), attention_mask=encode['attention_mask'].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2551c8b-5ac7-4af0-bb2f-854c7fc45559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(transformer_out)['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "814e739b-f7a1-405c-b13c-31e6b93dcdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mean(transformer_out.last_hidden_state, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecf50196-0a69-4db8-bc17-b967f89911f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_layer = nn.Linear(768, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "132b7585-1f6e-4482-9b92-9a7260618888",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = AutoConfig.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "403ef922-6ede-4fc1-83a1-fe12b85a517b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PegasusConfig {\n",
       "  \"_name_or_path\": \"./\",\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"relu\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": true,\n",
       "  \"architectures\": [\n",
       "    \"PegasusForConditionalGeneration\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classif_dropout\": 0.0,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 4096,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 16,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"do_blenderbot_90_layernorm\": false,\n",
       "  \"dropout\": 0.1,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 4096,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 16,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"extra_pos_embeddings\": 0,\n",
       "  \"force_bos_token_to_be_generated\": false,\n",
       "  \"forced_eos_token_id\": 1,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"length_penalty\": 0.6,\n",
       "  \"max_length\": 64,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"pegasus\",\n",
       "  \"normalize_before\": true,\n",
       "  \"normalize_embedding\": false,\n",
       "  \"num_beams\": 8,\n",
       "  \"num_hidden_layers\": 16,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"scale_embedding\": true,\n",
       "  \"static_position_embeddings\": true,\n",
       "  \"transformers_version\": \"4.6.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 96103\n",
       "}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f2dbb7c-e9b8-47af-a124-32c5a5448ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5021054-9f67-404b-9a03-a34db81e49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel\n",
    "\n",
    "class CommonLitModel(PreTrainedModel):\n",
    "    def __init__(self):\n",
    "        super(PreTrainedModel, self).__init__()\n",
    "        self.transformer_model = AutoModelForCausalLM.from_pretrained(cfg.model_name)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.config = AutoConfig.from_pretrained(cfg.model_name)\n",
    "        self.hidden_size = 1024\n",
    "        self.layer_norm = nn.LayerNorm(self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, 1)\n",
    "        self._init_weights(self.layer_norm)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        if isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        transformer_out = self.transformer_model(input_ids=input_ids.squeeze(), attention_mask=attention_mask.squeeze(), output_hidden_states=True)\n",
    "        x = transformer_out['hidden_states'][-1]\n",
    "        x = torch.mean(x, axis=1)\n",
    "#         x = transformer_out.pooler_output\n",
    "#         x = transformer_out.last_hidden_state[:, 0, :] # N, C, X\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "    def floating_point_ops(self, inputs: Dict[str, Union[torch.Tensor, Any]]):\n",
    "        \"\"\"\n",
    "        For models that inherit from :class:`~transformers.PreTrainedModel`, uses that method to compute the number of\n",
    "        floating point operations for every backward + forward pass. If using another model, either implement such a\n",
    "        method in the model or subclass and override this method.\n",
    "        Args:\n",
    "            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "        Returns:\n",
    "            :obj:`int`: The number of floating-point operations.\n",
    "        \"\"\"\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68bf7bb6-efa1-438e-8f61-a60f46df79e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/pegasus-xsum were not used when initializing PegasusForCausalLM: ['model.encoder.layers.15.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.15.self_attn.k_proj.weight', 'model.encoder.layers.12.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.13.self_attn.out_proj.weight', 'model.encoder.embed_tokens.weight', 'model.encoder.layers.13.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.14.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.13.self_attn.q_proj.bias', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.13.fc1.bias', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layer_norm.weight', 'model.encoder.layers.14.fc1.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.15.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.13.self_attn.k_proj.weight', 'model.encoder.layers.14.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.14.final_layer_norm.weight', 'model.encoder.layers.12.final_layer_norm.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.15.fc1.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.14.fc2.bias', 'model.encoder.layers.12.fc1.bias', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.14.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.12.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.12.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.15.self_attn.v_proj.weight', 'model.encoder.layers.15.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.14.self_attn_layer_norm.bias', 'model.encoder.layers.14.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.12.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.13.self_attn.out_proj.bias', 'model.encoder.layers.14.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.12.self_attn_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.13.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.14.self_attn.v_proj.bias', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.12.self_attn.k_proj.bias', 'model.encoder.layers.15.fc2.bias', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layer_norm.bias', 'model.encoder.layers.12.self_attn.out_proj.bias', 'model.encoder.layers.13.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.14.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.12.fc2.weight', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.13.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.13.final_layer_norm.bias', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.14.self_attn.k_proj.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.13.fc2.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.15.fc1.bias', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.13.fc1.weight', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.12.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.12.fc2.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.12.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.15.self_attn.q_proj.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.13.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.13.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.shared.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.14.self_attn.q_proj.bias', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.15.self_attn.out_proj.bias', 'model.encoder.layers.12.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.15.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.13.self_attn.v_proj.weight', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.15.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.14.fc2.weight', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.15.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.14.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.15.fc2.weight', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.12.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.15.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.13.fc2.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.14.fc1.bias', 'model.encoder.layers.12.fc1.weight', 'final_logits_bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.15.self_attn.out_proj.weight', 'model.encoder.layers.2.fc2.bias']\n",
      "- This IS expected if you are initializing PegasusForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PegasusForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PegasusForCausalLM were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['lm_head.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CommonLitModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d402996c-e965-4047-a39c-68a2c465280c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a04bb94-1364-4709-bc76-878d6d9ced4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = transformer_model.cuda()\n",
    "sample_out = transformer_model(encoded_dict.input_ids.cuda(), encoded_dict.attention_mask.cuda(), output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e210ebf4-4ada-4a98-aa85-fb77e052e87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'hidden_states'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e942e16-3653-4a19-b765-f3ef11189391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 1024])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out['hidden_states'][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "527e15cc-0cec-40bd-a071-10bb695b5ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(sample_out['hidden_states'][-1], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0504d936-bebe-4fbd-90b5-b5b990501033",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = create_train_valid_ds(tokenizer, train_text, train_target, valid_text, valid_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bfcf10f5-20f7-4f97-9a17-35c63ec4915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7265d3b2-f7cc-48aa-9f2b-66987f10182f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256]), torch.Size([1, 256]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.attention_mask.unsqueeze(0).shape, encoded_dict.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b825b57-a244-4a0c-be59-102e9c8f2760",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_out = transformer_model(encode.input_ids.unsqueeze(0).cuda(), encode.attention_mask.unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d826f6b-79c8-447d-9d78-df79b99e6655",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68a48686-ddb0-4046-ab70-40e16117bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8fa4e6a-6a87-4860-b33a-075c5e693a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "kl_loss = nn.KLDivLoss(reduction = 'batchmean')\n",
    "\n",
    "def loss_fct(yhat, y):\n",
    "    return criterion(yhat, y) * 0.7 + 0.3 * kl_loss(yhat, y)\n",
    "\n",
    "loss_fct = nn.MSELoss()\n",
    "\n",
    "def loss_fct(yhat, y):\n",
    "    return torch.sqrt(criterion(yhat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a861b0e-1207-454d-81fa-4a684a153d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_args(fold):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(MODELS_PATH/f\"{cfg.model_name.replace('/', '_')}-{fold}\"),\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        per_device_train_batch_size=cfg.batch_size,\n",
    "        per_device_eval_batch_size=cfg.batch_size,\n",
    "        num_train_epochs=cfg.epochs,\n",
    "        logging_strategy=\"epoch\",\n",
    "        logging_first_step=True,\n",
    "        save_steps=40000,\n",
    "        fp16=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_total_limit = 3,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='mse',\n",
    "        greater_is_better=False,\n",
    "        gradient_accumulation_steps=1,\n",
    "        learning_rate=5e-5\n",
    "    )\n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fb7ea1ed-e72f-43fd-aa2c-b1645480f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    return {'mse': mean_squared_error(logits, labels), 'rmse': rmse_score_2(logits, labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "325a9194-570e-4c1b-83c7-eb0fe7723de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "826b6f17-dd24-4be8-8644-4e4e40712f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "class CommonLitTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        input_ids = inputs.pop(\"input_ids\")\n",
    "        attention_mask = inputs.pop(\"attention_mask\")\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        logits = outputs\n",
    "        loss = loss_fct(logits.flatten(),\n",
    "                        labels.float().flatten())\n",
    "        zero_cat = torch.zeros([1, 1]).to(outputs.device)\n",
    "        return (loss, torch.cat([zero_cat, outputs])) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fec9efc-c67a-41b3-a6ad-ecf805fc4a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google/pegasus-xsum'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "004a6849-c4d7-40e9-98e9-eacd947f550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/commonlit/models/{cfg.model_name.replace('/', '_')}-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d3822354-7ee5-4f5f-93e6-f357a0157811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_bins 0: [9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/pegasus-xsum were not used when initializing PegasusForCausalLM: ['model.encoder.layers.15.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.15.self_attn.k_proj.weight', 'model.encoder.layers.12.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.13.self_attn.out_proj.weight', 'model.encoder.embed_tokens.weight', 'model.encoder.layers.13.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.14.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.13.self_attn.q_proj.bias', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.13.fc1.bias', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layer_norm.weight', 'model.encoder.layers.14.fc1.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.15.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.13.self_attn.k_proj.weight', 'model.encoder.layers.14.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.14.final_layer_norm.weight', 'model.encoder.layers.12.final_layer_norm.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.15.fc1.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.14.fc2.bias', 'model.encoder.layers.12.fc1.bias', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.14.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.12.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.12.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.15.self_attn.v_proj.weight', 'model.encoder.layers.15.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.14.self_attn_layer_norm.bias', 'model.encoder.layers.14.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.12.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.13.self_attn.out_proj.bias', 'model.encoder.layers.14.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.12.self_attn_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.13.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.14.self_attn.v_proj.bias', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.12.self_attn.k_proj.bias', 'model.encoder.layers.15.fc2.bias', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layer_norm.bias', 'model.encoder.layers.12.self_attn.out_proj.bias', 'model.encoder.layers.13.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.14.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.12.fc2.weight', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.13.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.13.final_layer_norm.bias', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.14.self_attn.k_proj.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.13.fc2.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.15.fc1.bias', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.13.fc1.weight', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.12.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.12.fc2.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.12.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.15.self_attn.q_proj.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.13.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.13.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.shared.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.14.self_attn.q_proj.bias', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.15.self_attn.out_proj.bias', 'model.encoder.layers.12.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.15.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.13.self_attn.v_proj.weight', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.15.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.14.fc2.weight', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.15.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.14.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.15.fc2.weight', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.12.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.15.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.13.fc2.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.14.fc1.bias', 'model.encoder.layers.12.fc1.weight', 'final_logits_bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.15.self_attn.out_proj.weight', 'model.encoder.layers.2.fc2.bias']\n",
      "- This IS expected if you are initializing PegasusForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PegasusForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PegasusForCausalLM were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['lm_head.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:39mfm36b) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 570<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210614_084726-39mfm36b/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210614_084726-39mfm36b/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">winter-sun-11</strong>: <a href=\"https://wandb.ai/gilf/commonlit_google_pegasus-xsum/runs/39mfm36b\" target=\"_blank\">https://wandb.ai/gilf/commonlit_google_pegasus-xsum/runs/39mfm36b</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:39mfm36b). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">gentle-paper-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/gilf/commonlit_google_pegasus-xsum\" target=\"_blank\">https://wandb.ai/gilf/commonlit_google_pegasus-xsum</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/gilf/commonlit_google_pegasus-xsum/runs/70xzaqet\" target=\"_blank\">https://wandb.ai/gilf/commonlit_google_pegasus-xsum/runs/70xzaqet</a><br/>\n",
       "                Run data is saved locally in <code>/home/commonlit/notebooks/wandb/run-20210614_090211-70xzaqet</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1144' max='3810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1144/3810 10:26 < 24:22, 1.82 it/s, Epoch 9/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.277200</td>\n",
       "      <td>0.978654</td>\n",
       "      <td>1.048392</td>\n",
       "      <td>1.023910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.088000</td>\n",
       "      <td>0.939367</td>\n",
       "      <td>0.975574</td>\n",
       "      <td>0.987712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.999600</td>\n",
       "      <td>0.849946</td>\n",
       "      <td>0.798960</td>\n",
       "      <td>0.893846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.856772</td>\n",
       "      <td>0.797242</td>\n",
       "      <td>0.892884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>0.930160</td>\n",
       "      <td>0.930661</td>\n",
       "      <td>0.964708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.772000</td>\n",
       "      <td>0.825209</td>\n",
       "      <td>0.736604</td>\n",
       "      <td>0.858257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.718800</td>\n",
       "      <td>0.896990</td>\n",
       "      <td>0.863730</td>\n",
       "      <td>0.929371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.698700</td>\n",
       "      <td>0.816865</td>\n",
       "      <td>0.716223</td>\n",
       "      <td>0.846300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.756963</td>\n",
       "      <td>0.615787</td>\n",
       "      <td>0.784721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:274] . unexpected pos 2051334080 vs 2051333968",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch)\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_world_process_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0;31m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"optimizer.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scheduler.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:274] . unexpected pos 2051334080 vs 2051333968"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import Adafactor, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "bin_step = 1\n",
    "bestmodels = []\n",
    "eval_rmses = []\n",
    "for i in range(0, num_bins, bin_step):\n",
    "    train_bins = bin_list[i:i+bin_step]\n",
    "    print('train_bins', f'{i}: {train_bins}')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "    train_text, train_target, valid_text, valid_target = create_split([i])\n",
    "    train_ds, valid_ds = create_train_valid_ds(tokenizer, train_text, train_target, valid_text, valid_target)\n",
    "    training_args = create_training_args(i)\n",
    "    model = CommonLitModel()\n",
    "    optimizer = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
    "    optimizer = AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "    wandb.init(project=f\"commonlit_{cfg.model_name.replace('/', '_')}\")\n",
    "    trainer = CommonLitTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=valid_ds,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=12)],\n",
    "        optimizers=(optimizer, get_linear_schedule_with_warmup(optimizer, 4, cfg.epochs * len(train_ds)))\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    print('training_args.output_dir', training_args.output_dir)\n",
    "    tokenizer.save_pretrained(training_args.output_dir)\n",
    "    result = trainer.evaluate()\n",
    "    bestmodels.append(trainer.state.best_model_checkpoint)\n",
    "    print('best_model_checkpoint', trainer.state.best_model_checkpoint)\n",
    "    print('result', result)\n",
    "    eval_rmses.append(result['eval_rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993d2b0-3c68-4241-b15d-c51e10ee788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_FOLDER = MODELS_PATH/cfg.model_name/'best'\n",
    "!rm -rf {BEST_MODEL_FOLDER}\n",
    "!mkdir -p {BEST_MODEL_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290ec66-8db4-4047-8fea-8d8f609c3d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Mean best RSME losses', np.array(eval_rmses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce73fad-cc12-4b8f-9849-5a44057cf956",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodels[0], MODELS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a671cdf-daac-4a40-861b-560d173247aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(MODELS_PATH/'roberta-large-0/checkpoint-1853').exists(),\n",
    "(MODELS_PATH/'roberta-large-1/checkpoint-1526').exists(),\n",
    "(MODELS_PATH/'roberta-large-2/checkpoint-2616').exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3d9bae-7840-4427-84e1-e23f51b51844",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodels = [MODELS_PATH/'roberta-large-0/checkpoint-1853',\n",
    "              MODELS_PATH/'roberta-large-1/checkpoint-1526',\n",
    "              MODELS_PATH/'roberta-large-2/checkpoint-2616',\n",
    "              MODELS_PATH/'roberta-large-3/checkpoint-1417',\n",
    "              MODELS_PATH/'roberta-large-4/checkpoint-1417',\n",
    "              MODELS_PATH/'roberta-large-5/checkpoint-1635',\n",
    "              MODELS_PATH/'roberta-large-6/checkpoint-1526',\n",
    "              MODELS_PATH/'roberta-large-7/checkpoint-1635',\n",
    "              MODELS_PATH/'roberta-large-8/checkpoint-1526',\n",
    "              MODELS_PATH/'roberta-large-9/checkpoint-2071',\n",
    "              MODELS_PATH/'roberta-large-10/checkpoint-1417',\n",
    "              MODELS_PATH/'roberta-large-11/checkpoint-1308']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3faa7c-7b90-4fe2-aebf-cf9733a3674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f114e7-7e75-43d8-8c4c-6889f6393b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "def normalize_name(path_name):\n",
    "    return path_name.replace('', '')\n",
    "\n",
    "for i, best_model in enumerate(bestmodels):\n",
    "    print(f'Processing {i}th model')\n",
    "    best_model_file = f'{best_model}/pytorch_model.bin'\n",
    "    if Path(best_model_file).exists():\n",
    "        copyfile(best_model_file, f'{BEST_MODEL_FOLDER}/{i}_pytorch_model.bin')\n",
    "        tokenizer_path = Path(BEST_MODEL_FOLDER/f'tokenizer-{i}')\n",
    "        tokenizer_path.mkdir(parents=True, exist_ok=True)\n",
    "        assert tokenizer_path.exists()\n",
    "\n",
    "        tokenizer_json = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}-{i}/tokenizer.json'))\n",
    "        assert tokenizer_json.exists(), f'{tokenizer_json} does not exist'\n",
    "        copyfile(tokenizer_json, tokenizer_path/'tokenizer.json')\n",
    "\n",
    "#         vocab_txt = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}-{i}/vocab.json'))\n",
    "#         assert vocab_txt.exists(), f'{vocab_txt} does not exist'\n",
    "#         copyfile(vocab_txt, tokenizer_path/'vocab.json')\n",
    "\n",
    "        config_json = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}-{i}/config.json'))\n",
    "        assert config_json.exists()\n",
    "        copyfile(config_json, tokenizer_path/'config.json')\n",
    "    else:\n",
    "        print(f'{best_model_file} is missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc422f71-d671-4eca-82f4-0dd059b1200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(MODELS_PATH/cfg.model_name/'best_models', 'zip', BEST_MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d2659-6041-47d9-ba4c-a8ecade644a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5088d-df35-4b54-8de6-9c8a3bdc5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h {MODELS_PATH/cfg.model_name}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616c042-2877-470a-b227-948606188b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets init -p {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6984b-07d9-49e6-89b2-6066503bda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json_path = Path(MODELS_PATH/cfg.model_name/'dataset-metadata.json')\n",
    "assert dataset_json_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa049c-faa9-45da-af4f-554a2000f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {str(dataset_json_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf108e8-c48c-4134-809b-6c775ef5b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_json_path, 'r') as f:\n",
    "    dataset_json = f.read()\n",
    "    dataset_json = dataset_json.replace('INSERT_TITLE_HERE', f'commonlit-{cfg.model_name}').replace('INSERT_SLUG_HERE', f'commonlit-{cfg.model_name}')\n",
    "    print(dataset_json)\n",
    "with(open(dataset_json_path, 'w')) as f:\n",
    "    f.write(dataset_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9877c0cb-0d80-43d6-a064-f929ad92b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {MODELS_PATH/cfg.model_name}/best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c385b-abde-4c53-9458-1561a69b158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(MODELS_PATH/cfg.model_name/'best_lm_model', 'zip', MODELS_PATH/f'{cfg.model_name}_lm/best_lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851185dc-f532-4920-bfc0-39f36f0224bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets create -p {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffe0ba-8412-4616-a0a4-78c0b4552f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(str(MODELS_PATH/f'distilroberta-0/checkpoint-105/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e77de-3b71-408f-8d6c-25bae3e60f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = CommonLitModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de19b9-2d6b-41c1-a765-5c39551fe176",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859231b7-d595-463e-8ab7-1ac150193306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
