{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e1dbe-f484-4304-8001-f10b5e0321c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef39394-5986-44bb-a6d6-84957a492ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, gc, sys, time, collections, random, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict, Optional, Union, Any, List, Tuple\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.utils.data as D\n",
    "from torch.utils.data.dataset import Dataset, IterableDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertModel\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertModel\n",
    "from transformers import Trainer\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from transformers import TrainingArguments\n",
    "from transformers.trainer_utils import EvalLoopOutput\n",
    "from transformers.trainer import logging\n",
    "from transformers.file_utils import is_torch_tpu_available, is_sagemaker_mp_enabled\n",
    "from transformers.trainer_pt_utils import find_batch_size, nested_concat, nested_numpify, nested_truncate, nested_detach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c54d1-55c1-4701-9fde-692cf4450c84",
   "metadata": {},
   "source": [
    "### Folders and Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c75e83-4760-4511-bf31-a144abfc01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/home/commonlit/data/')\n",
    "assert DATA_PATH.exists()\n",
    "MODELS_PATH = Path('/home/commonlit/models/')\n",
    "if not MODELS_PATH.exists():\n",
    "    os.mkdir(MODELS_PATH)\n",
    "assert MODELS_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b25934-3c16-4cb0-ab3b-6d95223432f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commonlit_lm\t\t       test.csv        train_duo.csv\n",
      "commonlitreadabilityprize.zip  train-orig.csv\n",
      "sample_submission.csv\t       train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12796f2-c49a-4d32-9f38-0ecdec520539",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH/'train_duo.csv')\n",
    "test_df = pd.read_csv(DATA_PATH/'test.csv')\n",
    "sample_df = pd.read_csv(DATA_PATH/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179a075d-6fa8-4cf4-b703-db4f09c9649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>excerpt_shortened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1142</td>\n",
       "      <td>493b80aa7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571404</td>\n",
       "      <td>The Dunwich horror itself came between Lammas ...</td>\n",
       "      <td>-3.672314</td>\n",
       "      <td>The Dunwich horror itself came between Lammas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1769</td>\n",
       "      <td>fe44cbd14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644398</td>\n",
       "      <td>The iron cylinder weighs 23 kilogrammes; but, ...</td>\n",
       "      <td>-3.655626</td>\n",
       "      <td>The iron cylinder weighs 23 kilogrammes; but, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1767</td>\n",
       "      <td>284eaa5ad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603819</td>\n",
       "      <td>As to surface-slope its measurement—from nearl...</td>\n",
       "      <td>-3.641414</td>\n",
       "      <td>As to surface-slope its measurement—from nearl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1735</td>\n",
       "      <td>9e9eacb49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.606822</td>\n",
       "      <td>The tree is dioecious, bearing male catkins on...</td>\n",
       "      <td>-3.638385</td>\n",
       "      <td>The tree is dioecious, bearing male catkins on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1854</td>\n",
       "      <td>466e33a64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567050</td>\n",
       "      <td>The copper even of such a conductor has been m...</td>\n",
       "      <td>-3.616792</td>\n",
       "      <td>The copper even of such a conductor has been m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>2843</td>\n",
       "      <td>1080</td>\n",
       "      <td>016913371</td>\n",
       "      <td>https://www.africanstorybook.org/</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>0.599600</td>\n",
       "      <td>Grandma's garden was wonderful. It was full of...</td>\n",
       "      <td>1.466629</td>\n",
       "      <td>Grandma's garden was wonderful. It was full of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>2844</td>\n",
       "      <td>1028</td>\n",
       "      <td>7a1d484be</td>\n",
       "      <td>https://www.africanstorybook.org/</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>0.606997</td>\n",
       "      <td>More people came to the bus stop just before 9...</td>\n",
       "      <td>1.504669</td>\n",
       "      <td>More people came to the bus stop just before 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>2845</td>\n",
       "      <td>822</td>\n",
       "      <td>8f35441e3</td>\n",
       "      <td>https://www.africanstorybook.org/#</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>0.624776</td>\n",
       "      <td>Every day, Emeka's father took him to school i...</td>\n",
       "      <td>1.562759</td>\n",
       "      <td>Every day, Emeka's father took him to school i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>2846</td>\n",
       "      <td>995</td>\n",
       "      <td>849971671</td>\n",
       "      <td>https://www.africanstorybook.org/</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>0.596349</td>\n",
       "      <td>For her last birthday, Sisanda had a special t...</td>\n",
       "      <td>1.590858</td>\n",
       "      <td>For her last birthday, Sisanda had a special t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>2847</td>\n",
       "      <td>2844</td>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>0.646900</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>1.654630</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2848 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index         id  \\\n",
       "0              0   1142  493b80aa7   \n",
       "1              1   1769  fe44cbd14   \n",
       "2              2   1767  284eaa5ad   \n",
       "3              3   1735  9e9eacb49   \n",
       "4              4   1854  466e33a64   \n",
       "...          ...    ...        ...   \n",
       "2843        2843   1080  016913371   \n",
       "2844        2844   1028  7a1d484be   \n",
       "2845        2845    822  8f35441e3   \n",
       "2846        2846    995  849971671   \n",
       "2847        2847   2844  25ca8f498   \n",
       "\n",
       "                                              url_legal       license  \\\n",
       "0                                                   NaN           NaN   \n",
       "1                                                   NaN           NaN   \n",
       "2                                                   NaN           NaN   \n",
       "3                                                   NaN           NaN   \n",
       "4                                                   NaN           NaN   \n",
       "...                                                 ...           ...   \n",
       "2843                  https://www.africanstorybook.org/     CC BY 4.0   \n",
       "2844                  https://www.africanstorybook.org/     CC BY 4.0   \n",
       "2845                 https://www.africanstorybook.org/#     CC BY 4.0   \n",
       "2846                  https://www.africanstorybook.org/     CC BY 4.0   \n",
       "2847  https://sites.ehe.osu.edu/beyondpenguins/files...  CC BY-SA 3.0   \n",
       "\n",
       "      standard_error                                            excerpt  \\\n",
       "0           0.571404  The Dunwich horror itself came between Lammas ...   \n",
       "1           0.644398  The iron cylinder weighs 23 kilogrammes; but, ...   \n",
       "2           0.603819  As to surface-slope its measurement—from nearl...   \n",
       "3           0.606822  The tree is dioecious, bearing male catkins on...   \n",
       "4           0.567050  The copper even of such a conductor has been m...   \n",
       "...              ...                                                ...   \n",
       "2843        0.599600  Grandma's garden was wonderful. It was full of...   \n",
       "2844        0.606997  More people came to the bus stop just before 9...   \n",
       "2845        0.624776  Every day, Emeka's father took him to school i...   \n",
       "2846        0.596349  For her last birthday, Sisanda had a special t...   \n",
       "2847        0.646900  When you think of dinosaurs and where they liv...   \n",
       "\n",
       "        target                                  excerpt_shortened  \n",
       "0    -3.672314  The Dunwich horror itself came between Lammas ...  \n",
       "1    -3.655626  The iron cylinder weighs 23 kilogrammes; but, ...  \n",
       "2    -3.641414  As to surface-slope its measurement—from nearl...  \n",
       "3    -3.638385  The tree is dioecious, bearing male catkins on...  \n",
       "4    -3.616792  The copper even of such a conductor has been m...  \n",
       "...        ...                                                ...  \n",
       "2843  1.466629  Grandma's garden was wonderful. It was full of...  \n",
       "2844  1.504669  More people came to the bus stop just before 9...  \n",
       "2845  1.562759  Every day, Emeka's father took him to school i...  \n",
       "2846  1.590858  For her last birthday, Sisanda had a special t...  \n",
       "2847  1.654630  When you think of dinosaurs and where they liv...  \n",
       "\n",
       "[2848 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efffba57-a6ab-4210-8391-5f2fccb3fd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>excerpt_shortened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>458</td>\n",
       "      <td>235</td>\n",
       "      <td>622f6215e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538084</td>\n",
       "      <td>About this time there was living in Nottingham...</td>\n",
       "      <td>-2.055361</td>\n",
       "      <td>About this time there was living in Nottingham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>459</td>\n",
       "      <td>2644</td>\n",
       "      <td>896fd296d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.517827</td>\n",
       "      <td>We then came back to our castle; and there I f...</td>\n",
       "      <td>-2.054038</td>\n",
       "      <td>We then came back to our castle; and there I f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>838</td>\n",
       "      <td>234</td>\n",
       "      <td>5cb5ab998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.478166</td>\n",
       "      <td>When they drew near Nottingham, all the people...</td>\n",
       "      <td>-1.541831</td>\n",
       "      <td>When they drew near Nottingham, all the people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>839</td>\n",
       "      <td>2663</td>\n",
       "      <td>87197d2c7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470756</td>\n",
       "      <td>You may lead a child to read Rab and His Frien...</td>\n",
       "      <td>-1.541170</td>\n",
       "      <td>You may lead a child to read Rab and His Frien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1041</td>\n",
       "      <td>231</td>\n",
       "      <td>21ea485fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450399</td>\n",
       "      <td>A little within the wood there was a fair cast...</td>\n",
       "      <td>-1.302944</td>\n",
       "      <td>A little within the wood there was a fair cast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>1042</td>\n",
       "      <td>232</td>\n",
       "      <td>21ea485fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450399</td>\n",
       "      <td>A little within the wood there was an imposing...</td>\n",
       "      <td>-1.302688</td>\n",
       "      <td>A little within the wood there was an imposing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1620</td>\n",
       "      <td>233</td>\n",
       "      <td>a04741371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.506864</td>\n",
       "      <td>The king dwelt for many months in Nottingham, ...</td>\n",
       "      <td>-0.714200</td>\n",
       "      <td>The king dwelt for many months in Nottingham, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>1621</td>\n",
       "      <td>2393</td>\n",
       "      <td>0aaac8f69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458041</td>\n",
       "      <td>The introductions concluded, Hawkins followed ...</td>\n",
       "      <td>-0.713706</td>\n",
       "      <td>The introductions concluded, Hawkins followed ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index         id url_legal license  standard_error  \\\n",
       "458          458    235  622f6215e       NaN     NaN        0.538084   \n",
       "459          459   2644  896fd296d       NaN     NaN        0.517827   \n",
       "838          838    234  5cb5ab998       NaN     NaN        0.478166   \n",
       "839          839   2663  87197d2c7       NaN     NaN        0.470756   \n",
       "1041        1041    231  21ea485fb       NaN     NaN        0.450399   \n",
       "1042        1042    232  21ea485fb       NaN     NaN        0.450399   \n",
       "1620        1620    233  a04741371       NaN     NaN        0.506864   \n",
       "1621        1621   2393  0aaac8f69       NaN     NaN        0.458041   \n",
       "\n",
       "                                                excerpt    target  \\\n",
       "458   About this time there was living in Nottingham... -2.055361   \n",
       "459   We then came back to our castle; and there I f... -2.054038   \n",
       "838   When they drew near Nottingham, all the people... -1.541831   \n",
       "839   You may lead a child to read Rab and His Frien... -1.541170   \n",
       "1041  A little within the wood there was a fair cast... -1.302944   \n",
       "1042  A little within the wood there was an imposing... -1.302688   \n",
       "1620  The king dwelt for many months in Nottingham, ... -0.714200   \n",
       "1621  The introductions concluded, Hawkins followed ... -0.713706   \n",
       "\n",
       "                                      excerpt_shortened  \n",
       "458   About this time there was living in Nottingham...  \n",
       "459   We then came back to our castle; and there I f...  \n",
       "838   When they drew near Nottingham, all the people...  \n",
       "839   You may lead a child to read Rab and His Frien...  \n",
       "1041  A little within the wood there was a fair cast...  \n",
       "1042  A little within the wood there was an imposing...  \n",
       "1620  The king dwelt for many months in Nottingham, ...  \n",
       "1621  The introductions concluded, Hawkins followed ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['excerpt'].str.contains('Robin Hood')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13ba276-1696-40d2-b05f-8f5f31e79c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A little within the wood there was a fair castle, with a double moat, and surrounded by stout walls. Here dwelt that noble knight, Sir Richard Lee, to whom Robin Hood had lent the four hundred pounds to redeem his land.\\nHe saw the little company of outlaws fighting their way along, so he hastened to call them to come and take shelter in his castle.\\n\"Welcome art thou, Robin Hood! Welcome!\" he cried, as he led them in. \"Much I thank thee for thy comfort and courtesy and great kindness to me in the forest. There is no man in the world I love so much as thee. For all the proud Sheriff of Nottingham, here thou shalt be safe!—Shut the gates, and draw the bridge, and let no man come in!\" he shouted to his retainers. \"Arm you well; make ready; guard the walls! One thing, Robin, I promise thee: here shalt thou stay for twelve days as my guest, to sup, and eat, and dine.\"\\nSwiftly and readily tables were laid and cloths spread, and Robin Hood and his merry men sat down to a good meal.\\nOut of the hall stepped the Piper, and as he stepped he laid his pipe to his lips and a shrill keen tune sounded through street and house. And as each note pierced the air you might have seen a strange sight. For out of every hole the rats came tumbling. There were none too old and none too young, none too big and none too little to crowd at the Piper\\'s heels and with eager feet and upturned noses to patter after him as he paced the streets. Nor was the Piper unmindful of the little toddling ones, for every fifty yards he\\'d stop and give an extra flourish on his pipe just to give them time to keep up with the older and stronger of the band.\\nUp Silver Street he went, and down Gold Street, and at the end of Gold Street is the harbour and the broad Solent beyond. And as he paced along, slowly and gravely, the townsfolk flocked to door and window, and many a blessing they called down upon his head.',\n",
       "       'A little within the wood there was an imposing castle, with a double dig, and surrounded by stout walls. Here dwelt that phantastic knight, Sir William Jones, to whom Trevor Blanford had lent the twenty hundred dollars to redeem his land.\\nHe saw the little company of small criminals fighting their way along, so he hastened to call them to come and take shelter in his castle.\\n\"Welcome art thou, Trevor Blanford! Welcome!\" he cried, as he led them in. \"Much I thank thee for thy comfort and sympathy and great kindness to me in the forest. There is no man in the world I love so much as thee. For all the proud Sheriff of Kendall, here thou shalt be safe!—Shut the gates, and draw the bridge, and let no man come in!\" he shouted to his retainers. \"Arm you well; prepare yourselves; guard the fortress! One thing, Trevor, I promise thee: here shalt thou stay for fifteen days as my guest, to sup, and eat, and dine.\"\\nSwiftly and readily tables were laid and cloths spread, and Trevor Blanford and his jolly men sat down to a good meal.\\nA little within the wood there was a fair castle, with a double moat, and surrounded by stout walls. Here dwelt that noble knight, Sir Richard Lee, to whom Robin Hood had lent the four hundred pounds to redeem his land.\\nHe saw the little company of outlaws fighting their way along, so he hastened to call them to come and take shelter in his castle.\\n\"Welcome art thou, Robin Hood! Welcome!\" he cried, as he led them in. \"Much I thank thee for thy comfort and courtesy and great kindness to me in the forest. There is no man in the world I love so much as thee. For all the proud Sheriff of Nottingham, here thou shalt be safe!—Shut the gates, and draw the bridge, and let no man come in!\" he shouted to his retainers. \"Arm you well; make ready; guard the walls! One thing, Robin, I promise thee: here shalt thou stay for twelve days as my guest, to sup, and eat, and dine.\"\\nSwiftly and readily tables were laid and cloths spread, and Robin Hood and his merry men sat down to a good meal.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['id'] == '21ea485fb']['excerpt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f5b0bd8-527e-4b89-9082-f0780c9ae28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23   -3.352197\n",
       "24   -3.351956\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['id'] == '0bf29d257']['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4144ba75-a2b5-4836-a417-10375ffe26c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['excerpt_shortened'] = train_df['excerpt'].apply(lambda t: re.sub(r'(.+\\.).+', r'\\1',  t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "003515fb-4fb6-400d-b990-64d583cdac73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Dunwich horror itself came between Lammas and the equinox in 1928, and Dr. Armitage was among those who witnessed its monstrous prologue. He had heard, meanwhile, of Whateley's grotesque trip to Cambridge, and of his frantic efforts to borrow or copy from the Necronomicon at the Widener Library. Those efforts had been in vain, since Armitage had issued warnings of the keenest intensity to all librarians having charge of the dreaded volume.\\nEarly in August the half-expected outcome developed, and in the small hours of the third Dr. Armitage was awakened suddenly by the wild, fierce cries of the savage watchdog on the college campus. Deep and terrible, the snarling, half-mad growls and barks continued; always in mounting volume, but with hideously significant pauses.\\nThe commutator is peculiar, consisting of only three segments of a copper ring, while in the simplest of other continuous current generators several times that number exist, and frequently 120! segments are to be found. These three segments are made so as to be removable in a moment for cleaning or replacement. They are mounted upon a metal support, and are surrounded on all sides by a free air space, and cannot, therefore, lose their insulated condition. This feature of air insulation is peculiar to this system, and is very important as a factor in the durability of the commutator. Besides this, the commutator is sustained by supports carried in flanges upon the shaft, which flanges, as an additional safeguard, are coated all over with hard rubber, one of the finest known insulators. It may be stated, without fear of contradiction, that no other commutator made is so thoroughly insulated and protected.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['excerpt_shortened'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e79e005-5651-4414-9725-4567d3a9b300",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07938c53-d840-4889-b9ab-3170c608137e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2848.000000\n",
       "mean       -0.958295\n",
       "std         1.031818\n",
       "min        -3.672314\n",
       "25%        -1.686362\n",
       "50%        -0.907955\n",
       "75%        -0.203294\n",
       "max         1.654630\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e568bce3-f458-4471-986b-9e993ebe2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_mean = train_df['target'].mean()\n",
    "train_target_std = train_df['target'].std()\n",
    "train_df['normalized_target'] = (train_df['target'] - train_target_mean) / train_target_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44eaabcc-b0aa-4f11-ae01-79ac86b2f7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.9582950780537218, 1.0318182993253338)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_mean, train_target_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a331cf16-59f9-492f-b753-96c72e69cc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.848000e+03\n",
       "mean    -7.983626e-17\n",
       "std      1.000000e+00\n",
       "min     -2.630326e+00\n",
       "25%     -7.056157e-01\n",
       "50%      4.878819e-02\n",
       "75%      7.317187e-01\n",
       "max      2.532350e+00\n",
       "Name: normalized_target, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['normalized_target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a80edc32-5e12-4487-98ba-f73d5256e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['normalized_target_check'] = train_df['normalized_target'] * train_target_std + train_target_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1433f5d3-98d1-419d-9635-71b379fa214f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>excerpt_shortened</th>\n",
       "      <th>normalized_target</th>\n",
       "      <th>normalized_target_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1142</td>\n",
       "      <td>493b80aa7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571404</td>\n",
       "      <td>The Dunwich horror itself came between Lammas ...</td>\n",
       "      <td>-3.672314</td>\n",
       "      <td>The Dunwich horror itself came between Lammas ...</td>\n",
       "      <td>-2.630326</td>\n",
       "      <td>-3.672314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1769</td>\n",
       "      <td>fe44cbd14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644398</td>\n",
       "      <td>The iron cylinder weighs 23 kilogrammes; but, ...</td>\n",
       "      <td>-3.655626</td>\n",
       "      <td>The iron cylinder weighs 23 kilogrammes; but, ...</td>\n",
       "      <td>-2.614153</td>\n",
       "      <td>-3.655626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1767</td>\n",
       "      <td>284eaa5ad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603819</td>\n",
       "      <td>As to surface-slope its measurement—from nearl...</td>\n",
       "      <td>-3.641414</td>\n",
       "      <td>As to surface-slope its measurement—from nearl...</td>\n",
       "      <td>-2.600379</td>\n",
       "      <td>-3.641414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1735</td>\n",
       "      <td>9e9eacb49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.606822</td>\n",
       "      <td>The tree is dioecious, bearing male catkins on...</td>\n",
       "      <td>-3.638385</td>\n",
       "      <td>The tree is dioecious, bearing male catkins on...</td>\n",
       "      <td>-2.597443</td>\n",
       "      <td>-3.638385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1854</td>\n",
       "      <td>466e33a64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567050</td>\n",
       "      <td>The copper even of such a conductor has been m...</td>\n",
       "      <td>-3.616792</td>\n",
       "      <td>The copper even of such a conductor has been m...</td>\n",
       "      <td>-2.576517</td>\n",
       "      <td>-3.616792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1657</td>\n",
       "      <td>ee7d40251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.588952</td>\n",
       "      <td>We have frequent inquiries as to the best mean...</td>\n",
       "      <td>-3.591060</td>\n",
       "      <td>We have frequent inquiries as to the best mean...</td>\n",
       "      <td>-2.551578</td>\n",
       "      <td>-3.591060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>507</td>\n",
       "      <td>f18969199</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Molecular_nanote...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>0.643309</td>\n",
       "      <td>Molecular nanotechnology (MNT) is a technology...</td>\n",
       "      <td>-3.567280</td>\n",
       "      <td>Molecular nanotechnology (MNT) is a technology...</td>\n",
       "      <td>-2.528531</td>\n",
       "      <td>-3.567280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1833</td>\n",
       "      <td>85b41606e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.609348</td>\n",
       "      <td>As soon as the plate is dry, a positive cliché...</td>\n",
       "      <td>-3.546589</td>\n",
       "      <td>As soon as the plate is dry, a positive cliché...</td>\n",
       "      <td>-2.508478</td>\n",
       "      <td>-3.546589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1842</td>\n",
       "      <td>1f8e17b78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.549034</td>\n",
       "      <td>Reservoir.--An ordinary inverted bell-glass wi...</td>\n",
       "      <td>-3.541709</td>\n",
       "      <td>Reservoir.--An ordinary inverted bell-glass wi...</td>\n",
       "      <td>-2.503749</td>\n",
       "      <td>-3.541709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1637</td>\n",
       "      <td>99a602911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.595653</td>\n",
       "      <td>The soil most suitable for the full developmen...</td>\n",
       "      <td>-3.535558</td>\n",
       "      <td>The soil most suitable for the full developmen...</td>\n",
       "      <td>-2.497788</td>\n",
       "      <td>-3.535558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1426</td>\n",
       "      <td>eecfb12bc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586590</td>\n",
       "      <td>They must, I think, be read in the light of th...</td>\n",
       "      <td>-3.530681</td>\n",
       "      <td>They must, I think, be read in the light of th...</td>\n",
       "      <td>-2.493061</td>\n",
       "      <td>-3.530681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2785</td>\n",
       "      <td>3e854ccc5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568356</td>\n",
       "      <td>For staining Bacillus tuberculosis the followi...</td>\n",
       "      <td>-3.528620</td>\n",
       "      <td>For staining Bacillus tuberculosis the followi...</td>\n",
       "      <td>-2.491063</td>\n",
       "      <td>-3.528620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2126</td>\n",
       "      <td>50e970a38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611192</td>\n",
       "      <td>It is hardly possible to imagine with what eag...</td>\n",
       "      <td>-3.502703</td>\n",
       "      <td>It is hardly possible to imagine with what eag...</td>\n",
       "      <td>-2.465946</td>\n",
       "      <td>-3.502703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2183</td>\n",
       "      <td>2ade9142e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.648481</td>\n",
       "      <td>The question now is as to a criterion, by whic...</td>\n",
       "      <td>-3.475567</td>\n",
       "      <td>The question now is as to a criterion, by whic...</td>\n",
       "      <td>-2.439646</td>\n",
       "      <td>-3.475567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1679</td>\n",
       "      <td>694fd5ea9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.593891</td>\n",
       "      <td>The hydrochloric acid gas passes into a vessel...</td>\n",
       "      <td>-3.468586</td>\n",
       "      <td>The hydrochloric acid gas passes into a vessel...</td>\n",
       "      <td>-2.432881</td>\n",
       "      <td>-3.468586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1925</td>\n",
       "      <td>4df97a927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600152</td>\n",
       "      <td>As with consciousness and volition, so with su...</td>\n",
       "      <td>-3.447497</td>\n",
       "      <td>As with consciousness and volition, so with su...</td>\n",
       "      <td>-2.412443</td>\n",
       "      <td>-3.447497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1638</td>\n",
       "      <td>efb89de3f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569281</td>\n",
       "      <td>Windows there are none in our houses: for the ...</td>\n",
       "      <td>-3.423448</td>\n",
       "      <td>Windows there are none in our houses: for the ...</td>\n",
       "      <td>-2.389134</td>\n",
       "      <td>-3.423448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>357</td>\n",
       "      <td>c56b17080</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Electric_charge</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>0.642028</td>\n",
       "      <td>Charge is the fundamental property of forms of...</td>\n",
       "      <td>-3.414649</td>\n",
       "      <td>Charge is the fundamental property of forms of...</td>\n",
       "      <td>-2.380607</td>\n",
       "      <td>-3.414649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1474</td>\n",
       "      <td>4ba8e0311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.599598</td>\n",
       "      <td>Bull, John, a fine, fat, American-beef fed ind...</td>\n",
       "      <td>-3.408723</td>\n",
       "      <td>Bull, John, a fine, fat, American-beef fed ind...</td>\n",
       "      <td>-2.374864</td>\n",
       "      <td>-3.408723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1712</td>\n",
       "      <td>51d407f43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575624</td>\n",
       "      <td>An ordinary weathercock provided with datum po...</td>\n",
       "      <td>-3.399402</td>\n",
       "      <td>An ordinary weathercock provided with datum po...</td>\n",
       "      <td>-2.365830</td>\n",
       "      <td>-3.399402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1785</td>\n",
       "      <td>968c283cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617688</td>\n",
       "      <td>\"The principal generators of incrustation in b...</td>\n",
       "      <td>-3.384237</td>\n",
       "      <td>\"The principal generators of incrustation in b...</td>\n",
       "      <td>-2.351133</td>\n",
       "      <td>-3.384237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2250</td>\n",
       "      <td>acac08ee4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649671</td>\n",
       "      <td>On the basis of the preceding comparisons some...</td>\n",
       "      <td>-3.364766</td>\n",
       "      <td>On the basis of the preceding comparisons some...</td>\n",
       "      <td>-2.332262</td>\n",
       "      <td>-3.364766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1093</td>\n",
       "      <td>099389445</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Electron_cry...</td>\n",
       "      <td>CC BY-SA 3.0 and GFDL</td>\n",
       "      <td>0.618258</td>\n",
       "      <td>Electron crystallography is a method to determ...</td>\n",
       "      <td>-3.354185</td>\n",
       "      <td>Electron crystallography is a method to determ...</td>\n",
       "      <td>-2.322007</td>\n",
       "      <td>-3.354185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1305</td>\n",
       "      <td>0bf29d257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.554593</td>\n",
       "      <td>The truth stands that the whole Sachsen-Anhalt...</td>\n",
       "      <td>-3.352197</td>\n",
       "      <td>The truth stands that the whole Sachsen-Anhalt...</td>\n",
       "      <td>-2.320081</td>\n",
       "      <td>-3.352197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1304</td>\n",
       "      <td>0bf29d257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.554593</td>\n",
       "      <td>The truth stands that the whole Schleswig-Hols...</td>\n",
       "      <td>-3.351956</td>\n",
       "      <td>The truth stands that the whole Schleswig-Hols...</td>\n",
       "      <td>-2.319847</td>\n",
       "      <td>-3.351956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1643</td>\n",
       "      <td>c744465b7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.554326</td>\n",
       "      <td>These enemies of our agriculture were scarcely...</td>\n",
       "      <td>-3.349074</td>\n",
       "      <td>These enemies of our agriculture were scarcely...</td>\n",
       "      <td>-2.317054</td>\n",
       "      <td>-3.349074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2149</td>\n",
       "      <td>d36b46c15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603355</td>\n",
       "      <td>The violations of truth, which dishonor poetry...</td>\n",
       "      <td>-3.344663</td>\n",
       "      <td>The violations of truth, which dishonor poetry...</td>\n",
       "      <td>-2.312779</td>\n",
       "      <td>-3.344663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1210</td>\n",
       "      <td>a6f74f001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614036</td>\n",
       "      <td>Checks require a stamp of 4 cents, also promis...</td>\n",
       "      <td>-3.340712</td>\n",
       "      <td>Checks require a stamp of 4 cents, also promis...</td>\n",
       "      <td>-2.308950</td>\n",
       "      <td>-3.340712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1724</td>\n",
       "      <td>286f9237a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.556906</td>\n",
       "      <td>The Pintsch gas is prepared by the distillatio...</td>\n",
       "      <td>-3.337050</td>\n",
       "      <td>The Pintsch gas is prepared by the distillatio...</td>\n",
       "      <td>-2.305401</td>\n",
       "      <td>-3.337050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1502</td>\n",
       "      <td>6d7c845a3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.576591</td>\n",
       "      <td>The normal and characteristic occupations of t...</td>\n",
       "      <td>-3.328119</td>\n",
       "      <td>The normal and characteristic occupations of t...</td>\n",
       "      <td>-2.296746</td>\n",
       "      <td>-3.328119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  index         id  \\\n",
       "0            0   1142  493b80aa7   \n",
       "1            1   1769  fe44cbd14   \n",
       "2            2   1767  284eaa5ad   \n",
       "3            3   1735  9e9eacb49   \n",
       "4            4   1854  466e33a64   \n",
       "5            5   1657  ee7d40251   \n",
       "6            6    507  f18969199   \n",
       "7            7   1833  85b41606e   \n",
       "8            8   1842  1f8e17b78   \n",
       "9            9   1637  99a602911   \n",
       "10          10   1426  eecfb12bc   \n",
       "11          11   2785  3e854ccc5   \n",
       "12          12   2126  50e970a38   \n",
       "13          13   2183  2ade9142e   \n",
       "14          14   1679  694fd5ea9   \n",
       "15          15   1925  4df97a927   \n",
       "16          16   1638  efb89de3f   \n",
       "17          17    357  c56b17080   \n",
       "18          18   1474  4ba8e0311   \n",
       "19          19   1712  51d407f43   \n",
       "20          20   1785  968c283cd   \n",
       "21          21   2250  acac08ee4   \n",
       "22          22   1093  099389445   \n",
       "23          23   1305  0bf29d257   \n",
       "24          24   1304  0bf29d257   \n",
       "25          25   1643  c744465b7   \n",
       "26          26   2149  d36b46c15   \n",
       "27          27   1210  a6f74f001   \n",
       "28          28   1724  286f9237a   \n",
       "29          29   1502  6d7c845a3   \n",
       "\n",
       "                                            url_legal                license  \\\n",
       "0                                                 NaN                    NaN   \n",
       "1                                                 NaN                    NaN   \n",
       "2                                                 NaN                    NaN   \n",
       "3                                                 NaN                    NaN   \n",
       "4                                                 NaN                    NaN   \n",
       "5                                                 NaN                    NaN   \n",
       "6   https://en.wikipedia.org/wiki/Molecular_nanote...           CC BY-SA 3.0   \n",
       "7                                                 NaN                    NaN   \n",
       "8                                                 NaN                    NaN   \n",
       "9                                                 NaN                    NaN   \n",
       "10                                                NaN                    NaN   \n",
       "11                                                NaN                    NaN   \n",
       "12                                                NaN                    NaN   \n",
       "13                                                NaN                    NaN   \n",
       "14                                                NaN                    NaN   \n",
       "15                                                NaN                    NaN   \n",
       "16                                                NaN                    NaN   \n",
       "17      https://en.wikipedia.org/wiki/Electric_charge           CC BY-SA 3.0   \n",
       "18                                                NaN                    NaN   \n",
       "19                                                NaN                    NaN   \n",
       "20                                                NaN                    NaN   \n",
       "21                                                NaN                    NaN   \n",
       "22  https://simple.wikipedia.org/wiki/Electron_cry...  CC BY-SA 3.0 and GFDL   \n",
       "23                                                NaN                    NaN   \n",
       "24                                                NaN                    NaN   \n",
       "25                                                NaN                    NaN   \n",
       "26                                                NaN                    NaN   \n",
       "27                                                NaN                    NaN   \n",
       "28                                                NaN                    NaN   \n",
       "29                                                NaN                    NaN   \n",
       "\n",
       "    standard_error                                            excerpt  \\\n",
       "0         0.571404  The Dunwich horror itself came between Lammas ...   \n",
       "1         0.644398  The iron cylinder weighs 23 kilogrammes; but, ...   \n",
       "2         0.603819  As to surface-slope its measurement—from nearl...   \n",
       "3         0.606822  The tree is dioecious, bearing male catkins on...   \n",
       "4         0.567050  The copper even of such a conductor has been m...   \n",
       "5         0.588952  We have frequent inquiries as to the best mean...   \n",
       "6         0.643309  Molecular nanotechnology (MNT) is a technology...   \n",
       "7         0.609348  As soon as the plate is dry, a positive cliché...   \n",
       "8         0.549034  Reservoir.--An ordinary inverted bell-glass wi...   \n",
       "9         0.595653  The soil most suitable for the full developmen...   \n",
       "10        0.586590  They must, I think, be read in the light of th...   \n",
       "11        0.568356  For staining Bacillus tuberculosis the followi...   \n",
       "12        0.611192  It is hardly possible to imagine with what eag...   \n",
       "13        0.648481  The question now is as to a criterion, by whic...   \n",
       "14        0.593891  The hydrochloric acid gas passes into a vessel...   \n",
       "15        0.600152  As with consciousness and volition, so with su...   \n",
       "16        0.569281  Windows there are none in our houses: for the ...   \n",
       "17        0.642028  Charge is the fundamental property of forms of...   \n",
       "18        0.599598  Bull, John, a fine, fat, American-beef fed ind...   \n",
       "19        0.575624  An ordinary weathercock provided with datum po...   \n",
       "20        0.617688  \"The principal generators of incrustation in b...   \n",
       "21        0.649671  On the basis of the preceding comparisons some...   \n",
       "22        0.618258  Electron crystallography is a method to determ...   \n",
       "23        0.554593  The truth stands that the whole Sachsen-Anhalt...   \n",
       "24        0.554593  The truth stands that the whole Schleswig-Hols...   \n",
       "25        0.554326  These enemies of our agriculture were scarcely...   \n",
       "26        0.603355  The violations of truth, which dishonor poetry...   \n",
       "27        0.614036  Checks require a stamp of 4 cents, also promis...   \n",
       "28        0.556906  The Pintsch gas is prepared by the distillatio...   \n",
       "29        0.576591  The normal and characteristic occupations of t...   \n",
       "\n",
       "      target                                  excerpt_shortened  \\\n",
       "0  -3.672314  The Dunwich horror itself came between Lammas ...   \n",
       "1  -3.655626  The iron cylinder weighs 23 kilogrammes; but, ...   \n",
       "2  -3.641414  As to surface-slope its measurement—from nearl...   \n",
       "3  -3.638385  The tree is dioecious, bearing male catkins on...   \n",
       "4  -3.616792  The copper even of such a conductor has been m...   \n",
       "5  -3.591060  We have frequent inquiries as to the best mean...   \n",
       "6  -3.567280  Molecular nanotechnology (MNT) is a technology...   \n",
       "7  -3.546589  As soon as the plate is dry, a positive cliché...   \n",
       "8  -3.541709  Reservoir.--An ordinary inverted bell-glass wi...   \n",
       "9  -3.535558  The soil most suitable for the full developmen...   \n",
       "10 -3.530681  They must, I think, be read in the light of th...   \n",
       "11 -3.528620  For staining Bacillus tuberculosis the followi...   \n",
       "12 -3.502703  It is hardly possible to imagine with what eag...   \n",
       "13 -3.475567  The question now is as to a criterion, by whic...   \n",
       "14 -3.468586  The hydrochloric acid gas passes into a vessel...   \n",
       "15 -3.447497  As with consciousness and volition, so with su...   \n",
       "16 -3.423448  Windows there are none in our houses: for the ...   \n",
       "17 -3.414649  Charge is the fundamental property of forms of...   \n",
       "18 -3.408723  Bull, John, a fine, fat, American-beef fed ind...   \n",
       "19 -3.399402  An ordinary weathercock provided with datum po...   \n",
       "20 -3.384237  \"The principal generators of incrustation in b...   \n",
       "21 -3.364766  On the basis of the preceding comparisons some...   \n",
       "22 -3.354185  Electron crystallography is a method to determ...   \n",
       "23 -3.352197  The truth stands that the whole Sachsen-Anhalt...   \n",
       "24 -3.351956  The truth stands that the whole Schleswig-Hols...   \n",
       "25 -3.349074  These enemies of our agriculture were scarcely...   \n",
       "26 -3.344663  The violations of truth, which dishonor poetry...   \n",
       "27 -3.340712  Checks require a stamp of 4 cents, also promis...   \n",
       "28 -3.337050  The Pintsch gas is prepared by the distillatio...   \n",
       "29 -3.328119  The normal and characteristic occupations of t...   \n",
       "\n",
       "    normalized_target  normalized_target_check  \n",
       "0           -2.630326                -3.672314  \n",
       "1           -2.614153                -3.655626  \n",
       "2           -2.600379                -3.641414  \n",
       "3           -2.597443                -3.638385  \n",
       "4           -2.576517                -3.616792  \n",
       "5           -2.551578                -3.591060  \n",
       "6           -2.528531                -3.567280  \n",
       "7           -2.508478                -3.546589  \n",
       "8           -2.503749                -3.541709  \n",
       "9           -2.497788                -3.535558  \n",
       "10          -2.493061                -3.530681  \n",
       "11          -2.491063                -3.528620  \n",
       "12          -2.465946                -3.502703  \n",
       "13          -2.439646                -3.475567  \n",
       "14          -2.432881                -3.468586  \n",
       "15          -2.412443                -3.447497  \n",
       "16          -2.389134                -3.423448  \n",
       "17          -2.380607                -3.414649  \n",
       "18          -2.374864                -3.408723  \n",
       "19          -2.365830                -3.399402  \n",
       "20          -2.351133                -3.384237  \n",
       "21          -2.332262                -3.364766  \n",
       "22          -2.322007                -3.354185  \n",
       "23          -2.320081                -3.352197  \n",
       "24          -2.319847                -3.351956  \n",
       "25          -2.317054                -3.349074  \n",
       "26          -2.312779                -3.344663  \n",
       "27          -2.308950                -3.340712  \n",
       "28          -2.305401                -3.337050  \n",
       "29          -2.296746                -3.328119  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cd025a-a37c-4aaf-a192-ac278264a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9b62eb3-cedd-4629-a726-173588d6a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b48a945-271e-4c18-afac-e0a4c9194e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_df['target'],bins=100,kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01155bd0-8460-404e-8b2b-f8e72d5ef04d",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11427cac-5fa2-4449-bc11-c8b870fe3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53766f20-5598-499a-b1a6-0a6b19060132",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG():\n",
    "    batch_size = 24\n",
    "    max_len = 512\n",
    "    num_workers = 4\n",
    "    epochs = 30\n",
    "    pretrained_transformers_model = f'roberta-base'\n",
    "    target_field = 'normalized_target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3933dfcb-16b7-4691-b8ac-f1878b1cc1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CONFIG()\n",
    "cfg.model_name = 'roberta-base'\n",
    "cfg.num_folds = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dd067b3-c1a6-4c4a-900e-9499ca93b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.train_target_std = float(train_target_std)\n",
    "cfg.train_target_mean = float(train_target_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d7236c3-198b-440a-9f7b-fd714be1a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert Path(cfg.pretrained_transformers_model).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7bb8579-7374-48dd-9847-672dc57eff20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'roberta-base',\n",
       " 'num_folds': 6,\n",
       " 'train_target_std': 1.0318182993253338,\n",
       " 'train_target_mean': -0.9582950780537218}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17671f1f-4785-459f-98ec-ebcaacda6c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/commonlit/models/facebook’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir {MODELS_PATH}/facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce25d430-59b5-4d91-936f-589dc022dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MODELS_PATH}/{cfg.model_name}.yaml', 'w') as file:\n",
    "    documents = yaml.dump(vars(cfg), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab8b20-6c63-4d51-b6fe-39ff141ad03e",
   "metadata": {},
   "source": [
    "### Prepare Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42787f35-115b-4258-925f-6575f3063924",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df[cfg.target_field].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbbc9a60-4c04-447a-9ddc-e5125688f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = int(np.floor(np.log2(len(train_df))) + 1)\n",
    "train_df.loc[:, 'bins'] = pd.cut(train_df[cfg.target_field], bins=num_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0769b07-e9ea-42b7-95a6-5becf82dd824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">normalized_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bins</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.376825</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.956596</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.529617</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.125716</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.686932</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.255735</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.177576</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.593139</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.012727</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.429633</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.846363</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.264230</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     normalized_target      \n",
       "                  mean count\n",
       "bins                        \n",
       "0            -2.376825    43\n",
       "1            -1.956596    77\n",
       "2            -1.529617   169\n",
       "3            -1.125716   264\n",
       "4            -0.686932   365\n",
       "5            -0.255735   406\n",
       "6             0.177576   480\n",
       "7             0.593139   407\n",
       "8             1.012727   321\n",
       "9             1.429633   198\n",
       "10            1.846363    93\n",
       "11            2.264230    25"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[cfg.target_field, 'bins']].groupby(['bins']).agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31f7c55d-a9c2-4e76-a7ef-42acd56f7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=cfg.num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f70453a0-e80b-4953-95cb-fd06547c6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (t_, v_) in enumerate(kf.split(X=train_df, y=train_df.bins.values)):\n",
    "    train_df.loc[v_, 'kfold'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b311fb49-dfdc-43e7-a89a-182b731c879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['kfold'] = train_df['kfold'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de386c06-bb90-4034-b290-cd03cb61cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop('bins', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89e6e9bd-9ae3-4871-a47d-37ed129634fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>excerpt_shortened</th>\n",
       "      <th>normalized_target</th>\n",
       "      <th>normalized_target_check</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1142</td>\n",
       "      <td>493b80aa7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571404</td>\n",
       "      <td>The Dunwich horror itself came between Lammas ...</td>\n",
       "      <td>-3.672314</td>\n",
       "      <td>The Dunwich horror itself came between Lammas ...</td>\n",
       "      <td>-2.630326</td>\n",
       "      <td>-3.672314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1769</td>\n",
       "      <td>fe44cbd14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644398</td>\n",
       "      <td>The iron cylinder weighs 23 kilogrammes; but, ...</td>\n",
       "      <td>-3.655626</td>\n",
       "      <td>The iron cylinder weighs 23 kilogrammes; but, ...</td>\n",
       "      <td>-2.614153</td>\n",
       "      <td>-3.655626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1767</td>\n",
       "      <td>284eaa5ad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603819</td>\n",
       "      <td>As to surface-slope its measurement—from nearl...</td>\n",
       "      <td>-3.641414</td>\n",
       "      <td>As to surface-slope its measurement—from nearl...</td>\n",
       "      <td>-2.600379</td>\n",
       "      <td>-3.641414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1735</td>\n",
       "      <td>9e9eacb49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.606822</td>\n",
       "      <td>The tree is dioecious, bearing male catkins on...</td>\n",
       "      <td>-3.638385</td>\n",
       "      <td>The tree is dioecious, bearing male catkins on...</td>\n",
       "      <td>-2.597443</td>\n",
       "      <td>-3.638385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1854</td>\n",
       "      <td>466e33a64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567050</td>\n",
       "      <td>The copper even of such a conductor has been m...</td>\n",
       "      <td>-3.616792</td>\n",
       "      <td>The copper even of such a conductor has been m...</td>\n",
       "      <td>-2.576517</td>\n",
       "      <td>-3.616792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>2843</td>\n",
       "      <td>1080</td>\n",
       "      <td>016913371</td>\n",
       "      <td>https://www.africanstorybook.org/</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>0.599600</td>\n",
       "      <td>Grandma's garden was wonderful. It was full of...</td>\n",
       "      <td>1.466629</td>\n",
       "      <td>Grandma's garden was wonderful. It was full of...</td>\n",
       "      <td>2.350146</td>\n",
       "      <td>1.466629</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>2844</td>\n",
       "      <td>1028</td>\n",
       "      <td>7a1d484be</td>\n",
       "      <td>https://www.africanstorybook.org/</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>0.606997</td>\n",
       "      <td>More people came to the bus stop just before 9...</td>\n",
       "      <td>1.504669</td>\n",
       "      <td>More people came to the bus stop just before 9...</td>\n",
       "      <td>2.387013</td>\n",
       "      <td>1.504669</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>2845</td>\n",
       "      <td>822</td>\n",
       "      <td>8f35441e3</td>\n",
       "      <td>https://www.africanstorybook.org/#</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>0.624776</td>\n",
       "      <td>Every day, Emeka's father took him to school i...</td>\n",
       "      <td>1.562759</td>\n",
       "      <td>Every day, Emeka's father took him to school i...</td>\n",
       "      <td>2.443312</td>\n",
       "      <td>1.562759</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>2846</td>\n",
       "      <td>995</td>\n",
       "      <td>849971671</td>\n",
       "      <td>https://www.africanstorybook.org/</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>0.596349</td>\n",
       "      <td>For her last birthday, Sisanda had a special t...</td>\n",
       "      <td>1.590858</td>\n",
       "      <td>For her last birthday, Sisanda had a special t...</td>\n",
       "      <td>2.470545</td>\n",
       "      <td>1.590858</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>2847</td>\n",
       "      <td>2844</td>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>0.646900</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>1.654630</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>2.532350</td>\n",
       "      <td>1.654630</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2848 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index         id  \\\n",
       "0              0   1142  493b80aa7   \n",
       "1              1   1769  fe44cbd14   \n",
       "2              2   1767  284eaa5ad   \n",
       "3              3   1735  9e9eacb49   \n",
       "4              4   1854  466e33a64   \n",
       "...          ...    ...        ...   \n",
       "2843        2843   1080  016913371   \n",
       "2844        2844   1028  7a1d484be   \n",
       "2845        2845    822  8f35441e3   \n",
       "2846        2846    995  849971671   \n",
       "2847        2847   2844  25ca8f498   \n",
       "\n",
       "                                              url_legal       license  \\\n",
       "0                                                   NaN           NaN   \n",
       "1                                                   NaN           NaN   \n",
       "2                                                   NaN           NaN   \n",
       "3                                                   NaN           NaN   \n",
       "4                                                   NaN           NaN   \n",
       "...                                                 ...           ...   \n",
       "2843                  https://www.africanstorybook.org/     CC BY 4.0   \n",
       "2844                  https://www.africanstorybook.org/     CC BY 4.0   \n",
       "2845                 https://www.africanstorybook.org/#     CC BY 4.0   \n",
       "2846                  https://www.africanstorybook.org/     CC BY 4.0   \n",
       "2847  https://sites.ehe.osu.edu/beyondpenguins/files...  CC BY-SA 3.0   \n",
       "\n",
       "      standard_error                                            excerpt  \\\n",
       "0           0.571404  The Dunwich horror itself came between Lammas ...   \n",
       "1           0.644398  The iron cylinder weighs 23 kilogrammes; but, ...   \n",
       "2           0.603819  As to surface-slope its measurement—from nearl...   \n",
       "3           0.606822  The tree is dioecious, bearing male catkins on...   \n",
       "4           0.567050  The copper even of such a conductor has been m...   \n",
       "...              ...                                                ...   \n",
       "2843        0.599600  Grandma's garden was wonderful. It was full of...   \n",
       "2844        0.606997  More people came to the bus stop just before 9...   \n",
       "2845        0.624776  Every day, Emeka's father took him to school i...   \n",
       "2846        0.596349  For her last birthday, Sisanda had a special t...   \n",
       "2847        0.646900  When you think of dinosaurs and where they liv...   \n",
       "\n",
       "        target                                  excerpt_shortened  \\\n",
       "0    -3.672314  The Dunwich horror itself came between Lammas ...   \n",
       "1    -3.655626  The iron cylinder weighs 23 kilogrammes; but, ...   \n",
       "2    -3.641414  As to surface-slope its measurement—from nearl...   \n",
       "3    -3.638385  The tree is dioecious, bearing male catkins on...   \n",
       "4    -3.616792  The copper even of such a conductor has been m...   \n",
       "...        ...                                                ...   \n",
       "2843  1.466629  Grandma's garden was wonderful. It was full of...   \n",
       "2844  1.504669  More people came to the bus stop just before 9...   \n",
       "2845  1.562759  Every day, Emeka's father took him to school i...   \n",
       "2846  1.590858  For her last birthday, Sisanda had a special t...   \n",
       "2847  1.654630  When you think of dinosaurs and where they liv...   \n",
       "\n",
       "      normalized_target  normalized_target_check  kfold  \n",
       "0             -2.630326                -3.672314      0  \n",
       "1             -2.614153                -3.655626      0  \n",
       "2             -2.600379                -3.641414      0  \n",
       "3             -2.597443                -3.638385      0  \n",
       "4             -2.576517                -3.616792      0  \n",
       "...                 ...                      ...    ...  \n",
       "2843           2.350146                 1.466629      4  \n",
       "2844           2.387013                 1.504669      5  \n",
       "2845           2.443312                 1.562759      5  \n",
       "2846           2.470545                 1.590858      5  \n",
       "2847           2.532350                 1.654630      5  \n",
       "\n",
       "[2848 rows x 12 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2501f5b3-fffb-42c7-8fcb-9f026d32499d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">normalized_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kfold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.182338</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.104118</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.031442</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039392</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.103799</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.175294</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      normalized_target      \n",
       "                   mean count\n",
       "kfold                        \n",
       "0             -0.182338   475\n",
       "1             -0.104118   475\n",
       "2             -0.031442   475\n",
       "3              0.039392   475\n",
       "4              0.103799   474\n",
       "5              0.175294   474"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[cfg.target_field, 'kfold']].groupby(['kfold']).agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf3e0ed2-719d-483c-976f-173b19c8070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 5, 9, 0, 2, 8, 10, 1, 7, 3, 4, 6]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_list = list(range(num_bins))\n",
    "random.shuffle(bin_list)\n",
    "bin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8f50740-d161-4f65-a762-169977d95a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.983626244495507e-17"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['normalized_target'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370fd3a4-9d7b-42be-b31c-2f6c6c15a3a0",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d57cfc8c-551e-4f67-91f8-5aec7002d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_score(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "def rmse_score_2(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18e1c48e-da7e-4a1e-b91e-c9c5a262a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10)\n",
    "b = np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "883bd02c-7ab8-4fdc-bb6e-42e6c98a0935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3853643949192, 0.3853643949192)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_score(a, b), rmse_score_2(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d96bf65-b75e-468d-83e2-1d60792baebd",
   "metadata": {},
   "source": [
    "### Prepare train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e601b365-a123-4a1d-bd31-3e6aeeee2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = 'excerpt_shortened'\n",
    "\n",
    "def create_split(fold = [1]):\n",
    "    valid_df = train_df[train_df['kfold'].isin(fold)]\n",
    "    valid_text = valid_df[text_field].values\n",
    "    valid_target = valid_df[cfg.target_field].values\n",
    "    training_df = train_df[~train_df['kfold'].isin(fold)]\n",
    "    train_text = training_df[text_field].values\n",
    "    train_target = training_df[cfg.target_field].values\n",
    "    return train_text, train_target, valid_text, valid_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8575c418-6c76-409c-9ce2-f907a92764d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2373, 475)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text, train_target, valid_text, valid_target = create_split([0])\n",
    "len(train_text), len(valid_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8c638-0a6f-4b0b-baab-9422908e0343",
   "metadata": {},
   "source": [
    "### Prepare Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34addbcd-c989-475e-9c61-72b2e3ddf8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.pretrained_transformers_model)\n",
    "# Save the tokenizer so that you can download the files and move it to a Kaggle dataset.\n",
    "# tokenizer.save_pretrained(cfg.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10cea73f-5dd2-42f2-bc8d-454190f84655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>The Dunwich horror itself came between Lammas and the equinox in 1928, and Dr. Armitage was among those who witnessed its monstrous prologue. He had heard, meanwhile, of Whateley's grotesque trip to Cambridge, and of his frantic efforts to borrow or copy from the Necronomicon at the Widener Library. Those efforts had been in vain, since Armitage had issued warnings of the keenest intensity to all librarians having charge of the dreaded volume.\\nEarly in August the half-expected outcome developed, and in the small hours of the third Dr. Armitage was awakened suddenly by the wild, fierce cries of the savage watchdog on the college campus. Deep and terrible, the snarling, half-mad growls and barks continued; always in mounting volume, but with hideously significant pauses.\\nThe commutator is peculiar, consisting of only three segments of a copper ring, while in the simplest of other continuous current generators several times that number exist, and frequently 120! segments are to be found. These three segments are made so as to be removable in a moment for cleaning or replacement. They are mounted upon a metal support, and are surrounded on all sides by a free air space, and cannot, therefore, lose their insulated condition. This feature of air insulation is peculiar to this system, and is very important as a factor in the durability of the commutator. Besides this, the commutator is sustained by supports carried in flanges upon the shaft, which flanges, as an additional safeguard, are coated all over with hard rubber, one of the finest known insulators. It may be stated, without fear of contradiction, that no other commutator made is so thoroughly insulated and protected.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict = tokenizer(train_df[text_field].values[0],\n",
    "                                return_tensors='pt',\n",
    "                                max_length=cfg.max_len,\n",
    "                                padding='max_length',\n",
    "                                truncation=True,\n",
    "                                return_token_type_ids=True)\n",
    "decoded = tokenizer.decode(encoded_dict[\"input_ids\"].squeeze())\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6caf9132-a5d5-460f-8584-5f22a87abac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1ee2410-2ce9-46c8-9e93-9aeb14bf6bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eab4041e-0b2d-41d6-94a3-6e3646e3427f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d093a87-1edd-4e0b-8545-5e97a91a7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(t):\n",
    "    return t.flatten().long()\n",
    "\n",
    "class CommonLitDataset(nn.Module):\n",
    "    def __init__(self, text, target, tokenizer, max_len=128):\n",
    "        self.excerpt = text\n",
    "        self.target = target\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],\n",
    "                                return_tensors='pt',\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length',\n",
    "                                truncation=True)\n",
    "        return InputFeatures(input_ids=convert_to_list(encode['input_ids']),\n",
    "                      attention_mask=convert_to_list(encode['attention_mask']),\n",
    "                      label=torch.tensor(self.target[idx]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a038b280-5d95-4a08-b3c6-da445770f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_valid_ds(tokenizer, train_text, train_target, valid_text, valid_target):\n",
    "    train_ds = CommonLitDataset(train_text, train_target, tokenizer, cfg.max_len)\n",
    "    valid_ds = CommonLitDataset(valid_text, valid_target, tokenizer, cfg.max_len)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13ae453b-84a5-4a13-a2fc-00e5562a95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode.keys(), target.shape, encode['input_ids'].shape, encode['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ddf1a2cf-19d7-42c1-ac39-83a8bb2655bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode['input_ids'][0].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed362b-cd1d-4d1a-b343-6ecddef7e324",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "863d53eb-7874-4bef-8b6a-d542749f7dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# You can use a Transformer model of your choice.\n",
    "# transformer_model = DistilBertModel.from_pretrained(cfg.pretrained_transformers_model)\n",
    "transformer_model = AutoModelForSequenceClassification.from_pretrained(cfg.pretrained_transformers_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1f92770-7aa6-4ff0-b656-33f6b4d00bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer_out = transformer_model(input_ids=encode['input_ids'].squeeze(), attention_mask=encode['attention_mask'].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2551c8b-5ac7-4af0-bb2f-854c7fc45559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(transformer_out)['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "814e739b-f7a1-405c-b13c-31e6b93dcdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mean(transformer_out.last_hidden_state, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ecf50196-0a69-4db8-bc17-b967f89911f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_layer = nn.Linear(768, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "132b7585-1f6e-4482-9b92-9a7260618888",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = AutoConfig.from_pretrained(cfg.pretrained_transformers_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "403ef922-6ede-4fc1-83a1-fe12b85a517b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.6.0\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f2dbb7c-e9b8-47af-a124-32c5a5448ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f5021054-9f67-404b-9a03-a34db81e49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel\n",
    "\n",
    "class CommonLitModel(PreTrainedModel):\n",
    "    def __init__(self):\n",
    "        super(PreTrainedModel, self).__init__()\n",
    "        self.transformer_model = AutoModel.from_pretrained(cfg.pretrained_transformers_model)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.config = AutoConfig.from_pretrained(cfg.pretrained_transformers_model)\n",
    "        self.layer_norm = nn.LayerNorm(self.config.hidden_size)\n",
    "        self.out = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.layer_norm)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        if isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        transformer_out = self.transformer_model(input_ids=input_ids.squeeze(), attention_mask=attention_mask.squeeze(), \n",
    "                                                 output_hidden_states=True)\n",
    "        x = transformer_out.pooler_output\n",
    "#         x = transformer_out.last_hidden_state[:, 0, :] # N, C, X\n",
    "#         x = torch.mean(transformer_out.hidden_states[-2], axis=1)\n",
    "#         x2 = torch.mean(transformer_out.encoder_hidden_states[-2], axis=1)\n",
    "#         x = torch.cat([x, x2], axis=1)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "    def floating_point_ops(self, inputs: Dict[str, Union[torch.Tensor, Any]]):\n",
    "        \"\"\"\n",
    "        For models that inherit from :class:`~transformers.PreTrainedModel`, uses that method to compute the number of\n",
    "        floating point operations for every backward + forward pass. If using another model, either implement such a\n",
    "        method in the model or subclass and override this method.\n",
    "        Args:\n",
    "            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "        Returns:\n",
    "            :obj:`int`: The number of floating-point operations.\n",
    "        \"\"\"\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68bf7bb6-efa1-438e-8f61-a60f46df79e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = CommonLitModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d402996c-e965-4047-a39c-68a2c465280c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict.token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "87795a72-d4cc-4481-a07c-28cbbdf32458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict.token_type_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a04bb94-1364-4709-bc76-878d6d9ced4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = transformer_model.cuda()\n",
    "sample_out = transformer_model(encoded_dict.input_ids.cuda(), encoded_dict.attention_mask.cuda(), encoded_dict.token_type_ids.cuda(), output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e942e16-3653-4a19-b765-f3ef11189391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'hidden_states'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e210ebf4-4ada-4a98-aa85-fb77e052e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_x = torch.mean(sample_out.hidden_states[-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e3aba55a-5465-4871-99ef-1f5a9c51d00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1536])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([sample_x, sample_x], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5a065ca-db17-413f-ab59-0f40c9e6b22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34428a20-76bf-4dcd-ad14-c008f82c7123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out.hidden_states[-1].shape, sample_out.hidden_states[-1][:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0504d936-bebe-4fbd-90b5-b5b990501033",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = create_train_valid_ds(tokenizer, train_text, train_target, valid_text, valid_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bfcf10f5-20f7-4f97-9a17-35c63ec4915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7265d3b2-f7cc-48aa-9f2b-66987f10182f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512]), torch.Size([1, 512]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.attention_mask.unsqueeze(0).shape, encoded_dict.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2b825b57-a244-4a0c-be59-102e9c8f2760",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_out = transformer_model(encode.input_ids.unsqueeze(0).cuda(), encode.attention_mask.unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d826f6b-79c8-447d-9d78-df79b99e6655",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "68a48686-ddb0-4046-ab70-40e16117bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b8fa4e6a-6a87-4860-b33a-075c5e693a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "kl_loss = nn.KLDivLoss(reduction = 'batchmean')\n",
    "\n",
    "def loss_fct(yhat, y):\n",
    "    return criterion(yhat, y) * 0.7 + 0.3 * kl_loss(yhat, y)\n",
    "\n",
    "loss_fct = nn.MSELoss()\n",
    "\n",
    "def loss_fct(yhat, y):\n",
    "    return torch.sqrt(criterion(yhat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4a861b0e-1207-454d-81fa-4a684a153d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_args(fold):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(MODELS_PATH/f\"{cfg.model_name.replace('/', '_')}-{fold}\"),\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        per_device_train_batch_size=cfg.batch_size,\n",
    "        per_device_eval_batch_size=cfg.batch_size,\n",
    "        num_train_epochs=cfg.epochs,\n",
    "        logging_strategy=\"epoch\",\n",
    "        logging_first_step=True,\n",
    "        save_steps=40000,\n",
    "        fp16=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_total_limit = 3,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='mse',\n",
    "        greater_is_better=False,\n",
    "        gradient_accumulation_steps=1,\n",
    "        learning_rate=5e-5\n",
    "    )\n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb7ea1ed-e72f-43fd-aa2c-b1645480f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    return {'mse': mean_squared_error(logits, labels), 'rmse': rmse_score_2(logits, labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "325a9194-570e-4c1b-83c7-eb0fe7723de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.pretrained_transformers_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "826b6f17-dd24-4be8-8644-4e4e40712f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "class CommonLitTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        input_ids = inputs.pop(\"input_ids\")\n",
    "        attention_mask = inputs.pop(\"attention_mask\")\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        logits = outputs\n",
    "        loss = loss_fct(logits.flatten(),\n",
    "                        labels.float().flatten())\n",
    "        zero_cat = torch.zeros([1, 1]).to(outputs.device)\n",
    "        return (loss, torch.cat([zero_cat, outputs])) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "004a6849-c4d7-40e9-98e9-eacd947f550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/commonlit/models/{cfg.model_name.replace('/', '_')}-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d3822354-7ee5-4f5f-93e6-f357a0157811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_bins 0: [11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgilf\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">frosty-puddle-68</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base/runs/2e4knzuz\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base/runs/2e4knzuz</a><br/>\n",
       "                Run data is saved locally in <code>/home/commonlit/notebooks/wandb/run-20210618_093551-2e4knzuz</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1386' max='2970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1386/2970 12:49 < 14:40, 1.80 it/s, Epoch 14/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.766200</td>\n",
       "      <td>0.528551</td>\n",
       "      <td>0.299893</td>\n",
       "      <td>0.547625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.556200</td>\n",
       "      <td>0.390989</td>\n",
       "      <td>0.160862</td>\n",
       "      <td>0.401076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.385343</td>\n",
       "      <td>0.161275</td>\n",
       "      <td>0.401591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.403800</td>\n",
       "      <td>0.474764</td>\n",
       "      <td>0.236813</td>\n",
       "      <td>0.486634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.491414</td>\n",
       "      <td>0.260298</td>\n",
       "      <td>0.510194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.346600</td>\n",
       "      <td>0.541803</td>\n",
       "      <td>0.323101</td>\n",
       "      <td>0.568420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.322900</td>\n",
       "      <td>0.589074</td>\n",
       "      <td>0.399202</td>\n",
       "      <td>0.631825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.309400</td>\n",
       "      <td>0.475152</td>\n",
       "      <td>0.248312</td>\n",
       "      <td>0.498309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.641253</td>\n",
       "      <td>0.438663</td>\n",
       "      <td>0.662316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.269100</td>\n",
       "      <td>0.547502</td>\n",
       "      <td>0.318922</td>\n",
       "      <td>0.564732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.459391</td>\n",
       "      <td>0.232350</td>\n",
       "      <td>0.482027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.261400</td>\n",
       "      <td>0.404134</td>\n",
       "      <td>0.173701</td>\n",
       "      <td>0.416775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>0.598365</td>\n",
       "      <td>0.399401</td>\n",
       "      <td>0.631981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.509247</td>\n",
       "      <td>0.290176</td>\n",
       "      <td>0.538680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args.output_dir /home/commonlit/models/roberta-base-0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_checkpoint /home/commonlit/models/roberta-base-0/checkpoint-198\n",
      "result {'eval_loss': 0.3909892737865448, 'eval_mse': 0.16086174547672272, 'eval_rmse': 0.40107572078704834, 'eval_runtime': 5.6677, 'eval_samples_per_second': 83.809, 'epoch': 14.0, 'eval_mem_cpu_alloc_delta': 8192, 'eval_mem_gpu_alloc_delta': 0, 'eval_mem_cpu_peaked_delta': 0, 'eval_mem_gpu_peaked_delta': 1246061056}\n",
      "train_bins 1: [5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2e4knzuz) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 704<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.03MB of 0.03MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210618_093551-2e4knzuz/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210618_093551-2e4knzuz/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.2276</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/epoch</td><td>14.0</td></tr><tr><td>train/global_step</td><td>1386</td></tr><tr><td>_runtime</td><td>782</td></tr><tr><td>_timestamp</td><td>1624009733</td></tr><tr><td>_step</td><td>30</td></tr><tr><td>eval/loss</td><td>0.39099</td></tr><tr><td>eval/mse</td><td>0.16086</td></tr><tr><td>eval/rmse</td><td>0.40108</td></tr><tr><td>eval/runtime</td><td>5.6677</td></tr><tr><td>eval/samples_per_second</td><td>83.809</td></tr><tr><td>train/train_runtime</td><td>770.1582</td></tr><tr><td>train/train_samples_per_second</td><td>3.856</td></tr><tr><td>train/total_flos</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>eval/loss</td><td>▅▁▁▃▄▅▇▃█▅▃▂▇▄▁</td></tr><tr><td>eval/mse</td><td>▅▁▁▃▄▅▇▃█▅▃▁▇▄▁</td></tr><tr><td>eval/rmse</td><td>▅▁▁▃▄▅▇▄█▅▃▁▇▅▁</td></tr><tr><td>eval/runtime</td><td>▁▄▆▆▇▇▇▆▇▆▇▆▆█▆</td></tr><tr><td>eval/samples_per_second</td><td>█▅▃▃▂▂▂▃▂▃▂▂▃▁▃</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">frosty-puddle-68</strong>: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base/runs/2e4knzuz\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base/runs/2e4knzuz</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2e4knzuz). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">radiant-gorge-69</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base/runs/3b1ngskv\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base/runs/3b1ngskv</a><br/>\n",
       "                Run data is saved locally in <code>/home/commonlit/notebooks/wandb/run-20210618_094904-3b1ngskv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1485' max='2970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1485/2970 13:46 < 13:47, 1.80 it/s, Epoch 15/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.642331</td>\n",
       "      <td>0.438686</td>\n",
       "      <td>0.662334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.589900</td>\n",
       "      <td>0.406958</td>\n",
       "      <td>0.182210</td>\n",
       "      <td>0.426860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.496800</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.175040</td>\n",
       "      <td>0.418378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.448900</td>\n",
       "      <td>0.477280</td>\n",
       "      <td>0.243517</td>\n",
       "      <td>0.493474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.627085</td>\n",
       "      <td>0.438083</td>\n",
       "      <td>0.661878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.531099</td>\n",
       "      <td>0.328275</td>\n",
       "      <td>0.572953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.429746</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.452671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.310100</td>\n",
       "      <td>0.465822</td>\n",
       "      <td>0.231045</td>\n",
       "      <td>0.480672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.567944</td>\n",
       "      <td>0.342741</td>\n",
       "      <td>0.585441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.442688</td>\n",
       "      <td>0.217455</td>\n",
       "      <td>0.466321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.189399</td>\n",
       "      <td>0.435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.261400</td>\n",
       "      <td>0.420946</td>\n",
       "      <td>0.196518</td>\n",
       "      <td>0.443303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.257900</td>\n",
       "      <td>0.408902</td>\n",
       "      <td>0.191290</td>\n",
       "      <td>0.437367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.429126</td>\n",
       "      <td>0.210610</td>\n",
       "      <td>0.458923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.505059</td>\n",
       "      <td>0.290470</td>\n",
       "      <td>0.538953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args.output_dir /home/commonlit/models/roberta-base-1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_checkpoint /home/commonlit/models/roberta-base-1/checkpoint-297\n",
      "result {'eval_loss': 0.3990003764629364, 'eval_mse': 0.17504021525382996, 'eval_rmse': 0.418378084897995, 'eval_runtime': 5.6724, 'eval_samples_per_second': 83.739, 'epoch': 15.0, 'eval_mem_cpu_alloc_delta': 0, 'eval_mem_gpu_alloc_delta': 0, 'eval_mem_cpu_peaked_delta': 0, 'eval_mem_gpu_peaked_delta': 1246061056}\n",
      "train_bins 2: [9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3b1ngskv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 767<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.03MB of 0.03MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210618_094904-3b1ngskv/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210618_094904-3b1ngskv/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.2172</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/epoch</td><td>15.0</td></tr><tr><td>train/global_step</td><td>1485</td></tr><tr><td>_runtime</td><td>839</td></tr><tr><td>_timestamp</td><td>1624010587</td></tr><tr><td>_step</td><td>32</td></tr><tr><td>eval/loss</td><td>0.399</td></tr><tr><td>eval/mse</td><td>0.17504</td></tr><tr><td>eval/rmse</td><td>0.41838</td></tr><tr><td>eval/runtime</td><td>5.6724</td></tr><tr><td>eval/samples_per_second</td><td>83.739</td></tr><tr><td>train/train_runtime</td><td>826.6053</td></tr><tr><td>train/train_samples_per_second</td><td>3.593</td></tr><tr><td>train/total_flos</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>█▆▄▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>eval/loss</td><td>█▁▁▃█▅▂▃▆▂▁▂▁▂▄▁</td></tr><tr><td>eval/mse</td><td>█▁▁▃█▅▂▂▅▂▁▂▁▂▄▁</td></tr><tr><td>eval/rmse</td><td>█▁▁▃█▅▂▃▆▂▁▂▂▂▄▁</td></tr><tr><td>eval/runtime</td><td>▅▃▄▇▃█▃▅▃▄▄▇▅▇▅▁</td></tr><tr><td>eval/samples_per_second</td><td>▄▆▅▂▆▁▆▄▆▅▅▂▄▂▄█</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">radiant-gorge-69</strong>: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base/runs/3b1ngskv\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base/runs/3b1ngskv</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3b1ngskv). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">iconic-voice-70</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base/runs/3kzn0v6q\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base/runs/3kzn0v6q</a><br/>\n",
       "                Run data is saved locally in <code>/home/commonlit/notebooks/wandb/run-20210618_100318-3kzn0v6q</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1881' max='2970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1881/2970 17:24 < 10:05, 1.80 it/s, Epoch 19/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.833400</td>\n",
       "      <td>0.480693</td>\n",
       "      <td>0.254882</td>\n",
       "      <td>0.504858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.578500</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.182877</td>\n",
       "      <td>0.427641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.497200</td>\n",
       "      <td>0.423085</td>\n",
       "      <td>0.197200</td>\n",
       "      <td>0.444072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.472170</td>\n",
       "      <td>0.235363</td>\n",
       "      <td>0.485142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.409300</td>\n",
       "      <td>0.390653</td>\n",
       "      <td>0.169903</td>\n",
       "      <td>0.412193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.354700</td>\n",
       "      <td>0.528513</td>\n",
       "      <td>0.292019</td>\n",
       "      <td>0.540387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.374061</td>\n",
       "      <td>0.153582</td>\n",
       "      <td>0.391895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.317800</td>\n",
       "      <td>0.409339</td>\n",
       "      <td>0.181334</td>\n",
       "      <td>0.425833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>0.393785</td>\n",
       "      <td>0.162407</td>\n",
       "      <td>0.402997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.440923</td>\n",
       "      <td>0.202613</td>\n",
       "      <td>0.450126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.284300</td>\n",
       "      <td>0.420063</td>\n",
       "      <td>0.196927</td>\n",
       "      <td>0.443765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.264500</td>\n",
       "      <td>0.425937</td>\n",
       "      <td>0.196116</td>\n",
       "      <td>0.442850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.255800</td>\n",
       "      <td>0.425653</td>\n",
       "      <td>0.208782</td>\n",
       "      <td>0.456927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.389123</td>\n",
       "      <td>0.164385</td>\n",
       "      <td>0.405444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.232700</td>\n",
       "      <td>0.451145</td>\n",
       "      <td>0.222989</td>\n",
       "      <td>0.472217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.383556</td>\n",
       "      <td>0.159958</td>\n",
       "      <td>0.399947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.216100</td>\n",
       "      <td>0.424646</td>\n",
       "      <td>0.190753</td>\n",
       "      <td>0.436753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.207600</td>\n",
       "      <td>0.431172</td>\n",
       "      <td>0.194470</td>\n",
       "      <td>0.440988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.213400</td>\n",
       "      <td>0.414102</td>\n",
       "      <td>0.179128</td>\n",
       "      <td>0.423235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args.output_dir /home/commonlit/models/roberta-base-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_checkpoint /home/commonlit/models/roberta-base-2/checkpoint-693\n",
      "result {'eval_loss': 0.37406057119369507, 'eval_mse': 0.15358179807662964, 'eval_rmse': 0.3918951451778412, 'eval_runtime': 5.6634, 'eval_samples_per_second': 83.872, 'epoch': 19.0, 'eval_mem_cpu_alloc_delta': 4096, 'eval_mem_gpu_alloc_delta': 0, 'eval_mem_cpu_peaked_delta': 0, 'eval_mem_gpu_peaked_delta': 1246061056}\n",
      "train_bins 3: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3kzn0v6q) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 829<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.03MB of 0.03MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210618_100318-3kzn0v6q/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210618_100318-3kzn0v6q/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.2134</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/epoch</td><td>19.0</td></tr><tr><td>train/global_step</td><td>1881</td></tr><tr><td>_runtime</td><td>1057</td></tr><tr><td>_timestamp</td><td>1624011659</td></tr><tr><td>_step</td><td>40</td></tr><tr><td>eval/loss</td><td>0.37406</td></tr><tr><td>eval/mse</td><td>0.15358</td></tr><tr><td>eval/rmse</td><td>0.3919</td></tr><tr><td>eval/runtime</td><td>5.6634</td></tr><tr><td>eval/samples_per_second</td><td>83.872</td></tr><tr><td>train/train_runtime</td><td>1045.2639</td></tr><tr><td>train/train_samples_per_second</td><td>2.841</td></tr><tr><td>train/total_flos</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>█▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>eval/loss</td><td>▆▂▃▅▂█▁▃▂▄▃▃▃▂▄▁▃▄▃▁</td></tr><tr><td>eval/mse</td><td>▆▂▃▅▂█▁▂▁▃▃▃▄▂▅▁▃▃▂▁</td></tr><tr><td>eval/rmse</td><td>▆▃▃▅▂█▁▃▂▄▃▃▄▂▅▁▃▃▂▁</td></tr><tr><td>eval/runtime</td><td>▃▄▆▅▅▅▃▄▅▇▇█▆▄▄▅▃▃▅▁</td></tr><tr><td>eval/samples_per_second</td><td>▆▅▃▄▄▄▆▅▄▂▂▁▃▅▅▄▆▆▄█</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">iconic-voice-70</strong>: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base/runs/3kzn0v6q\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base/runs/3kzn0v6q</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3kzn0v6q). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">swift-jazz-71</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base/runs/24rnq21q\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base/runs/24rnq21q</a><br/>\n",
       "                Run data is saved locally in <code>/home/commonlit/notebooks/wandb/run-20210618_102110-24rnq21q</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2475' max='2970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2475/2970 22:58 < 04:35, 1.79 it/s, Epoch 25/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.802100</td>\n",
       "      <td>0.451047</td>\n",
       "      <td>0.218222</td>\n",
       "      <td>0.467142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.591100</td>\n",
       "      <td>0.403373</td>\n",
       "      <td>0.171108</td>\n",
       "      <td>0.413652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.519700</td>\n",
       "      <td>0.425228</td>\n",
       "      <td>0.193390</td>\n",
       "      <td>0.439761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.433200</td>\n",
       "      <td>0.391444</td>\n",
       "      <td>0.165385</td>\n",
       "      <td>0.406676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.371600</td>\n",
       "      <td>0.501599</td>\n",
       "      <td>0.278326</td>\n",
       "      <td>0.527566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.378700</td>\n",
       "      <td>0.417586</td>\n",
       "      <td>0.190201</td>\n",
       "      <td>0.436120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.344500</td>\n",
       "      <td>0.424168</td>\n",
       "      <td>0.189774</td>\n",
       "      <td>0.435630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.459621</td>\n",
       "      <td>0.236005</td>\n",
       "      <td>0.485803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.428638</td>\n",
       "      <td>0.197259</td>\n",
       "      <td>0.444139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.432612</td>\n",
       "      <td>0.211150</td>\n",
       "      <td>0.459511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.270600</td>\n",
       "      <td>0.462137</td>\n",
       "      <td>0.232525</td>\n",
       "      <td>0.482208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.470948</td>\n",
       "      <td>0.245178</td>\n",
       "      <td>0.495155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.255200</td>\n",
       "      <td>0.368111</td>\n",
       "      <td>0.145810</td>\n",
       "      <td>0.381850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.442693</td>\n",
       "      <td>0.221243</td>\n",
       "      <td>0.470365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0.495480</td>\n",
       "      <td>0.267964</td>\n",
       "      <td>0.517653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.377239</td>\n",
       "      <td>0.153220</td>\n",
       "      <td>0.391434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.462861</td>\n",
       "      <td>0.237328</td>\n",
       "      <td>0.487163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.494571</td>\n",
       "      <td>0.257706</td>\n",
       "      <td>0.507648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>0.464043</td>\n",
       "      <td>0.230559</td>\n",
       "      <td>0.480166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.405790</td>\n",
       "      <td>0.175975</td>\n",
       "      <td>0.419494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.409348</td>\n",
       "      <td>0.183239</td>\n",
       "      <td>0.428064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.176200</td>\n",
       "      <td>0.397258</td>\n",
       "      <td>0.175143</td>\n",
       "      <td>0.418501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.172100</td>\n",
       "      <td>0.420157</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.440454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.158500</td>\n",
       "      <td>0.392444</td>\n",
       "      <td>0.167926</td>\n",
       "      <td>0.409788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.158800</td>\n",
       "      <td>0.404999</td>\n",
       "      <td>0.179084</td>\n",
       "      <td>0.423183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args.output_dir /home/commonlit/models/roberta-base-3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_checkpoint /home/commonlit/models/roberta-base-3/checkpoint-1287\n",
      "result {'eval_loss': 0.36811137199401855, 'eval_mse': 0.1458096206188202, 'eval_rmse': 0.3818502724170685, 'eval_runtime': 5.6963, 'eval_samples_per_second': 83.387, 'epoch': 25.0, 'eval_mem_cpu_alloc_delta': 0, 'eval_mem_gpu_alloc_delta': 0, 'eval_mem_cpu_peaked_delta': 0, 'eval_mem_gpu_peaked_delta': 1246061056}\n",
      "train_bins 4: [2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:24rnq21q) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 895<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.03MB of 0.03MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210618_102110-24rnq21q/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210618_102110-24rnq21q/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.1588</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/epoch</td><td>25.0</td></tr><tr><td>train/global_step</td><td>2475</td></tr><tr><td>_runtime</td><td>1391</td></tr><tr><td>_timestamp</td><td>1624013065</td></tr><tr><td>_step</td><td>52</td></tr><tr><td>eval/loss</td><td>0.36811</td></tr><tr><td>eval/mse</td><td>0.14581</td></tr><tr><td>eval/rmse</td><td>0.38185</td></tr><tr><td>eval/runtime</td><td>5.6963</td></tr><tr><td>eval/samples_per_second</td><td>83.387</td></tr><tr><td>train/train_runtime</td><td>1378.7248</td></tr><tr><td>train/train_samples_per_second</td><td>2.154</td></tr><tr><td>train/total_flos</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eval/loss</td><td>▅▃▄▂█▄▄▆▄▄▆▆▁▅█▁▆█▆▃▃▃▄▂▃▁</td></tr><tr><td>eval/mse</td><td>▅▂▄▂█▃▃▆▄▄▆▆▁▅▇▁▆▇▅▃▃▃▄▂▃▁</td></tr><tr><td>eval/rmse</td><td>▅▃▄▂█▄▄▆▄▅▆▆▁▅█▁▆▇▆▃▃▃▄▂▃▁</td></tr><tr><td>eval/runtime</td><td>▄▁▃▃▁▄▁▁▂▄▃▂█▂▂▃▁█▂▄█▄▅▅▆▄</td></tr><tr><td>eval/samples_per_second</td><td>▅█▆▆█▅██▇▅▆▇▁▇▇▆█▁█▅▁▅▄▄▃▅</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">swift-jazz-71</strong>: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base/runs/24rnq21q\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base/runs/24rnq21q</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:24rnq21q). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">hearty-paper-72</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base/runs/30xuwzos\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base/runs/30xuwzos</a><br/>\n",
       "                Run data is saved locally in <code>/home/commonlit/notebooks/wandb/run-20210618_104436-30xuwzos</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2475' max='2970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2475/2970 22:59 < 04:36, 1.79 it/s, Epoch 25/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.427108</td>\n",
       "      <td>0.197601</td>\n",
       "      <td>0.444524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.580400</td>\n",
       "      <td>0.445090</td>\n",
       "      <td>0.237567</td>\n",
       "      <td>0.487408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.480900</td>\n",
       "      <td>0.536644</td>\n",
       "      <td>0.347036</td>\n",
       "      <td>0.589097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.406200</td>\n",
       "      <td>0.557588</td>\n",
       "      <td>0.358804</td>\n",
       "      <td>0.599002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>0.667932</td>\n",
       "      <td>0.486211</td>\n",
       "      <td>0.697288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.369600</td>\n",
       "      <td>0.468470</td>\n",
       "      <td>0.252178</td>\n",
       "      <td>0.502174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.324100</td>\n",
       "      <td>0.416076</td>\n",
       "      <td>0.197949</td>\n",
       "      <td>0.444915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.403567</td>\n",
       "      <td>0.174562</td>\n",
       "      <td>0.417807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.527190</td>\n",
       "      <td>0.309227</td>\n",
       "      <td>0.556081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.462802</td>\n",
       "      <td>0.237531</td>\n",
       "      <td>0.487371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.530056</td>\n",
       "      <td>0.313930</td>\n",
       "      <td>0.560294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>0.425784</td>\n",
       "      <td>0.198310</td>\n",
       "      <td>0.445320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>0.390385</td>\n",
       "      <td>0.169642</td>\n",
       "      <td>0.411876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.410599</td>\n",
       "      <td>0.184951</td>\n",
       "      <td>0.430059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.224500</td>\n",
       "      <td>0.472943</td>\n",
       "      <td>0.237661</td>\n",
       "      <td>0.487505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.405712</td>\n",
       "      <td>0.179414</td>\n",
       "      <td>0.423573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.205200</td>\n",
       "      <td>0.438030</td>\n",
       "      <td>0.216175</td>\n",
       "      <td>0.464946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.464954</td>\n",
       "      <td>0.231182</td>\n",
       "      <td>0.480814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.429952</td>\n",
       "      <td>0.194467</td>\n",
       "      <td>0.440984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.460983</td>\n",
       "      <td>0.232824</td>\n",
       "      <td>0.482518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.421944</td>\n",
       "      <td>0.190094</td>\n",
       "      <td>0.435998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.419348</td>\n",
       "      <td>0.188979</td>\n",
       "      <td>0.434718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.183600</td>\n",
       "      <td>0.435175</td>\n",
       "      <td>0.202054</td>\n",
       "      <td>0.449504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.433764</td>\n",
       "      <td>0.203243</td>\n",
       "      <td>0.450825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.432760</td>\n",
       "      <td>0.203357</td>\n",
       "      <td>0.450951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args.output_dir /home/commonlit/models/roberta-base-4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_checkpoint /home/commonlit/models/roberta-base-4/checkpoint-1287\n",
      "result {'eval_loss': 0.390385240316391, 'eval_mse': 0.16964203119277954, 'eval_rmse': 0.41187623143196106, 'eval_runtime': 5.6531, 'eval_samples_per_second': 83.848, 'epoch': 25.0, 'eval_mem_cpu_alloc_delta': 0, 'eval_mem_gpu_alloc_delta': 0, 'eval_mem_cpu_peaked_delta': 0, 'eval_mem_gpu_peaked_delta': 1246061056}\n",
      "train_bins 5: [8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:30xuwzos) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 967<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.03MB of 0.03MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210618_104436-30xuwzos/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/commonlit/notebooks/wandb/run-20210618_104436-30xuwzos/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.1627</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/epoch</td><td>25.0</td></tr><tr><td>train/global_step</td><td>2475</td></tr><tr><td>_runtime</td><td>1391</td></tr><tr><td>_timestamp</td><td>1624014472</td></tr><tr><td>_step</td><td>52</td></tr><tr><td>eval/loss</td><td>0.39039</td></tr><tr><td>eval/mse</td><td>0.16964</td></tr><tr><td>eval/rmse</td><td>0.41188</td></tr><tr><td>eval/runtime</td><td>5.6531</td></tr><tr><td>eval/samples_per_second</td><td>83.848</td></tr><tr><td>train/train_runtime</td><td>1379.8792</td></tr><tr><td>train/train_samples_per_second</td><td>2.152</td></tr><tr><td>train/total_flos</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>█▅▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eval/loss</td><td>▂▂▅▅█▃▂▁▄▃▅▂▁▂▃▁▂▃▂▃▂▂▂▂▂▁</td></tr><tr><td>eval/mse</td><td>▂▃▅▅█▃▂▁▄▃▄▂▁▁▃▁▂▂▂▂▁▁▂▂▂▁</td></tr><tr><td>eval/rmse</td><td>▂▃▅▆█▃▂▁▅▃▅▂▁▁▃▁▂▃▂▃▂▂▂▂▂▁</td></tr><tr><td>eval/runtime</td><td>▃▆▃▃▅▅▆▂▄▇▇▂▆▇▄▄▂▃▃▂█▄▃▃▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▆▃▆▆▄▄▃▇▅▂▂▇▃▂▅▅▇▆▆▇▁▅▆▆▇█</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">hearty-paper-72</strong>: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base/runs/30xuwzos\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base/runs/30xuwzos</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:30xuwzos). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">celestial-bee-73</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/gilf/commonlit_roberta-base/runs/9ccnsldz\" target=\"_blank\">https://wandb.ai/gilf/commonlit_roberta-base/runs/9ccnsldz</a><br/>\n",
       "                Run data is saved locally in <code>/home/commonlit/notebooks/wandb/run-20210618_110803-9ccnsldz</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2376' max='2970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2376/2970 24:42 < 06:10, 1.60 it/s, Epoch 24/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.845300</td>\n",
       "      <td>0.575915</td>\n",
       "      <td>0.389345</td>\n",
       "      <td>0.623975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.596500</td>\n",
       "      <td>0.445307</td>\n",
       "      <td>0.259520</td>\n",
       "      <td>0.509431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.496300</td>\n",
       "      <td>0.422231</td>\n",
       "      <td>0.195115</td>\n",
       "      <td>0.441718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.380750</td>\n",
       "      <td>0.165696</td>\n",
       "      <td>0.407058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.365200</td>\n",
       "      <td>0.472163</td>\n",
       "      <td>0.239327</td>\n",
       "      <td>0.489211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>0.514642</td>\n",
       "      <td>0.309474</td>\n",
       "      <td>0.556304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.379941</td>\n",
       "      <td>0.155083</td>\n",
       "      <td>0.393806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.311100</td>\n",
       "      <td>0.395005</td>\n",
       "      <td>0.167740</td>\n",
       "      <td>0.409560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.273200</td>\n",
       "      <td>0.486560</td>\n",
       "      <td>0.258599</td>\n",
       "      <td>0.508526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>0.404346</td>\n",
       "      <td>0.178349</td>\n",
       "      <td>0.422314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.414913</td>\n",
       "      <td>0.185484</td>\n",
       "      <td>0.430678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.370116</td>\n",
       "      <td>0.148168</td>\n",
       "      <td>0.384926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.252200</td>\n",
       "      <td>0.369561</td>\n",
       "      <td>0.152008</td>\n",
       "      <td>0.389882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>0.477908</td>\n",
       "      <td>0.242956</td>\n",
       "      <td>0.492906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.441546</td>\n",
       "      <td>0.206422</td>\n",
       "      <td>0.454337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.449030</td>\n",
       "      <td>0.215256</td>\n",
       "      <td>0.463956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.214400</td>\n",
       "      <td>0.493419</td>\n",
       "      <td>0.262869</td>\n",
       "      <td>0.512707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.502506</td>\n",
       "      <td>0.267954</td>\n",
       "      <td>0.517643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.412348</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.421357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.444661</td>\n",
       "      <td>0.211975</td>\n",
       "      <td>0.460407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.378390</td>\n",
       "      <td>0.152335</td>\n",
       "      <td>0.390302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.383585</td>\n",
       "      <td>0.158250</td>\n",
       "      <td>0.397806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.386431</td>\n",
       "      <td>0.159563</td>\n",
       "      <td>0.399453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.167500</td>\n",
       "      <td>0.389853</td>\n",
       "      <td>0.164249</td>\n",
       "      <td>0.405277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args.output_dir /home/commonlit/models/roberta-base-5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_checkpoint /home/commonlit/models/roberta-base-5/checkpoint-1188\n",
      "result {'eval_loss': 0.37011590600013733, 'eval_mse': 0.1481679528951645, 'eval_rmse': 0.384925901889801, 'eval_runtime': 5.6604, 'eval_samples_per_second': 83.74, 'epoch': 24.0, 'eval_mem_cpu_alloc_delta': 0, 'eval_mem_gpu_alloc_delta': 0, 'eval_mem_cpu_peaked_delta': 0, 'eval_mem_gpu_peaked_delta': 1246061056}\n",
      "CPU times: user 2h 55min 27s, sys: 47min 12s, total: 3h 42min 40s\n",
      "Wall time: 1h 57min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "bin_step = 1\n",
    "bestmodels = []\n",
    "eval_rmses = []\n",
    "for i in range(0, cfg.num_folds, bin_step):\n",
    "    train_bins = bin_list[i:i+bin_step]\n",
    "    print('train_bins', f'{i}: {train_bins}')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.pretrained_transformers_model)\n",
    "    train_text, train_target, valid_text, valid_target = create_split([i])\n",
    "    train_ds, valid_ds = create_train_valid_ds(tokenizer, train_text, train_target, valid_text, valid_target)\n",
    "    training_args = create_training_args(i)\n",
    "    model = CommonLitModel()\n",
    "    wandb.init(project=f\"commonlit_{cfg.model_name.replace('/', '_')}\")\n",
    "    trainer = CommonLitTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=valid_ds,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=12)]\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    print('training_args.output_dir', training_args.output_dir)\n",
    "    tokenizer.save_pretrained(training_args.output_dir)\n",
    "    result = trainer.evaluate()\n",
    "    bestmodels.append(trainer.state.best_model_checkpoint)\n",
    "    print('best_model_checkpoint', trainer.state.best_model_checkpoint)\n",
    "    print('result', result)\n",
    "    eval_rmses.append(result['eval_rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5290ec66-8db4-4047-8fea-8d8f609c3d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mean best RSME losses', 0.3983335594336192)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Mean best RSME losses', np.array(eval_rmses).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a69a20-e7bd-4426-8394-9fe92ff4ceba",
   "metadata": {},
   "source": [
    "### Verify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1d2f26d-f0bc-4d35-b970-a18b100c97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "820cfbb0-36c6-41e7-b98e-d5ecc379c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model_offset = 0\n",
    "cfg.model_limit = 6\n",
    "cfg.n_folds = 5\n",
    "cfg.svm_kernels = ['rbf']\n",
    "cfg.svm_c = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "75a00952-6683-4536-b0ba-2ff0c60d55a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH/'train.csv')\n",
    "test_df = pd.read_csv(DATA_PATH/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f894e53d-7288-4609-a065-fdad630c250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_mean = train_df['target'].mean()\n",
    "train_target_std = train_df['target'].std()\n",
    "train_df['normalized_target'] = (train_df['target'] - train_target_mean) / train_target_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "34fe3330-3d2c-49c5-be98-69a13cf2a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = int(np.ceil(np.log2(len(train_df))))\n",
    "train_df['bins'] = pd.cut(train_df['target'], bins=num_bins, labels=False)\n",
    "bins = train_df['bins'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9508c0ef-984f-4af5-a283-88498c1dcabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.13 s, sys: 2.91 s, total: 12 s\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "inference_models = []\n",
    "for i in range(cfg.model_offset, cfg.model_limit):\n",
    "    print(f'Model {i}')\n",
    "    inference_model = CommonLitModel()\n",
    "    inference_model = inference_model.cuda()\n",
    "    inference_model.load_state_dict(torch.load(str(MODELS_PATH/f\"{cfg.model_name.replace('/', '_')}-{i}/pytorch_model.bin\")))\n",
    "    inference_model.eval();\n",
    "    inference_models.append(inference_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "386a6b85-3e21-44c5-bbe1-347c12d4c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = []\n",
    "for i in range(cfg.model_offset, cfg.model_limit):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODELS_PATH/f\"{cfg.model_name.replace('/', '_')}-{i}\")\n",
    "    tokenizers.append(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e6479666-2703-4691-831c-6a1a493924b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_embeddings(dl, transformer_model):\n",
    "    cls_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for input_features in tqdm(dl, total=len(dl)):\n",
    "            output = transformer_model(input_features['input_ids'].cuda(), input_features['attention_mask'].cuda())\n",
    "            cls_embeddings.extend(output[0][:,0,:].detach().cpu().numpy())\n",
    "    return np.array(cls_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9cb0cd48-b89a-4be9-b3f8-75f79133292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_score(X, y):\n",
    "    return np.sqrt(mean_squared_error(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c29dc0cb-b3d7-448c-8166-0716b76860c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(t):\n",
    "    return t.flatten().long()\n",
    "\n",
    "class CommonLitDataset(nn.Module):\n",
    "    def __init__(self, text, test_id, tokenizer, max_len=128):\n",
    "        self.excerpt = text\n",
    "        self.test_id = test_id\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],\n",
    "                                return_tensors='pt',\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length',\n",
    "                                truncation=True)\n",
    "        return {'input_ids': convert_to_list(encode['input_ids']),\n",
    "                'attention_mask': convert_to_list(encode['attention_mask']),\n",
    "                'id': self.test_id[idx]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c69fc14c-d0c9-486c-b15c-1aa2d81ad424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dl(df, tokenizer):\n",
    "    text = df['excerpt'].values\n",
    "    ids = df['id'].values\n",
    "    ds = CommonLitDataset(text, ids, tokenizer, max_len=cfg.max_len)\n",
    "    return DataLoader(ds, \n",
    "                      batch_size = cfg.batch_size,\n",
    "                      shuffle=False,\n",
    "                      num_workers = 1,\n",
    "                      pin_memory=True,\n",
    "                      drop_last=False\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "efdb532e-9f76-406b-ba60-c8991851faf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95ae8e8c84b45dc82efbac507d17474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756a59e13b174953b4bbe69cfd6646fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel rbf\n",
      "Fold 0 (2279,) (570,)\n",
      "rmse_score 0.45586839157188835\n",
      "Fold 1 (2279,) (570,)\n",
      "rmse_score 0.4478322583585632\n",
      "Fold 2 (2279,) (570,)\n",
      "rmse_score 0.42194573073894703\n",
      "Fold 3 (2279,) (570,)\n",
      "rmse_score 0.45930791776621377\n",
      "Fold 4 (2280,) (569,)\n",
      "rmse_score 0.4487610304594554\n",
      "Model 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecddc22743604dec8cd0aceca878d6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045c6112eafb40ad9c62926f1a0270c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel rbf\n",
      "Fold 0 (2279,) (570,)\n",
      "rmse_score 0.440093380855245\n",
      "Fold 1 (2279,) (570,)\n",
      "rmse_score 0.43635260136868004\n",
      "Fold 2 (2279,) (570,)\n",
      "rmse_score 0.39731368882278373\n",
      "Fold 3 (2279,) (570,)\n",
      "rmse_score 0.42903649269072247\n",
      "Fold 4 (2280,) (569,)\n",
      "rmse_score 0.4327009997142688\n",
      "Model 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91233a4ba084f7aaf59121a13e8d6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fdb75703ca406481f8ec68e3389f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel rbf\n",
      "Fold 0 (2279,) (570,)\n",
      "rmse_score 0.3744396651001222\n",
      "Fold 1 (2279,) (570,)\n",
      "rmse_score 0.3710565496121605\n",
      "Fold 2 (2279,) (570,)\n",
      "rmse_score 0.35116456718062067\n",
      "Fold 3 (2279,) (570,)\n",
      "rmse_score 0.38346864152628507\n",
      "Fold 4 (2280,) (569,)\n",
      "rmse_score 0.35713083310426047\n",
      "Model 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c348307278341babc6ccfc7ed3c8bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aec85a34d9043acb7e4c879dd4d7b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel rbf\n",
      "Fold 0 (2279,) (570,)\n",
      "rmse_score 0.33144303579245105\n",
      "Fold 1 (2279,) (570,)\n",
      "rmse_score 0.32696510782253535\n",
      "Fold 2 (2279,) (570,)\n",
      "rmse_score 0.30386175876974014\n",
      "Fold 3 (2279,) (570,)\n",
      "rmse_score 0.3318544195719857\n",
      "Fold 4 (2280,) (569,)\n",
      "rmse_score 0.3540809666938648\n",
      "Model 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b756be44374dd9ade140e4c735a8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca8f3d9e6cf435d9cf9393cded0fa0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel rbf\n",
      "Fold 0 (2279,) (570,)\n",
      "rmse_score 0.35405613246937295\n",
      "Fold 1 (2279,) (570,)\n",
      "rmse_score 0.3359799199774786\n",
      "Fold 2 (2279,) (570,)\n",
      "rmse_score 0.30837872718288134\n",
      "Fold 3 (2279,) (570,)\n",
      "rmse_score 0.3392986313094793\n",
      "Fold 4 (2280,) (569,)\n",
      "rmse_score 0.35957740224956375\n",
      "Model 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a4d0da3ded480b9152bca061e95ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0564bcfa64747deb76322b01c47595f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel rbf\n",
      "Fold 0 (2279,) (570,)\n",
      "rmse_score 0.34997106340500256\n",
      "Fold 1 (2279,) (570,)\n",
      "rmse_score 0.33984544147879536\n",
      "Fold 2 (2279,) (570,)\n",
      "rmse_score 0.29236355022547605\n",
      "Fold 3 (2279,) (570,)\n",
      "rmse_score 0.3565250897608336\n",
      "Fold 4 (2280,) (569,)\n",
      "rmse_score 0.3438175878353223\n",
      "FINAL RMSE score 0.37448305278050004\n",
      "CPU times: user 4min 3s, sys: 1.15 s, total: 4min 4s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_target = train_df['normalized_target'].values\n",
    "\n",
    "def calc_mean(scores):\n",
    "    return np.mean(np.array(scores), axis=0)\n",
    "\n",
    "final_scores = []\n",
    "final_rmse = []\n",
    "kernel_rmse_score_mean = []\n",
    "for j, (inference_model, tokenizer) in enumerate(zip(inference_models, tokenizers)):\n",
    "    print('Model', j)\n",
    "    test_dl = create_dl(test_df, tokenizer)\n",
    "    train_dl = create_dl(train_df, tokenizer)\n",
    "    transformer_model = inference_model.transformer_model if hasattr(inference_model, 'transformer_model') else inference_model\n",
    "    transformer_model.cuda()\n",
    "    X = get_cls_embeddings(train_dl, transformer_model)\n",
    "    y = train_target\n",
    "    X_test = get_cls_embeddings(test_dl, transformer_model)\n",
    "    kfold = StratifiedKFold(n_splits=cfg.n_folds)\n",
    "    scores = []\n",
    "    rmse_scores = []\n",
    "    for kernel in cfg.svm_kernels:\n",
    "        print('Kernel', kernel)\n",
    "        kernel_scores = []\n",
    "        kernel_rmse_scores = []\n",
    "        for k, (train_idx, valid_idx) in enumerate(kfold.split(X, bins)):\n",
    "\n",
    "            print('Fold', k, train_idx.shape, valid_idx.shape)\n",
    "            model = SVR(C=cfg.svm_c, kernel=kernel, gamma='auto')\n",
    "\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            prediction = model.predict(X_valid)\n",
    "            kernel_rmse_scores.append(rmse_score(prediction, y_valid))\n",
    "            print('rmse_score', kernel_rmse_scores[k])\n",
    "            kernel_scores.append(model.predict(X_test))\n",
    "        scores.append(calc_mean(kernel_scores))\n",
    "        kernel_rmse_score = calc_mean(kernel_rmse_scores)\n",
    "        kernel_rmse_score_mean.append(kernel_rmse_score)\n",
    "        rmse_scores.append(kernel_rmse_score)\n",
    "    final_scores.append(calc_mean(scores))\n",
    "    final_rmse.append(calc_mean(rmse_scores))\n",
    "print('FINAL RMSE score', np.mean(np.array(final_rmse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b0b649aa-784d-4dbf-83e4-252ca3f2bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_df['target'] - cfg.train_target_mean) / cfg.train_target_std\n",
    "final_scores_normalized = np.array(final_scores) * train_target_std + train_target_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e8fd46e8-1542-4a71-82ca-d6d4838d7470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16023469, 0.1619832 , 0.16729251, 0.17065812, 0.16978429,\n",
       "       0.17004719])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_rmse_score_mean_array = np.array(kernel_rmse_score_mean)\n",
    "kernel_rmse_score_mean_sum = np.sum(kernel_rmse_score_mean_array)\n",
    "prop_losses = kernel_rmse_score_mean_array / kernel_rmse_score_mean_sum\n",
    "prop_losses_sum = (1 - prop_losses).sum()\n",
    "weights = (1 - prop_losses) / prop_losses_sum\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "040b9381-2a90-4183-b305-59f6d233017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(scores, weights=weights):\n",
    "    return np.average(np.array(scores), weights=weights, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "03c0f5a2-7e63-4799-ad55-1a733b24a08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.9583035525693224, -0.9007549003323715)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_mean = train_df['target'].mean()\n",
    "final_scores_flat = calc_mean(final_scores_normalized).flatten()\n",
    "final_scores_mean = final_scores_flat.mean()\n",
    "target_mean, np.array(final_scores_normalized).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "345a4669-2c5d-49e6-8dec-f9abb9cd8153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.70057631, -0.34650067, -0.50153339, -2.47051331, -1.55480316,\n",
       "       -1.12997864,  0.39292791])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4614a6c5-af82-4b2c-bf5a-f1180109426a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.05673532906012657, -0.009455888176687762)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_diff = target_mean - final_scores_mean\n",
    "mean_diff, mean_diff / len(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29fd92a7-a55f-422a-bfae-7f475bd5f871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.757312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.403236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.558269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.527249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.611538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12537fe78</td>\n",
       "      <td>-1.186714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965e592c0</td>\n",
       "      <td>0.336193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.757312\n",
       "1  f0953f0a5 -0.403236\n",
       "2  0df072751 -0.558269\n",
       "3  04caf4e0c -2.527249\n",
       "4  0e63f8bea -1.611538\n",
       "5  12537fe78 -1.186714\n",
       "6  965e592c0  0.336193"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['target'] = final_scores_flat + mean_diff\n",
    "# sample_df['target'] = len(final_scores) / np.sum(1 / np.array(final_scores), axis=0) # harmonic mean\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c995ca-ff1f-4b43-a41c-28d6ec11fa97",
   "metadata": {},
   "source": [
    "### Prepare Packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4993d2b0-3c68-4241-b15d-c51e10ee788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_FOLDER = MODELS_PATH/cfg.model_name/'best'\n",
    "!rm -rf {BEST_MODEL_FOLDER}\n",
    "!mkdir -p {BEST_MODEL_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3e3faa7c-7b90-4fe2-aebf-cf9733a3674f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/commonlit/models/roberta-base/best')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BEST_MODEL_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "85f114e7-7e75-43d8-8c4c-6889f6393b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0th model\n",
      "Processing 1th model\n",
      "Processing 2th model\n",
      "Processing 3th model\n",
      "Processing 4th model\n",
      "Processing 5th model\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "def normalize_name(path_name):\n",
    "    return path_name.replace('', '')\n",
    "\n",
    "for i, best_model in enumerate(bestmodels):\n",
    "    print(f'Processing {i}th model')\n",
    "    best_model_file = f'{best_model}/pytorch_model.bin'\n",
    "    if Path(best_model_file).exists():\n",
    "        copyfile(best_model_file, f'{BEST_MODEL_FOLDER}/{i}_pytorch_model.bin')\n",
    "        tokenizer_path = Path(BEST_MODEL_FOLDER/f'tokenizer-{i}')\n",
    "        tokenizer_path.mkdir(parents=True, exist_ok=True)\n",
    "        assert tokenizer_path.exists()\n",
    "\n",
    "        tokenizer_json = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}-{i}/tokenizer.json'))\n",
    "        assert tokenizer_json.exists(), f'{tokenizer_json} does not exist'\n",
    "        copyfile(tokenizer_json, tokenizer_path/'tokenizer.json')\n",
    "\n",
    "        vocab_txt = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}-{i}/vocab.json'))\n",
    "        assert vocab_txt.exists(), f'{vocab_txt} does not exist'\n",
    "        copyfile(vocab_txt, tokenizer_path/'vocab.json')\n",
    "\n",
    "        config_json = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}-{i}/config.json'))\n",
    "        assert config_json.exists()\n",
    "        copyfile(config_json, tokenizer_path/'config.json')\n",
    "    else:\n",
    "        print(f'{best_model_file} is missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bc422f71-d671-4eca-82f4-0dd059b1200e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/commonlit/models/roberta-base/best_models.zip'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(MODELS_PATH/cfg.model_name/'best_models', 'zip', BEST_MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fc9d2659-6041-47d9-ba4c-a8ecade644a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best  best_models.zip  dataset-metadata.json  lm.zip  roberta-base.yaml\n"
     ]
    }
   ],
   "source": [
    "!ls {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ccbf7473-d8fd-4ff4-8b51-67028bc5d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv {MODELS_PATH}/{cfg.model_name}.yaml {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80bdcbd8-bed2-4ac9-91a0-93b35b0d2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model.save_pretrained(save_directory=f'{MODELS_PATH/cfg.model_name}/lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6ab5088d-df35-4b54-8de6-9c8a3bdc5054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1M\t/home/commonlit/models/roberta-base/best/tokenizer-0\n",
      "2.1M\t/home/commonlit/models/roberta-base/best/tokenizer-1\n",
      "2.1M\t/home/commonlit/models/roberta-base/best/tokenizer-2\n",
      "2.1M\t/home/commonlit/models/roberta-base/best/tokenizer-3\n",
      "2.1M\t/home/commonlit/models/roberta-base/best/tokenizer-4\n",
      "2.1M\t/home/commonlit/models/roberta-base/best/tokenizer-5\n",
      "2.8G\t/home/commonlit/models/roberta-base/best\n",
      "2.5G\t/home/commonlit/models/roberta-base/best_models.zip\n",
      "4.0K\t/home/commonlit/models/roberta-base/dataset-metadata.json\n",
      "476M\t/home/commonlit/models/roberta-base/lm\n",
      "421M\t/home/commonlit/models/roberta-base/lm.zip\n",
      "4.0K\t/home/commonlit/models/roberta-base/roberta-base.yaml\n"
     ]
    }
   ],
   "source": [
    "!du -h {MODELS_PATH/cfg.model_name}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "099a2e2d-e325-4b5f-ab68-71b1cc9d3af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/commonlit/models/roberta-base/lm.zip'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.make_archive(MODELS_PATH/cfg.model_name/'lm', 'zip', f'{MODELS_PATH/cfg.model_name}/lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4616c042-2877-470a-b227-948606188b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: /home/commonlit/models/roberta-base/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets init -p {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0e6984b-07d9-49e6-89b2-6066503bda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json_path = Path(MODELS_PATH/cfg.model_name/'dataset-metadata.json')\n",
    "assert dataset_json_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aafa049c-faa9-45da-af4f-554a2000f047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"INSERT_TITLE_HERE\",\n",
      "  \"id\": \"gilfernandes/INSERT_SLUG_HERE\",\n",
      "  \"licenses\": [\n",
      "    {\n",
      "      \"name\": \"CC0-1.0\"\n",
      "    }\n",
      "  ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat {str(dataset_json_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "faf108e8-c48c-4134-809b-6c775ef5b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"commonlit-roberta-base-standardized-duobert\",\n",
      "  \"id\": \"gilfernandes/commonlit-roberta-base-standardized-duobert\",\n",
      "  \"licenses\": [\n",
      "    {\n",
      "      \"name\": \"CC0-1.0\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(dataset_json_path, 'r') as f:\n",
    "    dataset_json = f.read()\n",
    "    dataset_json = dataset_json.replace('INSERT_TITLE_HERE', f'commonlit-{cfg.model_name}-standardized-duobert').replace('INSERT_SLUG_HERE', f'commonlit-{cfg.model_name}-standardized-duobert')\n",
    "    print(dataset_json)\n",
    "with(open(dataset_json_path, 'w')) as f:\n",
    "    f.write(dataset_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9877c0cb-0d80-43d6-a064-f929ad92b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {MODELS_PATH/cfg.model_name}/best\n",
    "!rm -rf {MODELS_PATH/cfg.model_name}/lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "851185dc-f532-4920-bfc0-39f36f0224bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file best_models.zip\n",
      "100%|██████████████████████████████████████| 2.46G/2.46G [04:20<00:00, 10.1MB/s]\n",
      "Upload successful: best_models.zip (2GB)\n",
      "Starting upload for file roberta-base.yaml\n",
      "100%|███████████████████████████████████████████| 114/114 [00:04<00:00, 25.5B/s]\n",
      "Upload successful: roberta-base.yaml (114B)\n",
      "Starting upload for file lm.zip\n",
      "100%|████████████████████████████████████████| 419M/419M [00:47<00:00, 9.27MB/s]\n",
      "Upload successful: lm.zip (419MB)\n",
      "Your private Dataset is being created. Please check progress at /api/v1/datasets/status//gilfernandes/commonlit-roberta-base-standardized-duobert\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets create -p {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19f40a-df46-4f1d-b247-c627e7cf091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets version -p {MODELS_PATH/cfg.model_name} -m \"Version with pooled output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffe0ba-8412-4616-a0a4-78c0b4552f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(str(MODELS_PATH/f'distilroberta-0/checkpoint-105/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e77de-3b71-408f-8d6c-25bae3e60f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = CommonLitModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de19b9-2d6b-41c1-a765-5c39551fe176",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859231b7-d595-463e-8ab7-1ac150193306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
