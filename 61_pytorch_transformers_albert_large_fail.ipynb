{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505e1dbe-f484-4304-8001-f10b5e0321c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef39394-5986-44bb-a6d6-84957a492ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import gc, warnings, random, time, os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c54d1-55c1-4701-9fde-692cf4450c84",
   "metadata": {},
   "source": [
    "### Folders and Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c75e83-4760-4511-bf31-a144abfc01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/home/commonlit/data/')\n",
    "assert DATA_PATH.exists()\n",
    "MODELS_PATH = Path('/home/commonlit/models/')\n",
    "if not MODELS_PATH.exists():\n",
    "    os.mkdir(MODELS_PATH)\n",
    "assert MODELS_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12796f2-c49a-4d32-9f38-0ecdec520539",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH/'train-orig.csv')\n",
    "test_df = pd.read_csv(DATA_PATH/'test.csv')\n",
    "sample_df = pd.read_csv(DATA_PATH/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836ed820-371a-48da-8412-db0701c05c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unnecessary(df):\n",
    "    df.drop(df[df['target'] == 0].index, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "remove_unnecessary(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179a075d-6fa8-4cf4-b703-db4f09c9649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2c26db523</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>So what is a solid? Solids are usually hard be...</td>\n",
       "      <td>0.189476</td>\n",
       "      <td>0.535648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>cd19e2350</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>The second state of matter we will discuss is ...</td>\n",
       "      <td>0.255209</td>\n",
       "      <td>0.483866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>15e2e9e7a</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Solids are shapes that you can actually touch....</td>\n",
       "      <td>-0.215279</td>\n",
       "      <td>0.514128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>5b990ba77</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Animals are made of many cells. They eat thing...</td>\n",
       "      <td>0.300779</td>\n",
       "      <td>0.512379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2833 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          url_legal  \\\n",
       "0     c12129c31                                                NaN   \n",
       "1     85aa80a4c                                                NaN   \n",
       "2     b69ac6792                                                NaN   \n",
       "3     dd1000b26                                                NaN   \n",
       "4     37c1b32fb                                                NaN   \n",
       "...         ...                                                ...   \n",
       "2828  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n",
       "2829  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2830  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2831  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n",
       "2832  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n",
       "\n",
       "           license                                            excerpt  \\\n",
       "0              NaN  When the young people returned to the ballroom...   \n",
       "1              NaN  All through dinner time, Mrs. Fayre was somewh...   \n",
       "2              NaN  As Roger had predicted, the snow departed as q...   \n",
       "3              NaN  And outside before the palace a great garden w...   \n",
       "4              NaN  Once upon a time there were Three Bears who li...   \n",
       "...            ...                                                ...   \n",
       "2828  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n",
       "2829  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n",
       "2830  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n",
       "2831  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n",
       "2832  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n",
       "\n",
       "        target  standard_error  \n",
       "0    -0.340259        0.464009  \n",
       "1    -0.315372        0.480805  \n",
       "2    -0.580118        0.476676  \n",
       "3    -1.054013        0.450007  \n",
       "4     0.247197        0.510845  \n",
       "...        ...             ...  \n",
       "2828  1.711390        0.646900  \n",
       "2829  0.189476        0.535648  \n",
       "2830  0.255209        0.483866  \n",
       "2831 -0.215279        0.514128  \n",
       "2832  0.300779        0.512379  \n",
       "\n",
       "[2833 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e79e005-5651-4414-9725-4567d3a9b300",
   "metadata": {},
   "source": [
    "### Config and Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07938c53-d840-4889-b9ab-3170c608137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(): \n",
    "    NUM_FOLDS = 6\n",
    "    NUM_EPOCHS = 3\n",
    "    BATCH_SIZE = 8\n",
    "    MAX_LEN = 248\n",
    "    EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
    "    MODEL_PATH = 'albert-xxlarge-v2'\n",
    "    TOKENIZER_PATH = 'albert-xxlarge-v2'\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    SEED = 1000\n",
    "    NUM_WORKERS = 2\n",
    "    MODEL_FOLDER = MODELS_PATH\n",
    "    model_name = 'albert-xxlarge-v2'\n",
    "    svm_kernels = ['rbf']\n",
    "    svm_c = 5\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b17b48-922f-4a27-8bb4-e641491d137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cfg.MODEL_FOLDER.exists():\n",
    "    os.mkdir(cfg.MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd067b3-c1a6-4c4a-900e-9499ca93b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab8b20-6c63-4d51-b6fe-39ff141ad03e",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978289c5-dc58-4be5-93d8-64566dad766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bins(train_df, num_bins):\n",
    "    train_df.loc[:, 'bins'] = pd.cut(train_df['target'], bins=num_bins, labels=False)\n",
    "    return num_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "131b79d6-1ec5-492b-930f-e4c75288bcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_bins(train_df, cfg.NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ee1b97-cef2-46cc-88d7-3f7ae737c3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bins</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "      <td>-3.125765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>441</td>\n",
       "      <td>-2.270279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>784</td>\n",
       "      <td>-1.412150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>886</td>\n",
       "      <td>-0.548095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>494</td>\n",
       "      <td>0.289716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>1.070237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count      mean\n",
       "bins                 \n",
       "0       122 -3.125765\n",
       "1       441 -2.270279\n",
       "2       784 -1.412150\n",
       "3       886 -0.548095\n",
       "4       494  0.289716\n",
       "5       106  1.070237"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(['bins'])['target'].agg(['count', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41922d13-b7af-4675-ae2d-c384025c86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42787f35-115b-4258-925f-6575f3063924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonLitDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, inference_only=False):\n",
    "        super().__init__()\n",
    "        self.df, self.inference_only = df, inference_only\n",
    "        self.text = df['excerpt'].tolist()\n",
    "        self.bins = df['bins']\n",
    "        if not inference_only:\n",
    "            self.target = torch.tensor(df['target'].to_numpy(), dtype = torch.float32)\n",
    "        \n",
    "        self.encoded = tokenizer.batch_encode_plus(\n",
    "            self.text,\n",
    "            padding = 'max_length',\n",
    "            max_length = cfg.MAX_LEN,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
    "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
    "        \n",
    "        if self.inference_only:\n",
    "            return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "        else:\n",
    "            target = self.target[index]\n",
    "            return {'input_ids': input_ids, 'attention_mask': attention_mask, 'target': target}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf2329ea-0c9a-407c-8c82-8f247ad9c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds = CommonLitDataset(train_df, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ee04e-2d41-46bc-89e0-c0b9476090cb",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2ef269a-01da-4555-bdb7-265d93940648",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, hidden_dim, num_targets):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        \n",
    "        self.hidden_layer = nn.Linear(in_features, hidden_dim)\n",
    "        self.final_layer = nn.Linear(hidden_dim, num_targets)\n",
    "        self.out_features = hidden_dim\n",
    "        \n",
    "    def forward(self, features):\n",
    "        att = torch.tanh(self.hidden_layer(features))\n",
    "        score = self.final_layer(att)\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "        return attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f7c88c-5970-4b12-bb86-ee4a5de126b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "class CommonLitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CommonLitModel, self).__init__()\n",
    "        config = AutoConfig.from_pretrained(cfg.MODEL_PATH)\n",
    "        config.update({\n",
    "            \"output_hidden_states\": True,\n",
    "            \"hidden_dropout_prob\": 0.0,\n",
    "            \"layer_norm_eps\": 1e-7\n",
    "        })\n",
    "        self.transformer_model = AutoModelForSequenceClassification.from_pretrained(cfg.MODEL_PATH, config=config)\n",
    "        self.attention = AttentionHead(config.hidden_size, 512, 1)\n",
    "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        hidden_states = self.transformer_model(input_ids=input_ids, attention_mask=attention_mask)['hidden_states']\n",
    "        last_layer_hidden_states = hidden_states[-1]\n",
    "        weights = self.attention(last_layer_hidden_states)\n",
    "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1) \n",
    "        return self.regressor(context_vector), context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aa41e86-dc36-43ae-a98f-e97cbc46fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-xxlarge-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.dense.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-xxlarge-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "sample_model = CommonLitModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01d5b219-2e0e-4485-99ef-3d2ffa0f149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for i, (name, param) in enumerate(sample_model.named_parameters()):\n",
    "    if(name.find('layer') > -1):\n",
    "        layer_name = re.sub(r'.+(layer\\.\\d+).+', r'\\1', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4929919-01cf-47e1-9e9c-3f040562b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 transformer_model.albert.embeddings.word_embeddings.weight torch.Size([30000, 128])\n",
      "1 transformer_model.albert.embeddings.position_embeddings.weight torch.Size([512, 128])\n",
      "2 transformer_model.albert.embeddings.token_type_embeddings.weight torch.Size([2, 128])\n",
      "3 transformer_model.albert.embeddings.LayerNorm.weight torch.Size([128])\n",
      "4 transformer_model.albert.embeddings.LayerNorm.bias torch.Size([128])\n",
      "5 transformer_model.albert.encoder.embedding_hidden_mapping_in.weight torch.Size([4096, 128])\n",
      "6 transformer_model.albert.encoder.embedding_hidden_mapping_in.bias torch.Size([4096])\n",
      "7 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight torch.Size([4096])\n",
      "8 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias torch.Size([4096])\n",
      "9 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight torch.Size([4096, 4096])\n",
      "10 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias torch.Size([4096])\n",
      "11 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight torch.Size([4096, 4096])\n",
      "12 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias torch.Size([4096])\n",
      "13 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight torch.Size([4096, 4096])\n",
      "14 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias torch.Size([4096])\n",
      "15 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight torch.Size([4096, 4096])\n",
      "16 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias torch.Size([4096])\n",
      "17 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight torch.Size([4096])\n",
      "18 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias torch.Size([4096])\n",
      "19 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight torch.Size([16384, 4096])\n",
      "20 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias torch.Size([16384])\n",
      "21 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight torch.Size([4096, 16384])\n",
      "22 transformer_model.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias torch.Size([4096])\n",
      "23 transformer_model.albert.pooler.weight torch.Size([4096, 4096])\n",
      "24 transformer_model.albert.pooler.bias torch.Size([4096])\n",
      "25 transformer_model.classifier.weight torch.Size([2, 4096])\n",
      "26 transformer_model.classifier.bias torch.Size([2])\n",
      "27 attention.hidden_layer.weight torch.Size([512, 4096])\n",
      "28 attention.hidden_layer.bias torch.Size([512])\n",
      "29 attention.final_layer.weight torch.Size([1, 512])\n",
      "30 attention.final_layer.bias torch.Size([1])\n",
      "31 regressor.weight torch.Size([1, 4096])\n",
      "32 regressor.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for i, (name, param) in enumerate(sample_model.named_parameters()):\n",
    "    print(i, name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c04f3dd-285e-4d70-8dd5-37fc2737ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input_ids = torch.randint(0, 1000, [4, 248])\n",
    "sample_attention_mask = torch.randint(0, 1000, [4, 248])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25dd4b70-f9d7-4c3a-81d6-da03dd8cf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_out = sample_model.transformer_model(sample_input_ids, sample_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a770a11a-485d-49b5-ae8a-9d5dccc90a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'hidden_states'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internal_out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "841fcfeb-6e75-40e5-8f82-265ed8da72d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]), 13, torch.Size([4, 248, 4096]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internal_out.logits.shape, len(internal_out.hidden_states), internal_out.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31ded8f5-d2ec-465f-88ca-317bf1954026",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_res = sample_model(sample_input_ids, sample_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea66f03e-eac6-478c-ab27-042d97ec1855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1]), torch.Size([4, 4096]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_res[0].shape, sample_res[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb86b195-8d45-41e2-9042-7007e416d916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 12.0305, -24.8167,  -8.0051,  ...,  -3.0728,  -1.4278,  -0.1048],\n",
       "        [  4.2832, -18.7329, -25.8748,  ...,  -9.5472,  -0.8887,   1.2327],\n",
       "        [ -7.4720,  -4.9036,   4.1109,  ...,  29.0668, -32.1302, -32.6248],\n",
       "        ...,\n",
       "        [  9.7457,   4.3581,  24.7495,  ..., -16.7221,  17.4259, -33.5271],\n",
       "        [ 16.3753, -29.9940, -10.5306,  ...,  38.5519,  30.1113,  -1.8203],\n",
       "        [ 10.0965,  15.2292,  12.9432,  ...,   3.4664,  16.1655,  26.1261]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.randn([8, 496, 768]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4bb67f-bc5f-4f90-8236-7f7eb949ec92",
   "metadata": {},
   "source": [
    "### Evaluation and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31f7c55d-a9c2-4e76-a7ef-42acd56f7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mse(model, data_loader):\n",
    "    model.eval()\n",
    "    mse_sum = 0\n",
    "    mse_loss = nn.MSELoss(reduction='sum')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, record in enumerate(data_loader):\n",
    "            input_ids, attention_mask, target = record['input_ids'].to(cfg.DEVICE), record['attention_mask'].to(cfg.DEVICE), record['target'].to(cfg.DEVICE)\n",
    "            pred, _ = model(input_ids, attention_mask)\n",
    "            mse_sum += mse_loss(pred.flatten().cpu(), target.cpu())\n",
    "            \n",
    "    return mse_sum / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b035767-df66-428f-a297-6db704dfc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "    result = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, record in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            input_ids, attention_mask = record['input_ids'].to(cfg.DEVICE), record['attention_mask'].to(cfg.DEVICE)\n",
    "            pred, _ = model(input_ids, attention_mask)\n",
    "            result.extend(pred.flatten().to(\"cpu\").tolist())\n",
    "            \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b90cd468-30bf-4362-824b-480820edb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dl = DataLoader(sample_ds, shuffle=False, batch_size=16, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0ec5d-7c5f-4a70-b792-7cb822fb35ce",
   "metadata": {},
   "source": [
    "### Optimizer and Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fd22b6b-dd73-41b1-81a4-af5e3261207e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2e-05, 0.0001, 5e-05)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5e-5 / 2.5, 5e-5 / 0.5, 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04c43c63-bdf7-4493-9f76-7b96b4c3f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(model, base_lr=5e-5, last_lr=None):\n",
    "    named_parameters = list(model.named_parameters())\n",
    "    attention_param_start = 27\n",
    "    regressor_param_start = 31\n",
    "    roberta_parameters = named_parameters[:attention_param_start]\n",
    "    attention_parameters = named_parameters[attention_param_start:regressor_param_start]\n",
    "    regressor_parameters = named_parameters[regressor_param_start:]\n",
    "    \n",
    "    attention_group = [params for (name, params) in attention_parameters]\n",
    "    regressor_group = [params for (name, params) in regressor_parameters]\n",
    "    \n",
    "    parameters = []\n",
    "    if last_lr is not None:\n",
    "        parameters.append({\"params\": attention_group, \"lr\": last_lr})\n",
    "        parameters.append({\"params\": regressor_group, \"lr\": last_lr})\n",
    "    else:\n",
    "        parameters.append({\"params\": attention_group})\n",
    "        parameters.append({\"params\": regressor_group})\n",
    "        \n",
    "    # Change on different models\n",
    "    layer_low_threshold = 7\n",
    "    layer_middle_threshold = 23\n",
    "    \n",
    "    for layer_num, (name, params) in enumerate(roberta_parameters):\n",
    "        weight_decay = 0.0 if 'bias' in name else 0.01\n",
    "        \n",
    "        lr = base_lr / 2.5 # 2e-05\n",
    "        if layer_num >= layer_middle_threshold:\n",
    "            lr = base_lr / 0.5 # 1e-4\n",
    "        elif layer_num >= layer_low_threshold:        \n",
    "            lr = base_lr    \n",
    "            \n",
    "        parameters.append({\"params\": params,\n",
    "                           \"weight_decay\": weight_decay,\n",
    "                           \"lr\": lr})\n",
    "        \n",
    "    return AdamW(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dd255e8-4568-4dfa-abd2-a429f9d545b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_optimizer = create_optimizer(sample_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4830178b-dff7-4635-a447-b9da1ca1ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler,SequentialSampler,RandomSampler,SubsetRandomSampler\n",
    "from collections import Counter\n",
    "\n",
    "class WeightedSampler(Sampler):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        \n",
    "        self.indices = list(range(len(dataset)))\n",
    "        self.num_samples = len(dataset)\n",
    "        self.label_to_count = dict(Counter(dataset.bins))\n",
    "        weights = [1/self.label_to_count[i] for i in dataset.bins]\n",
    "        \n",
    "        self.weights = torch.tensor(weights,dtype=torch.double)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        index = [self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True)]\n",
    "        while count < self.num_samples:\n",
    "            yield index[count]\n",
    "            count += 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7de8f75-5e7a-45d0-8029-ea6146ea2b48",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89e6e9bd-9ae3-4871-a47d-37ed129634fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_eval_period(val_rmse):\n",
    "    for rmse, period in cfg.EVAL_SCHEDULE:\n",
    "        if val_rmse >= rmse:\n",
    "            return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2501f5b3-fffb-42c7-8fcb-9f026d32499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_best(best_val_rmse, best_epoch, val_rmse, epoch, model, model_path):\n",
    "    if not best_val_rmse or val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_epoch = epoch\n",
    "        if not model_path.parent.exists():\n",
    "            os.makedirs(model_path.parent)\n",
    "        \n",
    "#         torch.save(model.state_dict(), model_path)\n",
    "        print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n",
    "    else:       \n",
    "        print(f\"Still best_val_rmse: {best_val_rmse:0.4}\",\n",
    "              f\"(from epoch {best_epoch})\")\n",
    "    return best_epoch, best_val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01766a88-69dc-4c6d-8dca-2950bdc7e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, scaler, model, model_path, train_loader, val_loader, optimizer, scheduler=None, num_epochs=cfg.NUM_EPOCHS):\n",
    "        self.scaler, self.model, self.model_path, self.train_loader, self.val_loader, self.optimizer, self.scheduler, self.num_epochs = (\n",
    "            scaler, model, model_path, train_loader, val_loader, optimizer, scheduler, num_epochs\n",
    "        )\n",
    "            \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        \n",
    "        mse_loss = nn.MSELoss(reduction='mean')\n",
    "        \n",
    "        best_val_rmse = None\n",
    "        best_epoch = 0\n",
    "        step = 0\n",
    "        last_eval_step = 0\n",
    "        eval_period = cfg.EVAL_SCHEDULE[0][1]    \n",
    "\n",
    "        start = time.time()\n",
    "        val_rmse_list = []\n",
    "        \n",
    "        tbar = tqdm(range(self.num_epochs), total=self.num_epochs)\n",
    "        for epoch in tbar:\n",
    "            tbar.set_description(f'Epoch: {epoch}')\n",
    "            val_rmse = None\n",
    "            for batch_num, record in enumerate(self.train_loader):\n",
    "                input_ids, attention_mask, target = record['input_ids'].to(cfg.DEVICE), record['attention_mask'].to(cfg.DEVICE), record['target'].to(cfg.DEVICE)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # Casts operations to mixed precision\n",
    "#                 with torch.cuda.amp.autocast():\n",
    "                pred, _ = self.model(input_ids, attention_mask)\n",
    "                mse = mse_loss(pred.flatten(), target)\n",
    "                    \n",
    "#                 self.scaler.scale(mse).backward()\n",
    "#                 self.scaler.step(self.optimizer)\n",
    "#                 self.scaler.update()\n",
    "                \n",
    "                mse.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                if self.scheduler:\n",
    "                    self.scheduler.step()\n",
    "                    \n",
    "                if step >= last_eval_step + eval_period:\n",
    "                    elapsed_seconds = time.time() - start\n",
    "                    num_steps = step - last_eval_step\n",
    "                    print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n",
    "                    last_eval_step = step\n",
    "                    \n",
    "                    val_rmse = np.sqrt(eval_mse(self.model, self.val_loader))\n",
    "                    print(f\"Epoch: {epoch} batch_num: {batch_num}\", f\"val_rmse: {val_rmse:0.4} \", end='')\n",
    "                    \n",
    "                    eval_period = choose_eval_period(val_rmse)\n",
    "                    best_epoch, best_val_rmse = serialize_best(best_val_rmse, best_epoch, val_rmse, epoch, self.model, self.model_path)\n",
    "                    val_rmse_list.append(val_rmse)\n",
    "                    start = time.time()\n",
    "                # Finish early on condition\n",
    "                if epoch > 0 and best_val_rmse > 0.6 or (len(val_rmse_list) > 5 and np.array(val_rmse_list).mean() > 1.0):\n",
    "                    return best_val_rmse\n",
    "                \n",
    "                step += 1\n",
    "        return best_val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2692dcf2-a5b7-404f-bb07-3feecb6ec40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=cfg.NUM_FOLDS, random_state=cfg.SEED, shuffle=True)\n",
    "splits = list(kfold.split(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6380179-d1bc-4102-b82f-73b7f8f1c5aa",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61471dbf-6953-4f76-a5ed-ca322f0bc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best results\n",
    "# Fold 0: \n",
    "# Fold 1: \n",
    "# Fold 2: \n",
    "# Fold 3: \n",
    "# Fold 4: \n",
    "# Fold 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1561a06c-a904-4056-8079-ba5cb737567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer\n",
    "\n",
    "fold = 0\n",
    "\n",
    "def objective(trial):\n",
    "    base_lr = trial.suggest_float(\"base_lr\", 3e-5, 5e-4, log=True)\n",
    "    last_lr = trial.suggest_float(\"last_lr\", 8e-5, 5e-3, log=True)\n",
    "    \n",
    "    print(f'##### Using fold {fold}')\n",
    "    print(f'##### Using base_lr {base_lr} last_lr {last_lr}')\n",
    "    \n",
    "    model_path = cfg.MODEL_FOLDER/f\"{cfg.model_name.replace('/', '_')}_{fold + 1}/model_{fold + 1}.pth\"\n",
    "    \n",
    "    set_random_seed(cfg.SEED + fold)\n",
    "    \n",
    "    tokenizer = AlbertTokenizer.from_pretrained(cfg.TOKENIZER_PATH)\n",
    "    \n",
    "    train_indices, val_indices = splits[fold]\n",
    "    train_dataset = CommonLitDataset(train_df.loc[train_indices], tokenizer)    \n",
    "    val_dataset = CommonLitDataset(train_df.loc[val_indices], tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE,\n",
    "                              drop_last=False, shuffle=True, num_workers=cfg.NUM_WORKERS)    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=cfg.BATCH_SIZE,\n",
    "                            drop_last=False, shuffle=False, num_workers=cfg.NUM_WORKERS)\n",
    "    \n",
    "    set_random_seed(cfg.SEED + fold)\n",
    "    \n",
    "    model = CommonLitModel().to(cfg.DEVICE)\n",
    "    \n",
    "    optimizer = create_optimizer(model, base_lr=base_lr, last_lr=last_lr)\n",
    "    \n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                                num_training_steps=cfg.NUM_EPOCHS * len(train_loader), \n",
    "                                                num_warmup_steps=50)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    trainer = Trainer(scaler, model, model_path, train_loader, val_loader, optimizer, scheduler = scheduler)\n",
    "    rmse_val = trainer.train()\n",
    "    \n",
    "    del trainer\n",
    "    del model\n",
    "    del tokenizer\n",
    "    del scaler\n",
    "    del optimizer\n",
    "    del train_loader\n",
    "    del val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return rmse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "efb49c7b-f2b8-4929-bd03-2b74c20361cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-20 10:45:11,849]\u001b[0m A new study created in memory with name: no-name-6e88f57d-2897-4b69-bad8-7b3971efa696\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Using fold 3\n",
      "##### Using base_lr 8.805424631281687e-05 last_lr 0.000752337528239587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-xxlarge-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.dense.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-xxlarge-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8405203f4c4189800376a5791983ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 42.0 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.019 New best_val_rmse: 1.019\n",
      "\n",
      "16 steps took 39.3 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8365 New best_val_rmse: 0.8365\n",
      "\n",
      "16 steps took 39.3 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.9776 Still best_val_rmse: 0.8365 (from epoch 0)\n",
      "\n",
      "16 steps took 39.2 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.049 Still best_val_rmse: 0.8365 (from epoch 0)\n",
      "\n",
      "16 steps took 39.0 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.091 Still best_val_rmse: 0.8365 (from epoch 0)\n",
      "\n",
      "16 steps took 38.8 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.9429 Still best_val_rmse: 0.8365 (from epoch 0)\n",
      "\n",
      "16 steps took 38.8 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.145 Still best_val_rmse: 0.8365 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-20 10:56:20,965]\u001b[0m Trial 0 finished with value: 0.8364642858505249 and parameters: {'base_lr': 8.805424631281687e-05, 'last_lr': 0.000752337528239587}. Best is trial 0 with value: 0.8364642858505249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 3\n",
      "##### Using base_lr 6.940927288507887e-05 last_lr 9.693996762376001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-xxlarge-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.dense.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-xxlarge-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9573b9218844bc89199cfa199aaee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    399\u001b[0m             )\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-6a39921bba9b>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mrmse_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-2da05a859acc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mval_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(3, len(list(splits))):\n",
    "    fold = i\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    print(\" Best value: \", study.best_trial.value)\n",
    "    print(\" Best params: \")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48210ee3-d9ea-4bab-b852-627f6f75ce0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-20 09:50:48,684]\u001b[0m A new study created in memory with name: no-name-fadf397a-cf59-44c0-9eae-668d9162bb50\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Using fold 0\n",
      "##### Using base_lr 0.0003626262232535029 last_lr 0.0011512218394495591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf1af3ddd394800a4d628fe682c2e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 14.4 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.058 New best_val_rmse: 1.058\n",
      "\n",
      "16 steps took 12.9 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.07 Still best_val_rmse: 1.058 (from epoch 0)\n",
      "\n",
      "16 steps took 12.9 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.034 New best_val_rmse: 1.034\n",
      "\n",
      "16 steps took 12.9 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.076 Still best_val_rmse: 1.034 (from epoch 0)\n",
      "\n",
      "16 steps took 12.9 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.036 Still best_val_rmse: 1.034 (from epoch 0)\n",
      "\n",
      "16 steps took 12.9 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.064 Still best_val_rmse: 1.034 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-20 09:53:15,384]\u001b[0m Trial 0 finished with value: 1.0335544347763062 and parameters: {'base_lr': 0.0003626262232535029, 'last_lr': 0.0011512218394495591}. Best is trial 0 with value: 1.0335544347763062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n",
      "##### Using base_lr 0.00023895773478201286 last_lr 0.000122110918172971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5bf63c7c1240149f718e9b39340999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 14.4 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.176 New best_val_rmse: 1.176\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8563 New best_val_rmse: 0.8563\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7705 New best_val_rmse: 0.7705\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.111 Still best_val_rmse: 0.7705 (from epoch 0)\n",
      "\n",
      "16 steps took 12.9 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.034 Still best_val_rmse: 0.7705 (from epoch 0)\n",
      "\n",
      "16 steps took 12.9 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.074 Still best_val_rmse: 0.7705 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-20 09:55:42,914]\u001b[0m Trial 1 finished with value: 0.7705181241035461 and parameters: {'base_lr': 0.00023895773478201286, 'last_lr': 0.000122110918172971}. Best is trial 1 with value: 0.7705181241035461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n",
      "##### Using base_lr 0.00020576298871587495 last_lr 9.716844058865107e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d15b7067d74c8e819e2465433b4f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 14.4 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.09 New best_val_rmse: 1.09\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.072 New best_val_rmse: 1.072\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.038 New best_val_rmse: 1.038\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.038 Still best_val_rmse: 1.038 (from epoch 0)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.038 Still best_val_rmse: 1.038 (from epoch 0)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.075 Still best_val_rmse: 1.038 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-20 09:58:10,595]\u001b[0m Trial 2 finished with value: 1.0376296043395996 and parameters: {'base_lr': 0.00020576298871587495, 'last_lr': 9.716844058865107e-05}. Best is trial 1 with value: 0.7705181241035461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n",
      "##### Using base_lr 5.496515884079063e-05 last_lr 0.0037970734087445328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f63aad04ff438a96481f55a082a8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 14.4 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9059 New best_val_rmse: 0.9059\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7554 New best_val_rmse: 0.7554\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7196 New best_val_rmse: 0.7196\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7066 New best_val_rmse: 0.7066\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6689 New best_val_rmse: 0.6689\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.782 Still best_val_rmse: 0.6689 (from epoch 0)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6326 New best_val_rmse: 0.6326\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.7558 Still best_val_rmse: 0.6326 (from epoch 0)\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5946 New best_val_rmse: 0.5946\n",
      "\n",
      "16 steps took 13.5 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5618 New best_val_rmse: 0.5618\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5877 Still best_val_rmse: 0.5618 (from epoch 1)\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.7986 Still best_val_rmse: 0.5618 (from epoch 1)\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.6351 Still best_val_rmse: 0.5618 (from epoch 1)\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5986 Still best_val_rmse: 0.5618 (from epoch 1)\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.6318 Still best_val_rmse: 0.5618 (from epoch 1)\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.7317 Still best_val_rmse: 0.5618 (from epoch 1)\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5869 Still best_val_rmse: 0.5618 (from epoch 1)\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.6499 Still best_val_rmse: 0.5618 (from epoch 1)\n",
      "\n",
      "16 steps took 13.5 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.6625 Still best_val_rmse: 0.5618 (from epoch 1)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5658 Still best_val_rmse: 0.5618 (from epoch 1)\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5638 Still best_val_rmse: 0.5618 (from epoch 1)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5476 New best_val_rmse: 0.5476\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5421 New best_val_rmse: 0.5421\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5447 Still best_val_rmse: 0.5421 (from epoch 2)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5392 New best_val_rmse: 0.5392\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5414 Still best_val_rmse: 0.5392 (from epoch 2)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5413 Still best_val_rmse: 0.5392 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-20 10:08:42,628]\u001b[0m Trial 3 finished with value: 0.5391799211502075 and parameters: {'base_lr': 5.496515884079063e-05, 'last_lr': 0.0037970734087445328}. Best is trial 3 with value: 0.5391799211502075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n",
      "##### Using base_lr 3.17879661864344e-05 last_lr 0.0007968750291217295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69226198b3fd45639ee102995fdc549e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 14.4 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.063 New best_val_rmse: 1.063\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7862 New best_val_rmse: 0.7862\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6887 New best_val_rmse: 0.6887\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7461 Still best_val_rmse: 0.6887 (from epoch 0)\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6839 New best_val_rmse: 0.6839\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.7494 Still best_val_rmse: 0.6839 (from epoch 0)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6309 New best_val_rmse: 0.6309\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.664 Still best_val_rmse: 0.6309 (from epoch 0)\n",
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.6156 New best_val_rmse: 0.6156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-20 10:12:22,288]\u001b[0m Trial 4 finished with value: 0.6155527234077454 and parameters: {'base_lr': 3.17879661864344e-05, 'last_lr': 0.0007968750291217295}. Best is trial 3 with value: 0.5391799211502075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n",
      "##### Using base_lr 4.502200767968494e-05 last_lr 0.00017517919394227307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c3b5a976ab4a8386ee6006b162179e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 14.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.038 New best_val_rmse: 1.038\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.9577 New best_val_rmse: 0.9577\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.9542 New best_val_rmse: 0.9542\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.035 Still best_val_rmse: 0.9542 (from epoch 0)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.031 Still best_val_rmse: 0.9542 (from epoch 0)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.024 Still best_val_rmse: 0.9542 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-20 10:14:50,570]\u001b[0m Trial 5 finished with value: 0.9541854858398438 and parameters: {'base_lr': 4.502200767968494e-05, 'last_lr': 0.00017517919394227307}. Best is trial 3 with value: 0.5391799211502075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n",
      "##### Using base_lr 0.00012081541161374568 last_lr 0.0005259371533251995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e24ff4f93c45ca8709c3b1b22ba64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 14.5 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.028 New best_val_rmse: 1.028\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.9844 New best_val_rmse: 0.9844\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.312 Still best_val_rmse: 0.9844 (from epoch 0)\n",
      "\n",
      "16 steps took 12.9 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.103 Still best_val_rmse: 0.9844 (from epoch 0)\n",
      "\n",
      "16 steps took 12.9 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.06 Still best_val_rmse: 0.9844 (from epoch 0)\n",
      "\n",
      "16 steps took 12.9 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.035 Still best_val_rmse: 0.9844 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-20 10:17:18,039]\u001b[0m Trial 6 finished with value: 0.9844056367874146 and parameters: {'base_lr': 0.00012081541161374568, 'last_lr': 0.0005259371533251995}. Best is trial 3 with value: 0.5391799211502075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n",
      "##### Using base_lr 0.0001609461052262704 last_lr 0.0043803091231005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7617f135ee6c4dd096a5092e10dce5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 14.5 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.773 New best_val_rmse: 0.773\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.111 Still best_val_rmse: 0.773 (from epoch 0)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.101 Still best_val_rmse: 0.773 (from epoch 0)\n",
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.238 Still best_val_rmse: 0.773 (from epoch 0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 3):\n",
    "    fold = i\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    print(\" Best value: \", study.best_trial.value)\n",
    "    print(\" Best params: \")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d360e24c-6ca3-4486-b2ba-27d94cb53913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 08:03:49,382]\u001b[0m A new study created in memory with name: no-name-1b0b8ca5-bbbf-4207-94cf-b93393383ddf\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Using fold 2\n",
      "##### Using base_lr 0.0003552760540192187 last_lr 0.0038043117994500013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02c54b03e074c5ea30427493bf70662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 14.0 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.485 New best_val_rmse: 1.485\n",
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.086 New best_val_rmse: 1.086\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.38 Still best_val_rmse: 1.086 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.098 Still best_val_rmse: 1.086 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.076 New best_val_rmse: 1.076\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.101 Still best_val_rmse: 1.076 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 08:06:17,801]\u001b[0m Trial 0 finished with value: 1.07648766040802 and parameters: {'base_lr': 0.0003552760540192187, 'last_lr': 0.0038043117994500013}. Best is trial 0 with value: 1.07648766040802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 4.57661676399739e-05 last_lr 0.0004619110960854159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622b46a84dbc4cf2b1b7c8cd860ef61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.163 New best_val_rmse: 1.163\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7022 New best_val_rmse: 0.7022\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.722 Still best_val_rmse: 0.7022 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7581 Still best_val_rmse: 0.7022 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6998 New best_val_rmse: 0.6998\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.8563 Still best_val_rmse: 0.6998 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.5806 New best_val_rmse: 0.5806\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5663 New best_val_rmse: 0.5663\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.6074 Still best_val_rmse: 0.5663 (from epoch 0)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5729 Still best_val_rmse: 0.5663 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5415 New best_val_rmse: 0.5415\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5579 Still best_val_rmse: 0.5415 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5352 New best_val_rmse: 0.5352\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5709 Still best_val_rmse: 0.5352 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5532 Still best_val_rmse: 0.5352 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5115 New best_val_rmse: 0.5115\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5016 New best_val_rmse: 0.5016\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5876 Still best_val_rmse: 0.5016 (from epoch 1)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5121 Still best_val_rmse: 0.5016 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5013 New best_val_rmse: 0.5013\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4975 New best_val_rmse: 0.4975\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4958 New best_val_rmse: 0.4958\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5004 Still best_val_rmse: 0.4958 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4951 New best_val_rmse: 0.4951\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.4993 Still best_val_rmse: 0.4951 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4988 Still best_val_rmse: 0.4951 (from epoch 2)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4968 Still best_val_rmse: 0.4951 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4973 Still best_val_rmse: 0.4951 (from epoch 2)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4964 Still best_val_rmse: 0.4951 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4963 Still best_val_rmse: 0.4951 (from epoch 2)\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4963 Still best_val_rmse: 0.4951 (from epoch 2)\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4963 Still best_val_rmse: 0.4951 (from epoch 2)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4963 Still best_val_rmse: 0.4951 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 08:16:55,396]\u001b[0m Trial 1 finished with value: 0.49514997005462646 and parameters: {'base_lr': 4.57661676399739e-05, 'last_lr': 0.0004619110960854159}. Best is trial 1 with value: 0.49514997005462646.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 0.00015686819593532155 last_lr 0.00043328911914538524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64bef6c81f440c0a0d1a7091fe7c633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.168 New best_val_rmse: 1.168\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.075 New best_val_rmse: 1.075\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.094 Still best_val_rmse: 1.075 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.076 Still best_val_rmse: 1.075 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.063 New best_val_rmse: 1.063\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.097 Still best_val_rmse: 1.063 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 08:19:22,081]\u001b[0m Trial 2 finished with value: 1.0626918077468872 and parameters: {'base_lr': 0.00015686819593532155, 'last_lr': 0.00043328911914538524}. Best is trial 1 with value: 0.49514997005462646.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 0.00011472919004535602 last_lr 0.0017329266411097838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf89fb65e4341f2a8baa9e9c92860fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8314 New best_val_rmse: 0.8314\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8183 New best_val_rmse: 0.8183\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.9561 Still best_val_rmse: 0.8183 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7514 New best_val_rmse: 0.7514\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.094 Still best_val_rmse: 0.7514 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.685 New best_val_rmse: 0.685\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.9212 Still best_val_rmse: 0.685 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6612 New best_val_rmse: 0.6612\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5858 New best_val_rmse: 0.5858\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.612 Still best_val_rmse: 0.5858 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.559 New best_val_rmse: 0.559\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.7623 Still best_val_rmse: 0.559 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5445 New best_val_rmse: 0.5445\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.603 Still best_val_rmse: 0.5445 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.54 New best_val_rmse: 0.54\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5216 New best_val_rmse: 0.5216\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5311 Still best_val_rmse: 0.5216 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.585 Still best_val_rmse: 0.5216 (from epoch 1)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5093 New best_val_rmse: 0.5093\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4989 New best_val_rmse: 0.4989\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.492 New best_val_rmse: 0.492\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4947 Still best_val_rmse: 0.492 (from epoch 2)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4894 New best_val_rmse: 0.4894\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4883 New best_val_rmse: 0.4883\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4876 New best_val_rmse: 0.4876\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4883 Still best_val_rmse: 0.4876 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4855 New best_val_rmse: 0.4855\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4912 Still best_val_rmse: 0.4855 (from epoch 2)\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4891 Still best_val_rmse: 0.4855 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.4925 Still best_val_rmse: 0.4855 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4853 New best_val_rmse: 0.4853\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4863 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4854 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4847 New best_val_rmse: 0.4847\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4897 Still best_val_rmse: 0.4847 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4907 Still best_val_rmse: 0.4847 (from epoch 2)\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4853 Still best_val_rmse: 0.4847 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4842 New best_val_rmse: 0.4842\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4845 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4848 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.485 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.485 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.485 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.485 Still best_val_rmse: 0.4842 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 08:31:34,364]\u001b[0m Trial 3 finished with value: 0.4841878116130829 and parameters: {'base_lr': 0.00011472919004535602, 'last_lr': 0.0017329266411097838}. Best is trial 3 with value: 0.4841878116130829.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 7.48556563348634e-05 last_lr 0.0004908001885823281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2165fa1b8a0b4543a911f44105b3a817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.5 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8619 New best_val_rmse: 0.8619\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.823 New best_val_rmse: 0.823\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.9686 Still best_val_rmse: 0.823 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.8791 Still best_val_rmse: 0.823 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6282 New best_val_rmse: 0.6282\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6561 Still best_val_rmse: 0.6282 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.5937 New best_val_rmse: 0.5937\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6405 Still best_val_rmse: 0.5937 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.6364 Still best_val_rmse: 0.5937 (from epoch 0)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5538 New best_val_rmse: 0.5538\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.523 New best_val_rmse: 0.523\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5402 Still best_val_rmse: 0.523 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5223 New best_val_rmse: 0.5223\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5645 Still best_val_rmse: 0.5223 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5381 Still best_val_rmse: 0.5223 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5073 New best_val_rmse: 0.5073\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.4885 New best_val_rmse: 0.4885\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 1 batch_num: 128 val_rmse: 0.5091 Still best_val_rmse: 0.4885 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 144 val_rmse: 0.4841 New best_val_rmse: 0.4841\n",
      "\n",
      "4 steps took 3.75 seconds\n",
      "Epoch: 2 batch_num: 0 val_rmse: 0.5608 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 16 val_rmse: 0.5027 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.4875 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.0 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.4871 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4863 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4856 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4857 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.03 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4881 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4877 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4862 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4861 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4881 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.0 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.488 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4904 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4858 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4866 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4864 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4867 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4865 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4864 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4865 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4864 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4863 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4866 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4868 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.487 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4869 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4869 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4869 Still best_val_rmse: 0.4841 (from epoch 1)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4869 Still best_val_rmse: 0.4841 (from epoch 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 08:44:27,165]\u001b[0m Trial 4 finished with value: 0.4840955138206482 and parameters: {'base_lr': 7.48556563348634e-05, 'last_lr': 0.0004908001885823281}. Best is trial 4 with value: 0.4840955138206482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 3.057078843312379e-05 last_lr 0.0009549025910941674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9185c676f5e4bca8cf5642d27692c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.027 New best_val_rmse: 1.027\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8379 New best_val_rmse: 0.8379\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.8646 Still best_val_rmse: 0.8379 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.8617 Still best_val_rmse: 0.8379 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6574 New best_val_rmse: 0.6574\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.604 New best_val_rmse: 0.604\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.5889 New best_val_rmse: 0.5889\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6779 Still best_val_rmse: 0.5889 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.585 New best_val_rmse: 0.585\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5649 New best_val_rmse: 0.5649\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.549 New best_val_rmse: 0.549\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5422 New best_val_rmse: 0.5422\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5289 New best_val_rmse: 0.5289\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5834 Still best_val_rmse: 0.5289 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5627 Still best_val_rmse: 0.5289 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5272 New best_val_rmse: 0.5272\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5071 New best_val_rmse: 0.5071\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.565 Still best_val_rmse: 0.5071 (from epoch 1)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5159 Still best_val_rmse: 0.5071 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5009 New best_val_rmse: 0.5009\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.501 Still best_val_rmse: 0.5009 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4994 New best_val_rmse: 0.4994\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.5052 Still best_val_rmse: 0.4994 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.5017 Still best_val_rmse: 0.4994 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.5006 Still best_val_rmse: 0.4994 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.5003 Still best_val_rmse: 0.4994 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4997 Still best_val_rmse: 0.4994 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4997 Still best_val_rmse: 0.4994 (from epoch 2)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4996 Still best_val_rmse: 0.4994 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 08:54:33,799]\u001b[0m Trial 5 finished with value: 0.49941134452819824 and parameters: {'base_lr': 3.057078843312379e-05, 'last_lr': 0.0009549025910941674}. Best is trial 4 with value: 0.4840955138206482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 0.00040362445879098193 last_lr 0.0006691421017614235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19064743632e4ff2811624f9ff3441c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.195 New best_val_rmse: 1.195\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.073 New best_val_rmse: 1.073\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.125 Still best_val_rmse: 1.073 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.073 Still best_val_rmse: 1.073 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.093 Still best_val_rmse: 1.073 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.069 New best_val_rmse: 1.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 08:57:00,663]\u001b[0m Trial 6 finished with value: 1.0692239999771118 and parameters: {'base_lr': 0.00040362445879098193, 'last_lr': 0.0006691421017614235}. Best is trial 4 with value: 0.4840955138206482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 6.285357587314095e-05 last_lr 0.0009582771584342349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d9e8e32cbc4536aef76aefae72f865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9278 New best_val_rmse: 0.9278\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8398 New best_val_rmse: 0.8398\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7729 New best_val_rmse: 0.7729\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.8208 Still best_val_rmse: 0.7729 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6994 New best_val_rmse: 0.6994\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.7497 Still best_val_rmse: 0.6994 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.5686 New best_val_rmse: 0.5686\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5668 New best_val_rmse: 0.5668\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5898 Still best_val_rmse: 0.5668 (from epoch 0)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5908 Still best_val_rmse: 0.5668 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5339 New best_val_rmse: 0.5339\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5347 Still best_val_rmse: 0.5339 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5238 New best_val_rmse: 0.5238\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5602 Still best_val_rmse: 0.5238 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5455 Still best_val_rmse: 0.5238 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.509 New best_val_rmse: 0.509\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.4943 New best_val_rmse: 0.4943\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 1 batch_num: 132 val_rmse: 0.496 Still best_val_rmse: 0.4943 (from epoch 1)\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5572 Still best_val_rmse: 0.4943 (from epoch 1)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5018 Still best_val_rmse: 0.4943 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4939 New best_val_rmse: 0.4939\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.4905 New best_val_rmse: 0.4905\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4914 Still best_val_rmse: 0.4905 (from epoch 2)\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4874 New best_val_rmse: 0.4874\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4916 Still best_val_rmse: 0.4874 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4853 New best_val_rmse: 0.4853\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4882 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4965 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4911 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4872 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4879 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4864 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4863 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4868 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.0 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4869 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4859 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4853 New best_val_rmse: 0.4853\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.485 New best_val_rmse: 0.485\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4854 Still best_val_rmse: 0.485 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4858 Still best_val_rmse: 0.485 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4859 Still best_val_rmse: 0.485 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4857 Still best_val_rmse: 0.485 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4855 Still best_val_rmse: 0.485 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4854 Still best_val_rmse: 0.485 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4854 Still best_val_rmse: 0.485 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 09:09:19,818]\u001b[0m Trial 7 finished with value: 0.4850175082683563 and parameters: {'base_lr': 6.285357587314095e-05, 'last_lr': 0.0009582771584342349}. Best is trial 4 with value: 0.4840955138206482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 0.0002314602967657199 last_lr 9.851194497387779e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096f9fb495134eb59e849d63a69c7407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.012 New best_val_rmse: 1.012\n",
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.08 Still best_val_rmse: 1.012 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.218 Still best_val_rmse: 1.012 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.071 Still best_val_rmse: 1.012 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.079 Still best_val_rmse: 1.012 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.086 Still best_val_rmse: 1.012 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 09:11:47,707]\u001b[0m Trial 8 finished with value: 1.0120644569396973 and parameters: {'base_lr': 0.0002314602967657199, 'last_lr': 9.851194497387779e-05}. Best is trial 4 with value: 0.4840955138206482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 5.400989949741741e-05 last_lr 0.00011196462142611125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79a71e74b314b7488befc71fbf33200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.09 New best_val_rmse: 1.09\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.9043 New best_val_rmse: 0.9043\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7569 New best_val_rmse: 0.7569\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.8641 Still best_val_rmse: 0.7569 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.731 New best_val_rmse: 0.731\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6332 New best_val_rmse: 0.6332\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.5742 New best_val_rmse: 0.5742\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.567 New best_val_rmse: 0.567\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5711 Still best_val_rmse: 0.567 (from epoch 0)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.6086 Still best_val_rmse: 0.567 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5425 New best_val_rmse: 0.5425\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5283 New best_val_rmse: 0.5283\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5226 New best_val_rmse: 0.5226\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5741 Still best_val_rmse: 0.5226 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5339 Still best_val_rmse: 0.5226 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5068 New best_val_rmse: 0.5068\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5 New best_val_rmse: 0.5\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5542 Still best_val_rmse: 0.5 (from epoch 1)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.4976 New best_val_rmse: 0.4976\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 16 val_rmse: 0.5067 Still best_val_rmse: 0.4976 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.4873 New best_val_rmse: 0.4873\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.4877 Still best_val_rmse: 0.4873 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4846 New best_val_rmse: 0.4846\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4842 New best_val_rmse: 0.4842\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4829 New best_val_rmse: 0.4829\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4867 Still best_val_rmse: 0.4829 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4842 Still best_val_rmse: 0.4829 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4846 Still best_val_rmse: 0.4829 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4928 Still best_val_rmse: 0.4829 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4841 Still best_val_rmse: 0.4829 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4826 New best_val_rmse: 0.4826\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.4857 Still best_val_rmse: 0.4826 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4854 Still best_val_rmse: 0.4826 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4837 Still best_val_rmse: 0.4826 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4822 New best_val_rmse: 0.4822\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4821 New best_val_rmse: 0.4821\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4815 New best_val_rmse: 0.4815\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.482 Still best_val_rmse: 0.4815 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.482 Still best_val_rmse: 0.4815 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4822 Still best_val_rmse: 0.4815 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4822 Still best_val_rmse: 0.4815 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4819 Still best_val_rmse: 0.4815 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4815 New best_val_rmse: 0.4815\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4815 New best_val_rmse: 0.4815\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4814 New best_val_rmse: 0.4814\n",
      "\n",
      "4 steps took 3.03 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4814 New best_val_rmse: 0.4814\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4814 New best_val_rmse: 0.4814\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4814 Still best_val_rmse: 0.4814 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 09:24:31,447]\u001b[0m Trial 9 finished with value: 0.4813994765281677 and parameters: {'base_lr': 5.400989949741741e-05, 'last_lr': 0.00011196462142611125}. Best is trial 9 with value: 0.4813994765281677.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 3.0349228979439946e-05 last_lr 8.356763721839508e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b32b54d95644161bdb07200ff5a49f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.07 New best_val_rmse: 1.07\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.9153 New best_val_rmse: 0.9153\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7683 New best_val_rmse: 0.7683\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7944 Still best_val_rmse: 0.7683 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6394 New best_val_rmse: 0.6394\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.5858 New best_val_rmse: 0.5858\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6185 Still best_val_rmse: 0.5858 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.634 Still best_val_rmse: 0.5858 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5752 New best_val_rmse: 0.5752\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.54 New best_val_rmse: 0.54\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.541 Still best_val_rmse: 0.54 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5286 New best_val_rmse: 0.5286\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.519 New best_val_rmse: 0.519\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5504 Still best_val_rmse: 0.519 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5179 New best_val_rmse: 0.5179\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5076 New best_val_rmse: 0.5076\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5021 New best_val_rmse: 0.5021\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5457 Still best_val_rmse: 0.5021 (from epoch 1)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5143 Still best_val_rmse: 0.5021 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4961 New best_val_rmse: 0.4961\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.4943 New best_val_rmse: 0.4943\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4915 New best_val_rmse: 0.4915\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4898 New best_val_rmse: 0.4898\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4896 New best_val_rmse: 0.4896\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4901 Still best_val_rmse: 0.4896 (from epoch 2)\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.5003 Still best_val_rmse: 0.4896 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.4932 Still best_val_rmse: 0.4896 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4924 Still best_val_rmse: 0.4896 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4895 New best_val_rmse: 0.4895\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4893 New best_val_rmse: 0.4893\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4888 New best_val_rmse: 0.4888\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4886 New best_val_rmse: 0.4886\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4885 New best_val_rmse: 0.4885\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4885 New best_val_rmse: 0.4885\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4882 New best_val_rmse: 0.4882\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4879 New best_val_rmse: 0.4879\n",
      "\n",
      "4 steps took 3.0 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4879 New best_val_rmse: 0.4879\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4879 New best_val_rmse: 0.4879\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4879 New best_val_rmse: 0.4879\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4879 New best_val_rmse: 0.4879\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4879 New best_val_rmse: 0.4879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 09:36:17,501]\u001b[0m Trial 10 finished with value: 0.487863153219223 and parameters: {'base_lr': 3.0349228979439946e-05, 'last_lr': 8.356763721839508e-05}. Best is trial 9 with value: 0.4813994765281677.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 7.604566984349528e-05 last_lr 0.00013966559365722486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07d02da735045f3abeee56ebce2b729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8743 New best_val_rmse: 0.8743\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7826 New best_val_rmse: 0.7826\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.9785 Still best_val_rmse: 0.7826 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7343 New best_val_rmse: 0.7343\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.9431 Still best_val_rmse: 0.7343 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6562 New best_val_rmse: 0.6562\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.7393 Still best_val_rmse: 0.6562 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5712 New best_val_rmse: 0.5712\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.576 Still best_val_rmse: 0.5712 (from epoch 0)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.579 Still best_val_rmse: 0.5712 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5346 New best_val_rmse: 0.5346\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5228 New best_val_rmse: 0.5228\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5427 Still best_val_rmse: 0.5228 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.6042 Still best_val_rmse: 0.5228 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5495 Still best_val_rmse: 0.5228 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5098 New best_val_rmse: 0.5098\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.4985 New best_val_rmse: 0.4985\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 1 batch_num: 132 val_rmse: 0.5183 Still best_val_rmse: 0.4985 (from epoch 1)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 2 batch_num: 0 val_rmse: 0.5855 Still best_val_rmse: 0.4985 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 16 val_rmse: 0.507 Still best_val_rmse: 0.4985 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.4842 New best_val_rmse: 0.4842\n",
      "\n",
      "4 steps took 3.0 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.4916 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4832 New best_val_rmse: 0.4832\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4823 New best_val_rmse: 0.4823\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4855 Still best_val_rmse: 0.4823 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4841 Still best_val_rmse: 0.4823 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4819 New best_val_rmse: 0.4819\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4867 Still best_val_rmse: 0.4819 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4799 New best_val_rmse: 0.4799\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 70 val_rmse: 0.48 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 74 val_rmse: 0.4811 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 78 val_rmse: 0.4808 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 82 val_rmse: 0.4838 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 86 val_rmse: 0.4818 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 90 val_rmse: 0.481 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 94 val_rmse: 0.481 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.0 seconds\n",
      "Epoch: 2 batch_num: 98 val_rmse: 0.4805 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 102 val_rmse: 0.4803 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.0 seconds\n",
      "Epoch: 2 batch_num: 106 val_rmse: 0.4806 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 110 val_rmse: 0.4806 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 114 val_rmse: 0.4804 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 118 val_rmse: 0.4803 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 122 val_rmse: 0.4803 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 126 val_rmse: 0.4805 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 130 val_rmse: 0.4806 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 134 val_rmse: 0.4806 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.0 seconds\n",
      "Epoch: 2 batch_num: 138 val_rmse: 0.4806 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 142 val_rmse: 0.4806 Still best_val_rmse: 0.4799 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 146 val_rmse: 0.4806 Still best_val_rmse: 0.4799 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 09:49:10,119]\u001b[0m Trial 11 finished with value: 0.47985729575157166 and parameters: {'base_lr': 7.604566984349528e-05, 'last_lr': 0.00013966559365722486}. Best is trial 11 with value: 0.47985729575157166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 8.661283535667235e-05 last_lr 0.00018490772170980246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540c86f8b9804114ad24e82cadecce94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8598 New best_val_rmse: 0.8598\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.893 Still best_val_rmse: 0.8598 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.9614 Still best_val_rmse: 0.8598 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.9419 Still best_val_rmse: 0.8598 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.7173 New best_val_rmse: 0.7173\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.8428 Still best_val_rmse: 0.7173 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.9031 Still best_val_rmse: 0.7173 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.043 Still best_val_rmse: 0.7173 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.031 Still best_val_rmse: 0.7173 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 09:52:43,132]\u001b[0m Trial 12 finished with value: 0.7173497080802917 and parameters: {'base_lr': 8.661283535667235e-05, 'last_lr': 0.00018490772170980246}. Best is trial 11 with value: 0.47985729575157166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 5.495320159797113e-05 last_lr 0.0001949936611791773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb5fd3b5d37426fb7779943649c8069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.108 New best_val_rmse: 1.108\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.935 New best_val_rmse: 0.935\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.8139 New best_val_rmse: 0.8139\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.8465 Still best_val_rmse: 0.8139 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6577 New best_val_rmse: 0.6577\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6899 Still best_val_rmse: 0.6577 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.7097 Still best_val_rmse: 0.6577 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5827 New best_val_rmse: 0.5827\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.564 New best_val_rmse: 0.564\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5867 Still best_val_rmse: 0.564 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5197 New best_val_rmse: 0.5197\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5306 Still best_val_rmse: 0.5197 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5378 Still best_val_rmse: 0.5197 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5927 Still best_val_rmse: 0.5197 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5476 Still best_val_rmse: 0.5197 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5112 New best_val_rmse: 0.5112\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.4927 New best_val_rmse: 0.4927\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 1 batch_num: 132 val_rmse: 0.4985 Still best_val_rmse: 0.4927 (from epoch 1)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5592 Still best_val_rmse: 0.4927 (from epoch 1)\n",
      "\n",
      "16 steps took 12.9 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5232 Still best_val_rmse: 0.4927 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4957 Still best_val_rmse: 0.4927 (from epoch 1)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.4896 New best_val_rmse: 0.4896\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.4894 New best_val_rmse: 0.4894\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4885 New best_val_rmse: 0.4885\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4876 New best_val_rmse: 0.4876\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4877 Still best_val_rmse: 0.4876 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4881 Still best_val_rmse: 0.4876 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4924 Still best_val_rmse: 0.4876 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4881 Still best_val_rmse: 0.4876 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4939 Still best_val_rmse: 0.4876 (from epoch 2)\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4885 Still best_val_rmse: 0.4876 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.4881 Still best_val_rmse: 0.4876 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4853 New best_val_rmse: 0.4853\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4869 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4864 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4861 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4857 Still best_val_rmse: 0.4853 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.485 New best_val_rmse: 0.485\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4846 New best_val_rmse: 0.4846\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4844 New best_val_rmse: 0.4844\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4842 New best_val_rmse: 0.4842\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4845 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4848 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4847 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4846 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4845 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4844 Still best_val_rmse: 0.4842 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4844 Still best_val_rmse: 0.4842 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 10:05:27,306]\u001b[0m Trial 13 finished with value: 0.4842141568660736 and parameters: {'base_lr': 5.495320159797113e-05, 'last_lr': 0.0001949936611791773}. Best is trial 11 with value: 0.47985729575157166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 4.075877307284862e-05 last_lr 0.0001624498006278733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5bca055abb462e9c9ad6467d55e0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.5 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.044 New best_val_rmse: 1.044\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8562 New best_val_rmse: 0.8562\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.9492 Still best_val_rmse: 0.8562 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7744 New best_val_rmse: 0.7744\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.857 Still best_val_rmse: 0.7744 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.7259 New best_val_rmse: 0.7259\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6584 New best_val_rmse: 0.6584\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.7345 Still best_val_rmse: 0.6584 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.6501 New best_val_rmse: 0.6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 10:09:00,133]\u001b[0m Trial 14 finished with value: 0.6501085162162781 and parameters: {'base_lr': 4.075877307284862e-05, 'last_lr': 0.0001624498006278733}. Best is trial 11 with value: 0.47985729575157166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 0.00010637579365513648 last_lr 8.276647346442369e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba98114f6e8a415696f865fb6ac6f371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.158 New best_val_rmse: 1.158\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7568 New best_val_rmse: 0.7568\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.8052 Still best_val_rmse: 0.7568 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7244 New best_val_rmse: 0.7244\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.7129 New best_val_rmse: 0.7129\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6232 New best_val_rmse: 0.6232\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6115 New best_val_rmse: 0.6115\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6461 Still best_val_rmse: 0.6115 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5694 New best_val_rmse: 0.5694\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.6209 Still best_val_rmse: 0.5694 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.579 Still best_val_rmse: 0.5694 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5409 New best_val_rmse: 0.5409\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5169 New best_val_rmse: 0.5169\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5562 Still best_val_rmse: 0.5169 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5453 Still best_val_rmse: 0.5169 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5095 New best_val_rmse: 0.5095\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5044 New best_val_rmse: 0.5044\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.6063 Still best_val_rmse: 0.5044 (from epoch 1)\n",
      "\n",
      "16 steps took 12.8 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.494 New best_val_rmse: 0.494\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 16 val_rmse: 0.4964 Still best_val_rmse: 0.494 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4808 New best_val_rmse: 0.4808\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 28 val_rmse: 0.4816 Still best_val_rmse: 0.4808 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.4816 Still best_val_rmse: 0.4808 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.48 New best_val_rmse: 0.48\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4791 New best_val_rmse: 0.4791\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 42 val_rmse: 0.48 Still best_val_rmse: 0.4791 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4779 New best_val_rmse: 0.4779\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 46 val_rmse: 0.4772 New best_val_rmse: 0.4772\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4771 New best_val_rmse: 0.4771\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 50 val_rmse: 0.4778 Still best_val_rmse: 0.4771 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4803 Still best_val_rmse: 0.4771 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4766 New best_val_rmse: 0.4766\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 58 val_rmse: 0.4773 Still best_val_rmse: 0.4766 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4861 Still best_val_rmse: 0.4766 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4851 Still best_val_rmse: 0.4766 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4738 New best_val_rmse: 0.4738\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 70 val_rmse: 0.4736 New best_val_rmse: 0.4736\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4722 New best_val_rmse: 0.4722\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 74 val_rmse: 0.476 Still best_val_rmse: 0.4722 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4782 Still best_val_rmse: 0.4722 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 78 val_rmse: 0.4729 Still best_val_rmse: 0.4722 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.4733 Still best_val_rmse: 0.4722 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 82 val_rmse: 0.4751 Still best_val_rmse: 0.4722 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4732 Still best_val_rmse: 0.4722 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 86 val_rmse: 0.4716 New best_val_rmse: 0.4716\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4717 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 90 val_rmse: 0.473 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4746 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 94 val_rmse: 0.4738 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4735 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 98 val_rmse: 0.4729 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4726 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 102 val_rmse: 0.4727 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4735 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 106 val_rmse: 0.4737 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4738 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 110 val_rmse: 0.4734 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.49 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4733 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 114 val_rmse: 0.4732 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.473 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 118 val_rmse: 0.4731 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4733 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 122 val_rmse: 0.4736 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4739 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 126 val_rmse: 0.474 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4743 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 130 val_rmse: 0.4744 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4745 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 134 val_rmse: 0.4745 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4745 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 138 val_rmse: 0.4746 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4746 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 142 val_rmse: 0.4746 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4746 Still best_val_rmse: 0.4716 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 2 batch_num: 146 val_rmse: 0.4746 Still best_val_rmse: 0.4716 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 10:25:31,053]\u001b[0m Trial 15 finished with value: 0.47160205245018005 and parameters: {'base_lr': 0.00010637579365513648, 'last_lr': 8.276647346442369e-05}. Best is trial 15 with value: 0.47160205245018005.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 0.00014957407459464006 last_lr 0.00028294729583032354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb00b90dcc640ec8d1f36f4bab97aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.5 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8874 New best_val_rmse: 0.8874\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7423 New best_val_rmse: 0.7423\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.8506 Still best_val_rmse: 0.7423 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.049 Still best_val_rmse: 0.7423 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.128 Still best_val_rmse: 0.7423 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.083 Still best_val_rmse: 0.7423 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.06 Still best_val_rmse: 0.7423 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.059 Still best_val_rmse: 0.7423 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.065 Still best_val_rmse: 0.7423 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 10:29:02,494]\u001b[0m Trial 16 finished with value: 0.7422624826431274 and parameters: {'base_lr': 0.00014957407459464006, 'last_lr': 0.00028294729583032354}. Best is trial 15 with value: 0.47160205245018005.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 0.00010197064730942197 last_lr 0.00012323780507671805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239d98d4f9c14a0eb81a1b8ea5541903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.5 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.067 New best_val_rmse: 1.067\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8543 New best_val_rmse: 0.8543\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.097 Still best_val_rmse: 0.8543 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.062 Still best_val_rmse: 0.8543 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.073 Still best_val_rmse: 0.8543 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.069 Still best_val_rmse: 0.8543 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 10:31:29,153]\u001b[0m Trial 17 finished with value: 0.8542517423629761 and parameters: {'base_lr': 0.00010197064730942197, 'last_lr': 0.00012323780507671805}. Best is trial 15 with value: 0.47160205245018005.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 0.00020300382337553154 last_lr 0.0002578690732592039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1973ee8421644afb9161d993a4180252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.5 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.018 New best_val_rmse: 1.018\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.161 Still best_val_rmse: 1.018 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.098 Still best_val_rmse: 1.018 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.08 Still best_val_rmse: 1.018 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.077 Still best_val_rmse: 1.018 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.096 Still best_val_rmse: 1.018 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 10:33:56,418]\u001b[0m Trial 18 finished with value: 1.0176031589508057 and parameters: {'base_lr': 0.00020300382337553154, 'last_lr': 0.0002578690732592039}. Best is trial 15 with value: 0.47160205245018005.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 2\n",
      "##### Using base_lr 8.121779661903581e-05 last_lr 8.341126960078048e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2a37c377664a1b9a9cc39f68557abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.5 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8434 New best_val_rmse: 0.8434\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8109 New best_val_rmse: 0.8109\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7472 New best_val_rmse: 0.7472\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.109 Still best_val_rmse: 0.7472 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.091 Still best_val_rmse: 0.7472 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.094 Still best_val_rmse: 0.7472 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.072 Still best_val_rmse: 0.7472 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.06 Still best_val_rmse: 0.7472 (from epoch 0)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.062 Still best_val_rmse: 0.7472 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-19 10:37:28,281]\u001b[0m Trial 19 finished with value: 0.7471550703048706 and parameters: {'base_lr': 8.121779661903581e-05, 'last_lr': 8.341126960078048e-05}. Best is trial 15 with value: 0.47160205245018005.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best value:  0.47160205245018005\n",
      " Best params: \n",
      "    base_lr: 0.00010637579365513648\n",
      "    last_lr: 8.276647346442369e-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 3):\n",
    "    fold = i\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    print(\" Best value: \", study.best_trial.value)\n",
    "    print(\" Best params: \")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a69a20-e7bd-4426-8394-9fe92ff4ceba",
   "metadata": {},
   "source": [
    "### Verify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d2f26d-f0bc-4d35-b970-a18b100c97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820cfbb0-36c6-41e7-b98e-d5ecc379c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model_offset = 0\n",
    "cfg.model_limit = 6\n",
    "cfg.n_folds = 5\n",
    "cfg.svm_kernels = ['rbf']\n",
    "cfg.svm_c = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe3330-3d2c-49c5-be98-69a13cf2a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = int(np.ceil(np.log2(len(train_df))))\n",
    "train_df['bins'] = pd.cut(train_df['target'], bins=num_bins, labels=False)\n",
    "bins = train_df['bins'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508c0ef-984f-4af5-a283-88498c1dcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "inference_models = []\n",
    "for i in range(1, cfg.NUM_FOLDS + 1):\n",
    "    print(f'Model {i}')\n",
    "    inference_model = CommonLitModel()\n",
    "    inference_model = inference_model.cuda()\n",
    "    inference_model.load_state_dict(torch.load(str(MODELS_PATH/f\"{cfg.model_name.replace('/', '_')}_{i}/model_{i}.pth\")))\n",
    "    inference_model.eval();\n",
    "    inference_models.append(inference_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a6b85-3e21-44c5-bbe1-347c12d4c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizers = []\n",
    "for i in range(1, cfg.NUM_FOLDS):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(MODELS_PATH/f\"{cfg.model_name.replace('/', '_')}_{i}\")\n",
    "    tokenizers.append(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6479666-2703-4691-831c-6a1a493924b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_embeddings(dl, transformer_model):\n",
    "    cls_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for input_features in tqdm(dl, total=len(dl)):\n",
    "            output, context_vector = transformer_model(input_features['input_ids'].cuda(), input_features['attention_mask'].cuda())\n",
    "#             cls_embeddings.extend(output['last_hidden_state'][:,0,:].detach().cpu().numpy())\n",
    "            embedding_out = context_vector.detach().cpu().numpy()\n",
    "            cls_embeddings.extend(embedding_out)\n",
    "    return np.array(cls_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0cd48-b89a-4be9-b3f8-75f79133292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_score(X, y):\n",
    "    return np.sqrt(mean_squared_error(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29dc0cb-b3d7-448c-8166-0716b76860c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(t):\n",
    "    return t.flatten().long()\n",
    "\n",
    "class CommonLitDataset(nn.Module):\n",
    "    def __init__(self, text, test_id, tokenizer, max_len=128):\n",
    "        self.excerpt = text\n",
    "        self.test_id = test_id\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],\n",
    "                                return_tensors='pt',\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length',\n",
    "                                truncation=True)\n",
    "        return {'input_ids': convert_to_list(encode['input_ids']),\n",
    "                'attention_mask': convert_to_list(encode['attention_mask']),\n",
    "                'id': self.test_id[idx]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69fc14c-d0c9-486c-b15c-1aa2d81ad424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dl(df, tokenizer):\n",
    "    text = df['excerpt'].values\n",
    "    ids = df['id'].values\n",
    "    ds = CommonLitDataset(text, ids, tokenizer, max_len=cfg.MAX_LEN)\n",
    "    return DataLoader(ds, \n",
    "                      batch_size = cfg.BATCH_SIZE,\n",
    "                      shuffle=False,\n",
    "                      num_workers = 1,\n",
    "                      pin_memory=True,\n",
    "                      drop_last=False\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7052da7-31ff-4863-a4bf-ff6bb5829873",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH/'train-orig.csv')\n",
    "test_df = pd.read_csv(DATA_PATH/'test.csv')\n",
    "remove_unnecessary(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f88ec-0471-4d1a-8270-f610141382b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_mean = train_df['target'].mean()\n",
    "train_target_std = train_df['target'].std()\n",
    "train_df['normalized_target'] = (train_df['target'] - train_target_mean) / train_target_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb532e-9f76-406b-ba60-c8991851faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_target = train_df['normalized_target'].values\n",
    "\n",
    "def calc_mean(scores):\n",
    "    return np.mean(np.array(scores), axis=0)\n",
    "\n",
    "final_scores = []\n",
    "final_rmse = []\n",
    "kernel_rmse_score_mean = []\n",
    "final_kernel_predictions_means = []\n",
    "for j, (inference_model, tokenizer) in enumerate(zip(inference_models, tokenizers)):\n",
    "    print('Model', j)\n",
    "    test_dl = create_dl(test_df, tokenizer)\n",
    "    train_dl = create_dl(train_df, tokenizer)\n",
    "    transformer_model = inference_model\n",
    "    transformer_model.cuda()\n",
    "    X = get_cls_embeddings(train_dl, transformer_model)\n",
    "    \n",
    "    y = train_target\n",
    "    X_test = get_cls_embeddings(test_dl, transformer_model)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=cfg.NUM_FOLDS)\n",
    "    scores = []\n",
    "    rmse_scores = []\n",
    "    kernel_predictions_means = []\n",
    "    for kernel in cfg.svm_kernels:\n",
    "        print('Kernel', kernel)\n",
    "        kernel_scores = []\n",
    "        kernel_rmse_scores = []\n",
    "        kernel_predictions = []\n",
    "        for k, (train_idx, valid_idx) in enumerate(kfold.split(X, bins)):\n",
    "\n",
    "            print('Fold', k, train_idx.shape, valid_idx.shape)\n",
    "            model = SVR(C=cfg.svm_c, kernel=kernel, gamma='auto')\n",
    "\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            prediction = model.predict(X_valid)\n",
    "            kernel_predictions.append(prediction)\n",
    "            kernel_rmse_scores.append(rmse_score(prediction, y_valid))\n",
    "            print('rmse_score', kernel_rmse_scores[k])\n",
    "            kernel_scores.append(model.predict(X_test))\n",
    "        kernel_predictions_means.append(np.array([np.mean(kp) for kp in kernel_predictions]).mean())\n",
    "        scores.append(calc_mean(kernel_scores))\n",
    "        kernel_rmse_score = calc_mean(kernel_rmse_scores)\n",
    "        kernel_rmse_score_mean.append(kernel_rmse_score)\n",
    "        rmse_scores.append(kernel_rmse_score)\n",
    "    final_kernel_predictions_means.append(kernel_predictions_means)\n",
    "    final_scores.append(calc_mean(scores))\n",
    "    final_rmse.append(calc_mean(rmse_scores))\n",
    "print('FINAL RMSE score', np.mean(np.array(final_rmse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ac2d7-605a-4cc7-8bd0-8eec0ec6f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_kernel_predictions_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b649aa-784d-4dbf-83e4-252ca3f2bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_df['target'] - cfg.train_target_mean) / cfg.train_target_std\n",
    "final_scores_normalized = np.array(final_scores) * train_target_std + train_target_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd46e8-1542-4a71-82ca-d6d4838d7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_rmse_score_mean_array = np.array(kernel_rmse_score_mean)\n",
    "kernel_rmse_score_mean_sum = np.sum(kernel_rmse_score_mean_array)\n",
    "prop_losses = kernel_rmse_score_mean_array / kernel_rmse_score_mean_sum\n",
    "prop_losses_sum = (1 - prop_losses).sum()\n",
    "weights = (1 - prop_losses) / prop_losses_sum\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b9381-2a90-4183-b305-59f6d233017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(scores, weights=weights):\n",
    "    return np.average(np.array(scores), weights=weights, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c0f5a2-7e63-4799-ad55-1a733b24a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mean = train_df['target'].mean()\n",
    "final_scores_flat = calc_mean(final_scores_normalized).flatten()\n",
    "final_scores_mean = final_scores_flat.mean()\n",
    "target_mean, np.array(final_scores_normalized).mean()\n",
    "# (-0.9579984513405823, -0.8029817438292849)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a4669-2c5d-49e6-8dec-f9abb9cd8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4614a6c5-af82-4b2c-bf5a-f1180109426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = target_mean - final_scores_mean\n",
    "mean_diff, mean_diff / len(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd92a7-a55f-422a-bfae-7f475bd5f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['target'] = final_scores_flat + mean_diff\n",
    "# sample_df['target'] = len(final_scores) / np.sum(1 / np.array(final_scores), axis=0) # harmonic mean\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c995ca-ff1f-4b43-a41c-28d6ec11fa97",
   "metadata": {},
   "source": [
    "### Prepare Packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c5d5b-b293-4d59-b2e7-53131745079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993d2b0-3c68-4241-b15d-c51e10ee788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_FOLDER = MODELS_PATH/cfg.model_name/'best'\n",
    "!rm -rf {BEST_MODEL_FOLDER}\n",
    "!mkdir -p {BEST_MODEL_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3faa7c-7b90-4fe2-aebf-cf9733a3674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44851d5-e456-4abd-972c-0838dd792714",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.NUM_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30572a-121f-4432-a83d-f49c6fa5e815",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodels = [MODELS_PATH/f'{cfg.model_name}_{i + 1}' for i in range(0, cfg.NUM_FOLDS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cf4b3-862c-4676-bc1d-875cd32ce7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f114e7-7e75-43d8-8c4c-6889f6393b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "def normalize_name(path_name):\n",
    "    return path_name.replace('', '')\n",
    "\n",
    "for i, best_model in enumerate(bestmodels):\n",
    "    print(f'Processing {i}th model')\n",
    "    i = i + 1\n",
    "    best_model_file = f'{best_model}/model_{i}.pth'\n",
    "    if Path(best_model_file).exists():\n",
    "        copyfile(best_model_file, f'{BEST_MODEL_FOLDER}/{i}_pytorch_model.bin')\n",
    "        tokenizer_path = Path(BEST_MODEL_FOLDER/f'tokenizer-{i}')\n",
    "        tokenizer_path.mkdir(parents=True, exist_ok=True)\n",
    "        assert tokenizer_path.exists()\n",
    "\n",
    "        tokenizer_json = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}_{i}/tokenizer_config.json'))\n",
    "        assert tokenizer_json.exists(), f'{tokenizer_json} does not exist'\n",
    "        copyfile(tokenizer_json, tokenizer_path/'tokenizer.json')\n",
    "\n",
    "        vocab_txt = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}_{i}/vocab.json'))\n",
    "        assert vocab_txt.exists(), f'{vocab_txt} does not exist'\n",
    "        copyfile(vocab_txt, tokenizer_path/'vocab.json')\n",
    "\n",
    "        merges = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}_{i}/merges.txt'))\n",
    "        assert merges.exists()\n",
    "        copyfile(merges, tokenizer_path/'merges.txt')\n",
    "    else:\n",
    "        print(f'{best_model_file} is missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc422f71-d671-4eca-82f4-0dd059b1200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(MODELS_PATH/cfg.model_name/'best_models', 'zip', BEST_MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d2659-6041-47d9-ba4c-a8ecade644a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf7473-d8fd-4ff4-8b51-67028bc5d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv {MODELS_PATH}/{cfg.model_name}.yaml {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bdcbd8-bed2-4ac9-91a0-93b35b0d2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model.transformer_model.save_pretrained(save_directory=f'{MODELS_PATH/cfg.model_name}/lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5088d-df35-4b54-8de6-9c8a3bdc5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h {MODELS_PATH/cfg.model_name}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a2e2d-e325-4b5f-ab68-71b1cc9d3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(MODELS_PATH/cfg.model_name/'lm', 'zip', f'{MODELS_PATH/cfg.model_name}/lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616c042-2877-470a-b227-948606188b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets init -p {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6984b-07d9-49e6-89b2-6066503bda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json_path = Path(MODELS_PATH/cfg.model_name/'dataset-metadata.json')\n",
    "assert dataset_json_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa049c-faa9-45da-af4f-554a2000f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {str(dataset_json_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf108e8-c48c-4134-809b-6c775ef5b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_json_path, 'r') as f:\n",
    "    dataset_json = f.read()\n",
    "    dataset_json = dataset_json.replace('INSERT_TITLE_HERE', f'commonlit-{cfg.model_name}-light').replace('INSERT_SLUG_HERE', f'commonlit-{cfg.model_name}-light')\n",
    "    print(dataset_json)\n",
    "with(open(dataset_json_path, 'w')) as f:\n",
    "    f.write(dataset_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9877c0cb-0d80-43d6-a064-f929ad92b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {MODELS_PATH/cfg.model_name}/best\n",
    "!rm -rf {MODELS_PATH/cfg.model_name}/lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851185dc-f532-4920-bfc0-39f36f0224bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets create -p {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19f40a-df46-4f1d-b247-c627e7cf091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets version -p {MODELS_PATH/cfg.model_name} -m \"Version with merges.txt\" -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffe0ba-8412-4616-a0a4-78c0b4552f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(str(MODELS_PATH/f'distilroberta-0/checkpoint-105/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e77de-3b71-408f-8d6c-25bae3e60f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = CommonLitModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de19b9-2d6b-41c1-a765-5c39551fe176",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859231b7-d595-463e-8ab7-1ac150193306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
