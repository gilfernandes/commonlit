{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e1dbe-f484-4304-8001-f10b5e0321c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef39394-5986-44bb-a6d6-84957a492ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, sys, time, collections, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict, Optional, Union, Any, List, Tuple\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.utils.data as D\n",
    "from torch.utils.data.dataset import Dataset, IterableDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertModel\n",
    "from transformers import Trainer\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from transformers import TrainingArguments\n",
    "from transformers.trainer_utils import EvalLoopOutput\n",
    "from transformers.trainer import logging\n",
    "from transformers.file_utils import is_torch_tpu_available, is_sagemaker_mp_enabled\n",
    "from transformers.trainer_pt_utils import find_batch_size, nested_concat, nested_numpify, nested_truncate, nested_detach\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c54d1-55c1-4701-9fde-692cf4450c84",
   "metadata": {},
   "source": [
    "### Folders and Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c75e83-4760-4511-bf31-a144abfc01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/home/commonlit/data/')\n",
    "assert DATA_PATH.exists()\n",
    "MODELS_PATH = Path('/home/commonlit/models/')\n",
    "if not MODELS_PATH.exists():\n",
    "    os.mkdir(MODELS_PATH)\n",
    "assert MODELS_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b25934-3c16-4cb0-ab3b-6d95223432f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_data_enhancements.ipynb     sample_submission.csv  train-orig.csv\n",
      "02_synonymizer.ipynb\t       test-enhanced.csv      train.csv\n",
      "commonlit_lm\t\t       test.csv\t\t      train_duo.csv\n",
      "commonlit_lm.zip\t       thumbelina\t      train_enhancements.csv\n",
      "commonlitreadabilityprize.zip  tokenizer.vocab.txt\n",
      "extra_data\t\t       train-mix.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12796f2-c49a-4d32-9f38-0ecdec520539",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH/'train-mix.csv')\n",
    "test_df = pd.read_csv(DATA_PATH/'test.csv')\n",
    "sample_df = pd.read_csv(DATA_PATH/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179a075d-6fa8-4cf4-b703-db4f09c9649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>659e6b1af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meanwhile they came to the palace, to the fath...</td>\n",
       "      <td>-0.095750</td>\n",
       "      <td>0.464406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>659e6b1af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To which the shepherd replied, \\n\"If you wish ...</td>\n",
       "      <td>-0.095750</td>\n",
       "      <td>0.464406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>659e6b1af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Now you understand the language of animals, a...</td>\n",
       "      <td>-0.095750</td>\n",
       "      <td>0.464406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>659e6b1af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"What if that shepherd only knew that undernea...</td>\n",
       "      <td>-0.095750</td>\n",
       "      <td>0.464406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>659e6b1af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The shepherd took the treasure, built himself ...</td>\n",
       "      <td>-0.095750</td>\n",
       "      <td>0.464406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3114 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id url_legal license  \\\n",
       "0     c12129c31       NaN     NaN   \n",
       "1     85aa80a4c       NaN     NaN   \n",
       "2     b69ac6792       NaN     NaN   \n",
       "3     dd1000b26       NaN     NaN   \n",
       "4     37c1b32fb       NaN     NaN   \n",
       "...         ...       ...     ...   \n",
       "3109  659e6b1af       NaN     NaN   \n",
       "3110  659e6b1af       NaN     NaN   \n",
       "3111  659e6b1af       NaN     NaN   \n",
       "3112  659e6b1af       NaN     NaN   \n",
       "3113  659e6b1af       NaN     NaN   \n",
       "\n",
       "                                                excerpt    target  \\\n",
       "0     When the young people returned to the ballroom... -0.340259   \n",
       "1     All through dinner time, Mrs. Fayre was somewh... -0.315372   \n",
       "2     As Roger had predicted, the snow departed as q... -0.580118   \n",
       "3     And outside before the palace a great garden w... -1.054013   \n",
       "4     Once upon a time there were Three Bears who li...  0.247197   \n",
       "...                                                 ...       ...   \n",
       "3109  Meanwhile they came to the palace, to the fath... -0.095750   \n",
       "3110  To which the shepherd replied, \\n\"If you wish ... -0.095750   \n",
       "3111  \"Now you understand the language of animals, a... -0.095750   \n",
       "3112  \"What if that shepherd only knew that undernea... -0.095750   \n",
       "3113  The shepherd took the treasure, built himself ... -0.095750   \n",
       "\n",
       "      standard_error  \n",
       "0           0.464009  \n",
       "1           0.480805  \n",
       "2           0.476676  \n",
       "3           0.450007  \n",
       "4           0.510845  \n",
       "...              ...  \n",
       "3109        0.464406  \n",
       "3110        0.464406  \n",
       "3111        0.464406  \n",
       "3112        0.464406  \n",
       "3113        0.464406  \n",
       "\n",
       "[3114 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efffba57-a6ab-4210-8391-5f2fccb3fd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Battle of Waterloo was a battle that was fought mostly between French and British forces. Napoleon was crowned as Emperor of France in 1804. Then he launched many successful attacks on other countries in Europe. France soon had an empire that stretched from Spain to the Russian border. The only country that was still not captured was Great Britain. The Royal Navy had many ships, so invasion by France was not possible. However, Great Britain was not strong enough to stop Napoleon and his army from taking over most of mainland Europe.\\nNapoleon seemed unstoppable until two separate campaigns caused his empire to fall apart. He gathered a huge army to invade and conquer Russia once and for all in 1812. However, he did not think that he would have very many difficulties and it turned out he did. His army was caught by the Russian winter and destroyed by the weather and lack of food.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['id'] == '5127fb10f']['excerpt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f5b0bd8-527e-4b89-9082-f0780c9ae28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['excerpt'].values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f9d38f-4496-420d-8d4b-d28bb24dd6fd",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aec270c2-9de5-4201-9627-04fdba2fa884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deberta-large'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "229b1b24-233b-4a4e-b759-78b3986bdbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG():\n",
    "    model_name = 'microsoft/deberta-large'\n",
    "    batch_size = 12\n",
    "    max_len = 512\n",
    "    save_dir = f'trained/{model_name}'\n",
    "    num_workers = 2\n",
    "    epochs = 15\n",
    "    pretrained_transformers_model = f'{model_name}'\n",
    "    mlm_probability= 0.15\n",
    "    preprocessing_num_workers = 2\n",
    "    overwrite_cache = True\n",
    "    do_train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e00160a-ea34-45e8-b147-6da8c2a3130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CONFIG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab8b20-6c63-4d51-b6fe-39ff141ad03e",
   "metadata": {},
   "source": [
    "### Prepare Train / Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "000cc1cf-b423-4c87-8069-62652f798c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "commonlit_lm_path = DATA_PATH/'commonlit_lm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d26c1baf-05c1-4308-8843-947b0d163c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not commonlit_lm_path.exists():\n",
    "    commonlit_lm_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4fcd590-9e30-44e9-b424-515085eb185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = train_df['excerpt'].values\n",
    "valid_text = test_df['excerpt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d72aebb9-6807-4880-a241-847c44252cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_to_text_file(data, file):\n",
    "#     with open(file, 'w') as f:\n",
    "#         for t in data:\n",
    "#             f.write(f'{t}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "429a926a-c792-45be-bffa-bd887d55c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_to_text_file(all_text, common_lit_text_file)\n",
    "# write_to_text_file(valid_text, common_lit_valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79a8106f-9073-40e9-8951-5af6dce939a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_dict = {'text': all_text.tolist()}\n",
    "valid_text_dict = {'text': valid_text.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8a90766-e63a-44e6-9867-40279332f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.Dataset.from_dict(train_text_dict)\n",
    "valid_dataset = datasets.Dataset.from_dict(valid_text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9f218df-bb8b-4c7d-a449-8a7084be227b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 3114\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09e5cc14-e2a1-44fc-9f23-2d48637180c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37895bf6-c70a-464f-a8a4-76c77efc7d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43376e11-8fa4-4ac3-8ae8-215cb105b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.pretrained_transformers_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b507057-26d8-4796-ac40-d16a33b702e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[column_names[0]], return_special_tokens_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d96450fb-fcc6-4c1b-8a03-f360ccd61c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=cfg.preprocessing_num_workers,\n",
    "    remove_columns=column_names,\n",
    "    load_from_cache_file=not cfg.overwrite_cache,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fe2350b-7f12-410f-8403-20e3e8e7af5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_valid_datasets = valid_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=cfg.preprocessing_num_workers,\n",
    "    remove_columns=column_names,\n",
    "    load_from_cache_file=not cfg.overwrite_cache,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cc18f17-4309-4ce7-8e28-33dbe38cb464",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, inputs in enumerate(tokenized_datasets):\n",
    "    input_length = len(inputs['input_ids'])\n",
    "    if input_length > 512:\n",
    "        print(i, input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d8756cc-bfbd-4d8e-9d85-a94e486b7d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'special_tokens_mask', 'token_type_ids'],\n",
       "    num_rows: 3114\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74a52668-cff6-4e51-9a9f-7dd72566b407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'special_tokens_mask', 'token_type_ids'],\n",
       "    num_rows: 7\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_valid_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41929b40-8c9f-4e32-af73-476163f9515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets\n",
    "valid_dataset = tokenized_valid_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941069e3-c670-4929-bd87-1c7651de3f70",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c83862f-f1b3-4512-a75b-af7348edb1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaForMaskedLM: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'config', 'lm_predictions.lm_head.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-large and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(cfg.pretrained_transformers_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88e87922-e401-42d6-8239-78f46bb9f1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForLanguageModeling(tokenizer=PreTrainedTokenizerFast(name_or_path='microsoft/deberta-large', vocab_size=50265, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'bos_token': AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=True)}), mlm=True, mlm_probability=0.15, pad_to_multiple_of=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=cfg.mlm_probability)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370fd3a4-9d7b-42be-b31c-2f6c6c15a3a0",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7aec0071-9d4d-400c-a163-044b20279a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d57cfc8c-551e-4f67-91f8-5aec7002d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_args():\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(MODELS_PATH/f\"{re.sub(r'.+/', '', cfg.model_name)}-lm\"),\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        per_device_train_batch_size=cfg.batch_size,\n",
    "        per_device_eval_batch_size=cfg.batch_size,\n",
    "        num_train_epochs=cfg.epochs,\n",
    "        logging_strategy=\"epoch\",\n",
    "        logging_first_step=True,\n",
    "        save_steps=40000,\n",
    "        fp16=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_total_limit = 3,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_loss',\n",
    "        greater_is_better=False,\n",
    "        gradient_accumulation_steps=1,\n",
    "        learning_rate=5e-5\n",
    "    )\n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18e1c48e-da7e-4a1e-b91e-c9c5a262a689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = create_training_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "883bd02c-7ab8-4fdc-bb6e-42e6c98a0935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/commonlit/models/deberta-large-lm'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b824f020-8c68-44e6-aea4-ba919f9ae9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset if cfg.do_train else None,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=9)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34a504b1-6a02-4a36-81a2-d5b9bb4139b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {training_args.output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e05a1af9-60ad-4750-ba51-15c679748446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3900' max='3900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3900/3900 30:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.150600</td>\n",
       "      <td>3.089156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.759800</td>\n",
       "      <td>2.370032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.388800</td>\n",
       "      <td>2.077657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.157400</td>\n",
       "      <td>2.221605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.972600</td>\n",
       "      <td>2.147031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.834600</td>\n",
       "      <td>2.137856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.756200</td>\n",
       "      <td>1.686588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.661300</td>\n",
       "      <td>2.175741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.571200</td>\n",
       "      <td>1.650662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.526100</td>\n",
       "      <td>1.634042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.470700</td>\n",
       "      <td>1.796856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.424900</td>\n",
       "      <td>1.518814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.401800</td>\n",
       "      <td>1.592233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.364800</td>\n",
       "      <td>1.671055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.346900</td>\n",
       "      <td>1.539035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 6s, sys: 7min 53s, total: 31min\n",
      "Wall time: 30min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "839234b6-a0ec-42c2-95bd-07d39f3fb51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_checkpoint /home/commonlit/models/deberta-large-lm/checkpoint-3120\n"
     ]
    }
   ],
   "source": [
    "print('best_model_checkpoint', trainer.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edc47c8e-6f86-4fe9-8e1f-6085c8127a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/commonlit/models')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODELS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f8ffe0ba-8412-4616-a0a4-78c0b4552f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "model_zip_file = shutil.make_archive(f'{MODELS_PATH}/{cfg.model_name}/commonlit_lm', 'zip', trainer.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f75802e3-ac7f-4b8c-9c69-cfdb6912004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_file_name = f'{MODELS_PATH}/{cfg.model_name}/commonlit_lm.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "976e97d9-1bf5-401b-b499-90658c4e44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv {trainer.state.best_model_checkpoint} {Path(trainer.state.best_model_checkpoint).parent}/best_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "63d8517a-ae53-4ced-b9f3-c370e123d55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t   rng_state.pth\t    tokenizer.json\t   vocab.json\n",
      "merges.txt\t   scaler.pt\t\t    tokenizer_config.json\n",
      "optimizer.pt\t   scheduler.pt\t\t    trainer_state.json\n",
      "pytorch_model.bin  special_tokens_map.json  training_args.bin\n"
     ]
    }
   ],
   "source": [
    "!ls {MODELS_PATH}/{re.sub(r'.+/', '', cfg.model_name)}-lm/best_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c5502ce7-4ee4-4dca-bca0-95cfdeba95f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/commonlit/models/deberta-large-lm/best_lm\n"
     ]
    }
   ],
   "source": [
    "!echo {MODELS_PATH}/{re.sub(r'.+/', '', cfg.model_name)}-lm/best_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f403fb7e-8f0a-40f5-a0be-d73b604b3cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2G\t/home/commonlit/models/microsoft/deberta-large/commonlit_lm.zip\n"
     ]
    }
   ],
   "source": [
    "!du -h {export_file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "200ae0ae-490c-4d60-b518-87547818b70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/commonlit/models/distilroberta_lm’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir /home/commonlit/models/distilroberta_lm\n",
    "!mv {trainer.state.best_model_checkpoint} /home/commonlit/models/distilroberta_lm/best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1717a9-c8a0-4709-b7a7-2acd9244bb76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
