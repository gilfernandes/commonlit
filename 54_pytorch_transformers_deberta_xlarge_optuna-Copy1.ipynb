{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e1dbe-f484-4304-8001-f10b5e0321c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef39394-5986-44bb-a6d6-84957a492ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import gc, warnings, random, time, os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c54d1-55c1-4701-9fde-692cf4450c84",
   "metadata": {},
   "source": [
    "### Folders and Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c75e83-4760-4511-bf31-a144abfc01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/home/commonlit/data/')\n",
    "assert DATA_PATH.exists()\n",
    "MODELS_PATH = Path('/home/commonlit/models/')\n",
    "if not MODELS_PATH.exists():\n",
    "    os.mkdir(MODELS_PATH)\n",
    "assert MODELS_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12796f2-c49a-4d32-9f38-0ecdec520539",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH/'train-orig.csv')\n",
    "test_df = pd.read_csv(DATA_PATH/'test.csv')\n",
    "sample_df = pd.read_csv(DATA_PATH/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836ed820-371a-48da-8412-db0701c05c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unnecessary(df):\n",
    "    df.drop(df[df['target'] == 0].index, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "remove_unnecessary(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179a075d-6fa8-4cf4-b703-db4f09c9649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2c26db523</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>So what is a solid? Solids are usually hard be...</td>\n",
       "      <td>0.189476</td>\n",
       "      <td>0.535648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>cd19e2350</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>The second state of matter we will discuss is ...</td>\n",
       "      <td>0.255209</td>\n",
       "      <td>0.483866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>15e2e9e7a</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Solids are shapes that you can actually touch....</td>\n",
       "      <td>-0.215279</td>\n",
       "      <td>0.514128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>5b990ba77</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Animals are made of many cells. They eat thing...</td>\n",
       "      <td>0.300779</td>\n",
       "      <td>0.512379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2833 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          url_legal  \\\n",
       "0     c12129c31                                                NaN   \n",
       "1     85aa80a4c                                                NaN   \n",
       "2     b69ac6792                                                NaN   \n",
       "3     dd1000b26                                                NaN   \n",
       "4     37c1b32fb                                                NaN   \n",
       "...         ...                                                ...   \n",
       "2828  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n",
       "2829  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2830  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2831  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n",
       "2832  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n",
       "\n",
       "           license                                            excerpt  \\\n",
       "0              NaN  When the young people returned to the ballroom...   \n",
       "1              NaN  All through dinner time, Mrs. Fayre was somewh...   \n",
       "2              NaN  As Roger had predicted, the snow departed as q...   \n",
       "3              NaN  And outside before the palace a great garden w...   \n",
       "4              NaN  Once upon a time there were Three Bears who li...   \n",
       "...            ...                                                ...   \n",
       "2828  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n",
       "2829  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n",
       "2830  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n",
       "2831  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n",
       "2832  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n",
       "\n",
       "        target  standard_error  \n",
       "0    -0.340259        0.464009  \n",
       "1    -0.315372        0.480805  \n",
       "2    -0.580118        0.476676  \n",
       "3    -1.054013        0.450007  \n",
       "4     0.247197        0.510845  \n",
       "...        ...             ...  \n",
       "2828  1.711390        0.646900  \n",
       "2829  0.189476        0.535648  \n",
       "2830  0.255209        0.483866  \n",
       "2831 -0.215279        0.514128  \n",
       "2832  0.300779        0.512379  \n",
       "\n",
       "[2833 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e79e005-5651-4414-9725-4567d3a9b300",
   "metadata": {},
   "source": [
    "### Config and Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07938c53-d840-4889-b9ab-3170c608137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(): \n",
    "    NUM_FOLDS = 6\n",
    "    NUM_EPOCHS = 3\n",
    "    BATCH_SIZE = 16\n",
    "    MAX_LEN = 248\n",
    "    EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
    "    ROBERTA_PATH = 'microsoft/deberta-v2-xlarge'\n",
    "    TOKENIZER_PATH = 'microsoft/deberta-v2-xlarge'\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    SEED = 1000\n",
    "    NUM_WORKERS = 2\n",
    "    MODEL_FOLDER = MODELS_PATH\n",
    "    model_name = 'microsoft/deberta-v2-xlarge-mnli'\n",
    "    svm_kernels = ['rbf']\n",
    "    svm_c = 5\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b17b48-922f-4a27-8bb4-e641491d137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cfg.MODEL_FOLDER.exists():\n",
    "    os.mkdir(cfg.MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd067b3-c1a6-4c4a-900e-9499ca93b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab8b20-6c63-4d51-b6fe-39ff141ad03e",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978289c5-dc58-4be5-93d8-64566dad766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bins(train_df, num_bins):\n",
    "    train_df.loc[:, 'bins'] = pd.cut(train_df['target'], bins=num_bins, labels=False)\n",
    "    return num_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "131b79d6-1ec5-492b-930f-e4c75288bcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_bins(train_df, cfg.NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ee1b97-cef2-46cc-88d7-3f7ae737c3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bins</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "      <td>-3.125765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>441</td>\n",
       "      <td>-2.270279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>784</td>\n",
       "      <td>-1.412150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>886</td>\n",
       "      <td>-0.548095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>494</td>\n",
       "      <td>0.289716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>1.070237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count      mean\n",
       "bins                 \n",
       "0       122 -3.125765\n",
       "1       441 -2.270279\n",
       "2       784 -1.412150\n",
       "3       886 -0.548095\n",
       "4       494  0.289716\n",
       "5       106  1.070237"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(['bins'])['target'].agg(['count', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41922d13-b7af-4675-ae2d-c384025c86e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42787f35-115b-4258-925f-6575f3063924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonLitDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, inference_only=False):\n",
    "        super().__init__()\n",
    "        self.df, self.inference_only = df, inference_only\n",
    "        self.text = df['excerpt'].tolist()\n",
    "        self.bins = df['bins']\n",
    "        if not inference_only:\n",
    "            self.target = torch.tensor(df['target'].to_numpy(), dtype = torch.float32)\n",
    "        \n",
    "        self.encoded = tokenizer.batch_encode_plus(\n",
    "            self.text,\n",
    "            padding = 'max_length',\n",
    "            max_length = cfg.MAX_LEN,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
    "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
    "        \n",
    "        if self.inference_only:\n",
    "            return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "        else:\n",
    "            target = self.target[index]\n",
    "            return {'input_ids': input_ids, 'attention_mask': attention_mask, 'target': target}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf2329ea-0c9a-407c-8c82-8f247ad9c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds = CommonLitDataset(train_df, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ee04e-2d41-46bc-89e0-c0b9476090cb",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2ef269a-01da-4555-bdb7-265d93940648",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, hidden_dim, num_targets):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        \n",
    "        self.hidden_layer = nn.Linear(in_features, hidden_dim)\n",
    "        self.final_layer = nn.Linear(hidden_dim, num_targets)\n",
    "        self.out_features = hidden_dim\n",
    "        \n",
    "    def forward(self, features):\n",
    "        att = torch.tanh(self.hidden_layer(features))\n",
    "        score = self.final_layer(att)\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "        return attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f7c88c-5970-4b12-bb86-ee4a5de126b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonLitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CommonLitModel, self).__init__()\n",
    "        config = AutoConfig.from_pretrained(cfg.ROBERTA_PATH)\n",
    "        config.update({\n",
    "            \"output_hidden_states\": True,\n",
    "            \"hidden_dropout_prob\": 0.0,\n",
    "            \"layer_norm_eps\": 1e-7\n",
    "        })\n",
    "        self.transformer_model = AutoModel.from_pretrained(cfg.ROBERTA_PATH, config=config)\n",
    "        self.attention = AttentionHead(config.hidden_size, 512, 1)\n",
    "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        last_layer_hidden_states = self.transformer_model(input_ids=input_ids, attention_mask=attention_mask)['last_hidden_state']\n",
    "        weights = self.attention(last_layer_hidden_states)\n",
    "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1) \n",
    "        return self.regressor(context_vector), context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aa41e86-dc36-43ae-a98f-e97cbc46fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "sample_model = CommonLitModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01d5b219-2e0e-4485-99ef-3d2ffa0f149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for i, (name, param) in enumerate(sample_model.named_parameters()):\n",
    "    if(name.find('layer') > -1):\n",
    "        layer_name = re.sub(r'.+(layer\\.\\d+).+', r'\\1', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4929919-01cf-47e1-9e9c-3f040562b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 transformer_model.embeddings.word_embeddings.weight torch.Size([128100, 1536])\n",
      "1 transformer_model.embeddings.LayerNorm.weight torch.Size([1536])\n",
      "2 transformer_model.embeddings.LayerNorm.bias torch.Size([1536])\n",
      "3 transformer_model.encoder.layer.0.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "4 transformer_model.encoder.layer.0.attention.self.query_proj.bias torch.Size([1536])\n",
      "5 transformer_model.encoder.layer.0.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "6 transformer_model.encoder.layer.0.attention.self.key_proj.bias torch.Size([1536])\n",
      "7 transformer_model.encoder.layer.0.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "8 transformer_model.encoder.layer.0.attention.self.value_proj.bias torch.Size([1536])\n",
      "9 transformer_model.encoder.layer.0.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "10 transformer_model.encoder.layer.0.attention.output.dense.bias torch.Size([1536])\n",
      "11 transformer_model.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "12 transformer_model.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "13 transformer_model.encoder.layer.0.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "14 transformer_model.encoder.layer.0.intermediate.dense.bias torch.Size([6144])\n",
      "15 transformer_model.encoder.layer.0.output.dense.weight torch.Size([1536, 6144])\n",
      "16 transformer_model.encoder.layer.0.output.dense.bias torch.Size([1536])\n",
      "17 transformer_model.encoder.layer.0.output.LayerNorm.weight torch.Size([1536])\n",
      "18 transformer_model.encoder.layer.0.output.LayerNorm.bias torch.Size([1536])\n",
      "19 transformer_model.encoder.layer.1.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "20 transformer_model.encoder.layer.1.attention.self.query_proj.bias torch.Size([1536])\n",
      "21 transformer_model.encoder.layer.1.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "22 transformer_model.encoder.layer.1.attention.self.key_proj.bias torch.Size([1536])\n",
      "23 transformer_model.encoder.layer.1.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "24 transformer_model.encoder.layer.1.attention.self.value_proj.bias torch.Size([1536])\n",
      "25 transformer_model.encoder.layer.1.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "26 transformer_model.encoder.layer.1.attention.output.dense.bias torch.Size([1536])\n",
      "27 transformer_model.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "28 transformer_model.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "29 transformer_model.encoder.layer.1.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "30 transformer_model.encoder.layer.1.intermediate.dense.bias torch.Size([6144])\n",
      "31 transformer_model.encoder.layer.1.output.dense.weight torch.Size([1536, 6144])\n",
      "32 transformer_model.encoder.layer.1.output.dense.bias torch.Size([1536])\n",
      "33 transformer_model.encoder.layer.1.output.LayerNorm.weight torch.Size([1536])\n",
      "34 transformer_model.encoder.layer.1.output.LayerNorm.bias torch.Size([1536])\n",
      "35 transformer_model.encoder.layer.2.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "36 transformer_model.encoder.layer.2.attention.self.query_proj.bias torch.Size([1536])\n",
      "37 transformer_model.encoder.layer.2.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "38 transformer_model.encoder.layer.2.attention.self.key_proj.bias torch.Size([1536])\n",
      "39 transformer_model.encoder.layer.2.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "40 transformer_model.encoder.layer.2.attention.self.value_proj.bias torch.Size([1536])\n",
      "41 transformer_model.encoder.layer.2.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "42 transformer_model.encoder.layer.2.attention.output.dense.bias torch.Size([1536])\n",
      "43 transformer_model.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "44 transformer_model.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "45 transformer_model.encoder.layer.2.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "46 transformer_model.encoder.layer.2.intermediate.dense.bias torch.Size([6144])\n",
      "47 transformer_model.encoder.layer.2.output.dense.weight torch.Size([1536, 6144])\n",
      "48 transformer_model.encoder.layer.2.output.dense.bias torch.Size([1536])\n",
      "49 transformer_model.encoder.layer.2.output.LayerNorm.weight torch.Size([1536])\n",
      "50 transformer_model.encoder.layer.2.output.LayerNorm.bias torch.Size([1536])\n",
      "51 transformer_model.encoder.layer.3.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "52 transformer_model.encoder.layer.3.attention.self.query_proj.bias torch.Size([1536])\n",
      "53 transformer_model.encoder.layer.3.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "54 transformer_model.encoder.layer.3.attention.self.key_proj.bias torch.Size([1536])\n",
      "55 transformer_model.encoder.layer.3.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "56 transformer_model.encoder.layer.3.attention.self.value_proj.bias torch.Size([1536])\n",
      "57 transformer_model.encoder.layer.3.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "58 transformer_model.encoder.layer.3.attention.output.dense.bias torch.Size([1536])\n",
      "59 transformer_model.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "60 transformer_model.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "61 transformer_model.encoder.layer.3.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "62 transformer_model.encoder.layer.3.intermediate.dense.bias torch.Size([6144])\n",
      "63 transformer_model.encoder.layer.3.output.dense.weight torch.Size([1536, 6144])\n",
      "64 transformer_model.encoder.layer.3.output.dense.bias torch.Size([1536])\n",
      "65 transformer_model.encoder.layer.3.output.LayerNorm.weight torch.Size([1536])\n",
      "66 transformer_model.encoder.layer.3.output.LayerNorm.bias torch.Size([1536])\n",
      "67 transformer_model.encoder.layer.4.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "68 transformer_model.encoder.layer.4.attention.self.query_proj.bias torch.Size([1536])\n",
      "69 transformer_model.encoder.layer.4.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "70 transformer_model.encoder.layer.4.attention.self.key_proj.bias torch.Size([1536])\n",
      "71 transformer_model.encoder.layer.4.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "72 transformer_model.encoder.layer.4.attention.self.value_proj.bias torch.Size([1536])\n",
      "73 transformer_model.encoder.layer.4.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "74 transformer_model.encoder.layer.4.attention.output.dense.bias torch.Size([1536])\n",
      "75 transformer_model.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "76 transformer_model.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "77 transformer_model.encoder.layer.4.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "78 transformer_model.encoder.layer.4.intermediate.dense.bias torch.Size([6144])\n",
      "79 transformer_model.encoder.layer.4.output.dense.weight torch.Size([1536, 6144])\n",
      "80 transformer_model.encoder.layer.4.output.dense.bias torch.Size([1536])\n",
      "81 transformer_model.encoder.layer.4.output.LayerNorm.weight torch.Size([1536])\n",
      "82 transformer_model.encoder.layer.4.output.LayerNorm.bias torch.Size([1536])\n",
      "83 transformer_model.encoder.layer.5.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "84 transformer_model.encoder.layer.5.attention.self.query_proj.bias torch.Size([1536])\n",
      "85 transformer_model.encoder.layer.5.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "86 transformer_model.encoder.layer.5.attention.self.key_proj.bias torch.Size([1536])\n",
      "87 transformer_model.encoder.layer.5.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "88 transformer_model.encoder.layer.5.attention.self.value_proj.bias torch.Size([1536])\n",
      "89 transformer_model.encoder.layer.5.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "90 transformer_model.encoder.layer.5.attention.output.dense.bias torch.Size([1536])\n",
      "91 transformer_model.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "92 transformer_model.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "93 transformer_model.encoder.layer.5.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "94 transformer_model.encoder.layer.5.intermediate.dense.bias torch.Size([6144])\n",
      "95 transformer_model.encoder.layer.5.output.dense.weight torch.Size([1536, 6144])\n",
      "96 transformer_model.encoder.layer.5.output.dense.bias torch.Size([1536])\n",
      "97 transformer_model.encoder.layer.5.output.LayerNorm.weight torch.Size([1536])\n",
      "98 transformer_model.encoder.layer.5.output.LayerNorm.bias torch.Size([1536])\n",
      "99 transformer_model.encoder.layer.6.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "100 transformer_model.encoder.layer.6.attention.self.query_proj.bias torch.Size([1536])\n",
      "101 transformer_model.encoder.layer.6.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "102 transformer_model.encoder.layer.6.attention.self.key_proj.bias torch.Size([1536])\n",
      "103 transformer_model.encoder.layer.6.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "104 transformer_model.encoder.layer.6.attention.self.value_proj.bias torch.Size([1536])\n",
      "105 transformer_model.encoder.layer.6.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "106 transformer_model.encoder.layer.6.attention.output.dense.bias torch.Size([1536])\n",
      "107 transformer_model.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "108 transformer_model.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "109 transformer_model.encoder.layer.6.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "110 transformer_model.encoder.layer.6.intermediate.dense.bias torch.Size([6144])\n",
      "111 transformer_model.encoder.layer.6.output.dense.weight torch.Size([1536, 6144])\n",
      "112 transformer_model.encoder.layer.6.output.dense.bias torch.Size([1536])\n",
      "113 transformer_model.encoder.layer.6.output.LayerNorm.weight torch.Size([1536])\n",
      "114 transformer_model.encoder.layer.6.output.LayerNorm.bias torch.Size([1536])\n",
      "115 transformer_model.encoder.layer.7.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "116 transformer_model.encoder.layer.7.attention.self.query_proj.bias torch.Size([1536])\n",
      "117 transformer_model.encoder.layer.7.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "118 transformer_model.encoder.layer.7.attention.self.key_proj.bias torch.Size([1536])\n",
      "119 transformer_model.encoder.layer.7.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "120 transformer_model.encoder.layer.7.attention.self.value_proj.bias torch.Size([1536])\n",
      "121 transformer_model.encoder.layer.7.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "122 transformer_model.encoder.layer.7.attention.output.dense.bias torch.Size([1536])\n",
      "123 transformer_model.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "124 transformer_model.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "125 transformer_model.encoder.layer.7.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "126 transformer_model.encoder.layer.7.intermediate.dense.bias torch.Size([6144])\n",
      "127 transformer_model.encoder.layer.7.output.dense.weight torch.Size([1536, 6144])\n",
      "128 transformer_model.encoder.layer.7.output.dense.bias torch.Size([1536])\n",
      "129 transformer_model.encoder.layer.7.output.LayerNorm.weight torch.Size([1536])\n",
      "130 transformer_model.encoder.layer.7.output.LayerNorm.bias torch.Size([1536])\n",
      "131 transformer_model.encoder.layer.8.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "132 transformer_model.encoder.layer.8.attention.self.query_proj.bias torch.Size([1536])\n",
      "133 transformer_model.encoder.layer.8.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "134 transformer_model.encoder.layer.8.attention.self.key_proj.bias torch.Size([1536])\n",
      "135 transformer_model.encoder.layer.8.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "136 transformer_model.encoder.layer.8.attention.self.value_proj.bias torch.Size([1536])\n",
      "137 transformer_model.encoder.layer.8.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "138 transformer_model.encoder.layer.8.attention.output.dense.bias torch.Size([1536])\n",
      "139 transformer_model.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "140 transformer_model.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "141 transformer_model.encoder.layer.8.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "142 transformer_model.encoder.layer.8.intermediate.dense.bias torch.Size([6144])\n",
      "143 transformer_model.encoder.layer.8.output.dense.weight torch.Size([1536, 6144])\n",
      "144 transformer_model.encoder.layer.8.output.dense.bias torch.Size([1536])\n",
      "145 transformer_model.encoder.layer.8.output.LayerNorm.weight torch.Size([1536])\n",
      "146 transformer_model.encoder.layer.8.output.LayerNorm.bias torch.Size([1536])\n",
      "147 transformer_model.encoder.layer.9.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "148 transformer_model.encoder.layer.9.attention.self.query_proj.bias torch.Size([1536])\n",
      "149 transformer_model.encoder.layer.9.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "150 transformer_model.encoder.layer.9.attention.self.key_proj.bias torch.Size([1536])\n",
      "151 transformer_model.encoder.layer.9.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "152 transformer_model.encoder.layer.9.attention.self.value_proj.bias torch.Size([1536])\n",
      "153 transformer_model.encoder.layer.9.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "154 transformer_model.encoder.layer.9.attention.output.dense.bias torch.Size([1536])\n",
      "155 transformer_model.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "156 transformer_model.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "157 transformer_model.encoder.layer.9.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "158 transformer_model.encoder.layer.9.intermediate.dense.bias torch.Size([6144])\n",
      "159 transformer_model.encoder.layer.9.output.dense.weight torch.Size([1536, 6144])\n",
      "160 transformer_model.encoder.layer.9.output.dense.bias torch.Size([1536])\n",
      "161 transformer_model.encoder.layer.9.output.LayerNorm.weight torch.Size([1536])\n",
      "162 transformer_model.encoder.layer.9.output.LayerNorm.bias torch.Size([1536])\n",
      "163 transformer_model.encoder.layer.10.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "164 transformer_model.encoder.layer.10.attention.self.query_proj.bias torch.Size([1536])\n",
      "165 transformer_model.encoder.layer.10.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "166 transformer_model.encoder.layer.10.attention.self.key_proj.bias torch.Size([1536])\n",
      "167 transformer_model.encoder.layer.10.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "168 transformer_model.encoder.layer.10.attention.self.value_proj.bias torch.Size([1536])\n",
      "169 transformer_model.encoder.layer.10.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "170 transformer_model.encoder.layer.10.attention.output.dense.bias torch.Size([1536])\n",
      "171 transformer_model.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "172 transformer_model.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "173 transformer_model.encoder.layer.10.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "174 transformer_model.encoder.layer.10.intermediate.dense.bias torch.Size([6144])\n",
      "175 transformer_model.encoder.layer.10.output.dense.weight torch.Size([1536, 6144])\n",
      "176 transformer_model.encoder.layer.10.output.dense.bias torch.Size([1536])\n",
      "177 transformer_model.encoder.layer.10.output.LayerNorm.weight torch.Size([1536])\n",
      "178 transformer_model.encoder.layer.10.output.LayerNorm.bias torch.Size([1536])\n",
      "179 transformer_model.encoder.layer.11.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "180 transformer_model.encoder.layer.11.attention.self.query_proj.bias torch.Size([1536])\n",
      "181 transformer_model.encoder.layer.11.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "182 transformer_model.encoder.layer.11.attention.self.key_proj.bias torch.Size([1536])\n",
      "183 transformer_model.encoder.layer.11.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "184 transformer_model.encoder.layer.11.attention.self.value_proj.bias torch.Size([1536])\n",
      "185 transformer_model.encoder.layer.11.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "186 transformer_model.encoder.layer.11.attention.output.dense.bias torch.Size([1536])\n",
      "187 transformer_model.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "188 transformer_model.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "189 transformer_model.encoder.layer.11.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "190 transformer_model.encoder.layer.11.intermediate.dense.bias torch.Size([6144])\n",
      "191 transformer_model.encoder.layer.11.output.dense.weight torch.Size([1536, 6144])\n",
      "192 transformer_model.encoder.layer.11.output.dense.bias torch.Size([1536])\n",
      "193 transformer_model.encoder.layer.11.output.LayerNorm.weight torch.Size([1536])\n",
      "194 transformer_model.encoder.layer.11.output.LayerNorm.bias torch.Size([1536])\n",
      "195 transformer_model.encoder.layer.12.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "196 transformer_model.encoder.layer.12.attention.self.query_proj.bias torch.Size([1536])\n",
      "197 transformer_model.encoder.layer.12.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "198 transformer_model.encoder.layer.12.attention.self.key_proj.bias torch.Size([1536])\n",
      "199 transformer_model.encoder.layer.12.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "200 transformer_model.encoder.layer.12.attention.self.value_proj.bias torch.Size([1536])\n",
      "201 transformer_model.encoder.layer.12.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "202 transformer_model.encoder.layer.12.attention.output.dense.bias torch.Size([1536])\n",
      "203 transformer_model.encoder.layer.12.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "204 transformer_model.encoder.layer.12.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "205 transformer_model.encoder.layer.12.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "206 transformer_model.encoder.layer.12.intermediate.dense.bias torch.Size([6144])\n",
      "207 transformer_model.encoder.layer.12.output.dense.weight torch.Size([1536, 6144])\n",
      "208 transformer_model.encoder.layer.12.output.dense.bias torch.Size([1536])\n",
      "209 transformer_model.encoder.layer.12.output.LayerNorm.weight torch.Size([1536])\n",
      "210 transformer_model.encoder.layer.12.output.LayerNorm.bias torch.Size([1536])\n",
      "211 transformer_model.encoder.layer.13.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "212 transformer_model.encoder.layer.13.attention.self.query_proj.bias torch.Size([1536])\n",
      "213 transformer_model.encoder.layer.13.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "214 transformer_model.encoder.layer.13.attention.self.key_proj.bias torch.Size([1536])\n",
      "215 transformer_model.encoder.layer.13.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "216 transformer_model.encoder.layer.13.attention.self.value_proj.bias torch.Size([1536])\n",
      "217 transformer_model.encoder.layer.13.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "218 transformer_model.encoder.layer.13.attention.output.dense.bias torch.Size([1536])\n",
      "219 transformer_model.encoder.layer.13.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "220 transformer_model.encoder.layer.13.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "221 transformer_model.encoder.layer.13.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "222 transformer_model.encoder.layer.13.intermediate.dense.bias torch.Size([6144])\n",
      "223 transformer_model.encoder.layer.13.output.dense.weight torch.Size([1536, 6144])\n",
      "224 transformer_model.encoder.layer.13.output.dense.bias torch.Size([1536])\n",
      "225 transformer_model.encoder.layer.13.output.LayerNorm.weight torch.Size([1536])\n",
      "226 transformer_model.encoder.layer.13.output.LayerNorm.bias torch.Size([1536])\n",
      "227 transformer_model.encoder.layer.14.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "228 transformer_model.encoder.layer.14.attention.self.query_proj.bias torch.Size([1536])\n",
      "229 transformer_model.encoder.layer.14.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "230 transformer_model.encoder.layer.14.attention.self.key_proj.bias torch.Size([1536])\n",
      "231 transformer_model.encoder.layer.14.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "232 transformer_model.encoder.layer.14.attention.self.value_proj.bias torch.Size([1536])\n",
      "233 transformer_model.encoder.layer.14.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "234 transformer_model.encoder.layer.14.attention.output.dense.bias torch.Size([1536])\n",
      "235 transformer_model.encoder.layer.14.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "236 transformer_model.encoder.layer.14.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "237 transformer_model.encoder.layer.14.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "238 transformer_model.encoder.layer.14.intermediate.dense.bias torch.Size([6144])\n",
      "239 transformer_model.encoder.layer.14.output.dense.weight torch.Size([1536, 6144])\n",
      "240 transformer_model.encoder.layer.14.output.dense.bias torch.Size([1536])\n",
      "241 transformer_model.encoder.layer.14.output.LayerNorm.weight torch.Size([1536])\n",
      "242 transformer_model.encoder.layer.14.output.LayerNorm.bias torch.Size([1536])\n",
      "243 transformer_model.encoder.layer.15.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "244 transformer_model.encoder.layer.15.attention.self.query_proj.bias torch.Size([1536])\n",
      "245 transformer_model.encoder.layer.15.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "246 transformer_model.encoder.layer.15.attention.self.key_proj.bias torch.Size([1536])\n",
      "247 transformer_model.encoder.layer.15.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "248 transformer_model.encoder.layer.15.attention.self.value_proj.bias torch.Size([1536])\n",
      "249 transformer_model.encoder.layer.15.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "250 transformer_model.encoder.layer.15.attention.output.dense.bias torch.Size([1536])\n",
      "251 transformer_model.encoder.layer.15.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "252 transformer_model.encoder.layer.15.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "253 transformer_model.encoder.layer.15.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "254 transformer_model.encoder.layer.15.intermediate.dense.bias torch.Size([6144])\n",
      "255 transformer_model.encoder.layer.15.output.dense.weight torch.Size([1536, 6144])\n",
      "256 transformer_model.encoder.layer.15.output.dense.bias torch.Size([1536])\n",
      "257 transformer_model.encoder.layer.15.output.LayerNorm.weight torch.Size([1536])\n",
      "258 transformer_model.encoder.layer.15.output.LayerNorm.bias torch.Size([1536])\n",
      "259 transformer_model.encoder.layer.16.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "260 transformer_model.encoder.layer.16.attention.self.query_proj.bias torch.Size([1536])\n",
      "261 transformer_model.encoder.layer.16.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "262 transformer_model.encoder.layer.16.attention.self.key_proj.bias torch.Size([1536])\n",
      "263 transformer_model.encoder.layer.16.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "264 transformer_model.encoder.layer.16.attention.self.value_proj.bias torch.Size([1536])\n",
      "265 transformer_model.encoder.layer.16.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "266 transformer_model.encoder.layer.16.attention.output.dense.bias torch.Size([1536])\n",
      "267 transformer_model.encoder.layer.16.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "268 transformer_model.encoder.layer.16.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "269 transformer_model.encoder.layer.16.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "270 transformer_model.encoder.layer.16.intermediate.dense.bias torch.Size([6144])\n",
      "271 transformer_model.encoder.layer.16.output.dense.weight torch.Size([1536, 6144])\n",
      "272 transformer_model.encoder.layer.16.output.dense.bias torch.Size([1536])\n",
      "273 transformer_model.encoder.layer.16.output.LayerNorm.weight torch.Size([1536])\n",
      "274 transformer_model.encoder.layer.16.output.LayerNorm.bias torch.Size([1536])\n",
      "275 transformer_model.encoder.layer.17.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "276 transformer_model.encoder.layer.17.attention.self.query_proj.bias torch.Size([1536])\n",
      "277 transformer_model.encoder.layer.17.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "278 transformer_model.encoder.layer.17.attention.self.key_proj.bias torch.Size([1536])\n",
      "279 transformer_model.encoder.layer.17.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "280 transformer_model.encoder.layer.17.attention.self.value_proj.bias torch.Size([1536])\n",
      "281 transformer_model.encoder.layer.17.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "282 transformer_model.encoder.layer.17.attention.output.dense.bias torch.Size([1536])\n",
      "283 transformer_model.encoder.layer.17.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "284 transformer_model.encoder.layer.17.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "285 transformer_model.encoder.layer.17.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "286 transformer_model.encoder.layer.17.intermediate.dense.bias torch.Size([6144])\n",
      "287 transformer_model.encoder.layer.17.output.dense.weight torch.Size([1536, 6144])\n",
      "288 transformer_model.encoder.layer.17.output.dense.bias torch.Size([1536])\n",
      "289 transformer_model.encoder.layer.17.output.LayerNorm.weight torch.Size([1536])\n",
      "290 transformer_model.encoder.layer.17.output.LayerNorm.bias torch.Size([1536])\n",
      "291 transformer_model.encoder.layer.18.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "292 transformer_model.encoder.layer.18.attention.self.query_proj.bias torch.Size([1536])\n",
      "293 transformer_model.encoder.layer.18.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "294 transformer_model.encoder.layer.18.attention.self.key_proj.bias torch.Size([1536])\n",
      "295 transformer_model.encoder.layer.18.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "296 transformer_model.encoder.layer.18.attention.self.value_proj.bias torch.Size([1536])\n",
      "297 transformer_model.encoder.layer.18.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "298 transformer_model.encoder.layer.18.attention.output.dense.bias torch.Size([1536])\n",
      "299 transformer_model.encoder.layer.18.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "300 transformer_model.encoder.layer.18.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "301 transformer_model.encoder.layer.18.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "302 transformer_model.encoder.layer.18.intermediate.dense.bias torch.Size([6144])\n",
      "303 transformer_model.encoder.layer.18.output.dense.weight torch.Size([1536, 6144])\n",
      "304 transformer_model.encoder.layer.18.output.dense.bias torch.Size([1536])\n",
      "305 transformer_model.encoder.layer.18.output.LayerNorm.weight torch.Size([1536])\n",
      "306 transformer_model.encoder.layer.18.output.LayerNorm.bias torch.Size([1536])\n",
      "307 transformer_model.encoder.layer.19.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "308 transformer_model.encoder.layer.19.attention.self.query_proj.bias torch.Size([1536])\n",
      "309 transformer_model.encoder.layer.19.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "310 transformer_model.encoder.layer.19.attention.self.key_proj.bias torch.Size([1536])\n",
      "311 transformer_model.encoder.layer.19.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "312 transformer_model.encoder.layer.19.attention.self.value_proj.bias torch.Size([1536])\n",
      "313 transformer_model.encoder.layer.19.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "314 transformer_model.encoder.layer.19.attention.output.dense.bias torch.Size([1536])\n",
      "315 transformer_model.encoder.layer.19.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "316 transformer_model.encoder.layer.19.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "317 transformer_model.encoder.layer.19.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "318 transformer_model.encoder.layer.19.intermediate.dense.bias torch.Size([6144])\n",
      "319 transformer_model.encoder.layer.19.output.dense.weight torch.Size([1536, 6144])\n",
      "320 transformer_model.encoder.layer.19.output.dense.bias torch.Size([1536])\n",
      "321 transformer_model.encoder.layer.19.output.LayerNorm.weight torch.Size([1536])\n",
      "322 transformer_model.encoder.layer.19.output.LayerNorm.bias torch.Size([1536])\n",
      "323 transformer_model.encoder.layer.20.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "324 transformer_model.encoder.layer.20.attention.self.query_proj.bias torch.Size([1536])\n",
      "325 transformer_model.encoder.layer.20.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "326 transformer_model.encoder.layer.20.attention.self.key_proj.bias torch.Size([1536])\n",
      "327 transformer_model.encoder.layer.20.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "328 transformer_model.encoder.layer.20.attention.self.value_proj.bias torch.Size([1536])\n",
      "329 transformer_model.encoder.layer.20.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "330 transformer_model.encoder.layer.20.attention.output.dense.bias torch.Size([1536])\n",
      "331 transformer_model.encoder.layer.20.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "332 transformer_model.encoder.layer.20.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "333 transformer_model.encoder.layer.20.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "334 transformer_model.encoder.layer.20.intermediate.dense.bias torch.Size([6144])\n",
      "335 transformer_model.encoder.layer.20.output.dense.weight torch.Size([1536, 6144])\n",
      "336 transformer_model.encoder.layer.20.output.dense.bias torch.Size([1536])\n",
      "337 transformer_model.encoder.layer.20.output.LayerNorm.weight torch.Size([1536])\n",
      "338 transformer_model.encoder.layer.20.output.LayerNorm.bias torch.Size([1536])\n",
      "339 transformer_model.encoder.layer.21.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "340 transformer_model.encoder.layer.21.attention.self.query_proj.bias torch.Size([1536])\n",
      "341 transformer_model.encoder.layer.21.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "342 transformer_model.encoder.layer.21.attention.self.key_proj.bias torch.Size([1536])\n",
      "343 transformer_model.encoder.layer.21.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "344 transformer_model.encoder.layer.21.attention.self.value_proj.bias torch.Size([1536])\n",
      "345 transformer_model.encoder.layer.21.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "346 transformer_model.encoder.layer.21.attention.output.dense.bias torch.Size([1536])\n",
      "347 transformer_model.encoder.layer.21.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "348 transformer_model.encoder.layer.21.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "349 transformer_model.encoder.layer.21.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "350 transformer_model.encoder.layer.21.intermediate.dense.bias torch.Size([6144])\n",
      "351 transformer_model.encoder.layer.21.output.dense.weight torch.Size([1536, 6144])\n",
      "352 transformer_model.encoder.layer.21.output.dense.bias torch.Size([1536])\n",
      "353 transformer_model.encoder.layer.21.output.LayerNorm.weight torch.Size([1536])\n",
      "354 transformer_model.encoder.layer.21.output.LayerNorm.bias torch.Size([1536])\n",
      "355 transformer_model.encoder.layer.22.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "356 transformer_model.encoder.layer.22.attention.self.query_proj.bias torch.Size([1536])\n",
      "357 transformer_model.encoder.layer.22.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "358 transformer_model.encoder.layer.22.attention.self.key_proj.bias torch.Size([1536])\n",
      "359 transformer_model.encoder.layer.22.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "360 transformer_model.encoder.layer.22.attention.self.value_proj.bias torch.Size([1536])\n",
      "361 transformer_model.encoder.layer.22.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "362 transformer_model.encoder.layer.22.attention.output.dense.bias torch.Size([1536])\n",
      "363 transformer_model.encoder.layer.22.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "364 transformer_model.encoder.layer.22.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "365 transformer_model.encoder.layer.22.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "366 transformer_model.encoder.layer.22.intermediate.dense.bias torch.Size([6144])\n",
      "367 transformer_model.encoder.layer.22.output.dense.weight torch.Size([1536, 6144])\n",
      "368 transformer_model.encoder.layer.22.output.dense.bias torch.Size([1536])\n",
      "369 transformer_model.encoder.layer.22.output.LayerNorm.weight torch.Size([1536])\n",
      "370 transformer_model.encoder.layer.22.output.LayerNorm.bias torch.Size([1536])\n",
      "371 transformer_model.encoder.layer.23.attention.self.query_proj.weight torch.Size([1536, 1536])\n",
      "372 transformer_model.encoder.layer.23.attention.self.query_proj.bias torch.Size([1536])\n",
      "373 transformer_model.encoder.layer.23.attention.self.key_proj.weight torch.Size([1536, 1536])\n",
      "374 transformer_model.encoder.layer.23.attention.self.key_proj.bias torch.Size([1536])\n",
      "375 transformer_model.encoder.layer.23.attention.self.value_proj.weight torch.Size([1536, 1536])\n",
      "376 transformer_model.encoder.layer.23.attention.self.value_proj.bias torch.Size([1536])\n",
      "377 transformer_model.encoder.layer.23.attention.output.dense.weight torch.Size([1536, 1536])\n",
      "378 transformer_model.encoder.layer.23.attention.output.dense.bias torch.Size([1536])\n",
      "379 transformer_model.encoder.layer.23.attention.output.LayerNorm.weight torch.Size([1536])\n",
      "380 transformer_model.encoder.layer.23.attention.output.LayerNorm.bias torch.Size([1536])\n",
      "381 transformer_model.encoder.layer.23.intermediate.dense.weight torch.Size([6144, 1536])\n",
      "382 transformer_model.encoder.layer.23.intermediate.dense.bias torch.Size([6144])\n",
      "383 transformer_model.encoder.layer.23.output.dense.weight torch.Size([1536, 6144])\n",
      "384 transformer_model.encoder.layer.23.output.dense.bias torch.Size([1536])\n",
      "385 transformer_model.encoder.layer.23.output.LayerNorm.weight torch.Size([1536])\n",
      "386 transformer_model.encoder.layer.23.output.LayerNorm.bias torch.Size([1536])\n",
      "387 transformer_model.encoder.rel_embeddings.weight torch.Size([512, 1536])\n",
      "388 transformer_model.encoder.LayerNorm.weight torch.Size([1536])\n",
      "389 transformer_model.encoder.LayerNorm.bias torch.Size([1536])\n",
      "390 transformer_model.encoder.conv.conv.weight torch.Size([1536, 1536, 3])\n",
      "391 transformer_model.encoder.conv.conv.bias torch.Size([1536])\n",
      "392 transformer_model.encoder.conv.LayerNorm.weight torch.Size([1536])\n",
      "393 transformer_model.encoder.conv.LayerNorm.bias torch.Size([1536])\n",
      "394 attention.hidden_layer.weight torch.Size([512, 1536])\n",
      "395 attention.hidden_layer.bias torch.Size([512])\n",
      "396 attention.final_layer.weight torch.Size([1, 512])\n",
      "397 attention.final_layer.bias torch.Size([1])\n",
      "398 regressor.weight torch.Size([1, 1536])\n",
      "399 regressor.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for i, (name, param) in enumerate(sample_model.named_parameters()):\n",
    "    print(i, name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c04f3dd-285e-4d70-8dd5-37fc2737ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input_ids = torch.randint(0, 1000, [8, 248])\n",
    "sample_attention_mask = torch.randint(0, 1000, [8, 248])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31ded8f5-d2ec-465f-88ca-317bf1954026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1536])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model(sample_input_ids, sample_attention_mask)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb86b195-8d45-41e2-9042-7007e416d916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-29.1539,  10.5193,   4.8170,  ...,  -4.6910,  -4.8709, -23.6917],\n",
       "        [ 31.2577,  -1.6726,  -2.4526,  ..., -13.7970, -37.0621,  27.6887],\n",
       "        [-21.3302,  18.4718,  16.2454,  ..., -34.2290,  -2.8959,   4.5172],\n",
       "        ...,\n",
       "        [  7.5623,  -4.1929, -39.9838,  ...,  -8.3921, -19.0073,  -6.9267],\n",
       "        [ 24.4055,   8.4576,  -6.3430,  ..., -23.9439,  13.3083, -16.9619],\n",
       "        [-13.6124,  -5.5589,  17.4086,  ..., -12.3878, -53.0160, -11.6563]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.randn([8, 496, 768]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4bb67f-bc5f-4f90-8236-7f7eb949ec92",
   "metadata": {},
   "source": [
    "### Evaluation and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31f7c55d-a9c2-4e76-a7ef-42acd56f7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mse(model, data_loader):\n",
    "    model.eval()\n",
    "    mse_sum = 0\n",
    "    mse_loss = nn.MSELoss(reduction='sum')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, record in enumerate(data_loader):\n",
    "            input_ids, attention_mask, target = record['input_ids'].to(cfg.DEVICE), record['attention_mask'].to(cfg.DEVICE), record['target'].to(cfg.DEVICE)\n",
    "            pred, _ = model(input_ids, attention_mask)\n",
    "            mse_sum += mse_loss(pred.flatten().cpu(), target.cpu())\n",
    "            \n",
    "    return mse_sum / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b035767-df66-428f-a297-6db704dfc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "    result = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, record in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            input_ids, attention_mask = record['input_ids'].to(cfg.DEVICE), record['attention_mask'].to(cfg.DEVICE)\n",
    "            pred, _ = model(input_ids, attention_mask)\n",
    "            result.extend(pred.flatten().to(\"cpu\").tolist())\n",
    "            \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b90cd468-30bf-4362-824b-480820edb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dl = DataLoader(sample_ds, shuffle=False, batch_size=16, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0ec5d-7c5f-4a70-b792-7cb822fb35ce",
   "metadata": {},
   "source": [
    "### Optimizer and Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fd22b6b-dd73-41b1-81a4-af5e3261207e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2e-05, 0.0001, 5e-05)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5e-5 / 2.5, 5e-5 / 0.5, 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04c43c63-bdf7-4493-9f76-7b96b4c3f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(model, base_lr=5e-5, last_lr=None):\n",
    "    named_parameters = list(model.named_parameters())\n",
    "    \n",
    "    regressor_param_start = 398\n",
    "    attention_param_start = 394\n",
    "    roberta_parameters = named_parameters[:attention_param_start]\n",
    "    attention_parameters = named_parameters[attention_param_start:regressor_param_start]\n",
    "    regressor_parameters = named_parameters[regressor_param_start:]\n",
    "    \n",
    "    attention_group = [params for (name, params) in attention_parameters]\n",
    "    regressor_group = [params for (name, params) in regressor_parameters]\n",
    "    \n",
    "    parameters = []\n",
    "    if last_lr is not None:\n",
    "        parameters.append({\"params\": attention_group, \"lr\": last_lr})\n",
    "        parameters.append({\"params\": regressor_group, \"lr\": last_lr})\n",
    "    else:\n",
    "        parameters.append({\"params\": attention_group})\n",
    "        parameters.append({\"params\": regressor_group})\n",
    "    \n",
    "    for layer_num, (name, params) in enumerate(roberta_parameters):\n",
    "        weight_decay = 0.0 if 'bias' in name else 0.01\n",
    "        \n",
    "        lr = base_lr / 2.5 # 2e-05\n",
    "        if layer_num >= 260:\n",
    "            lr = base_lr / 0.5 # 1e-4\n",
    "        elif layer_num >= 132:        \n",
    "            lr = base_lr    \n",
    "            \n",
    "        parameters.append({\"params\": params,\n",
    "                           \"weight_decay\": weight_decay,\n",
    "                           \"lr\": lr})\n",
    "        \n",
    "    return AdamW(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dd255e8-4568-4dfa-abd2-a429f9d545b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_optimizer = create_optimizer(sample_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4830178b-dff7-4635-a447-b9da1ca1ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler,SequentialSampler,RandomSampler,SubsetRandomSampler\n",
    "from collections import Counter\n",
    "\n",
    "class WeightedSampler(Sampler):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        \n",
    "        self.indices = list(range(len(dataset)))\n",
    "        self.num_samples = len(dataset)\n",
    "        self.label_to_count = dict(Counter(dataset.bins))\n",
    "        weights = [1/self.label_to_count[i] for i in dataset.bins]\n",
    "        \n",
    "        self.weights = torch.tensor(weights,dtype=torch.double)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        index = [self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True)]\n",
    "        while count < self.num_samples:\n",
    "            yield index[count]\n",
    "            count += 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7de8f75-5e7a-45d0-8029-ea6146ea2b48",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89e6e9bd-9ae3-4871-a47d-37ed129634fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_eval_period(val_rmse):\n",
    "    for rmse, period in cfg.EVAL_SCHEDULE:\n",
    "        if val_rmse >= rmse:\n",
    "            return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2501f5b3-fffb-42c7-8fcb-9f026d32499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_best(best_val_rmse, best_epoch, val_rmse, epoch, model, model_path):\n",
    "    if not best_val_rmse or val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_epoch = epoch\n",
    "        if not model_path.parent.exists():\n",
    "            os.makedirs(model_path.parent)\n",
    "        \n",
    "#         torch.save(model.state_dict(), model_path)\n",
    "        print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n",
    "    else:       \n",
    "        print(f\"Still best_val_rmse: {best_val_rmse:0.4}\",\n",
    "              f\"(from epoch {best_epoch})\")\n",
    "    return best_epoch, best_val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01766a88-69dc-4c6d-8dca-2950bdc7e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, scaler, model, model_path, train_loader, val_loader, optimizer, scheduler=None, num_epochs=cfg.NUM_EPOCHS):\n",
    "        self.scaler, self.model, self.model_path, self.train_loader, self.val_loader, self.optimizer, self.scheduler, self.num_epochs = (\n",
    "            scaler, model, model_path, train_loader, val_loader, optimizer, scheduler, num_epochs\n",
    "        )\n",
    "            \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        \n",
    "        mse_loss = nn.MSELoss(reduction='mean')\n",
    "        \n",
    "        best_val_rmse = None\n",
    "        best_epoch = 0\n",
    "        step = 0\n",
    "        last_eval_step = 0\n",
    "        eval_period = cfg.EVAL_SCHEDULE[0][1]    \n",
    "\n",
    "        start = time.time()\n",
    "        val_rmse_list = []\n",
    "        \n",
    "        tbar = tqdm(range(self.num_epochs), total=self.num_epochs)\n",
    "        for epoch in tbar:\n",
    "            tbar.set_description(f'Epoch: {epoch}')\n",
    "            val_rmse = None\n",
    "            for batch_num, record in enumerate(self.train_loader):\n",
    "                input_ids, attention_mask, target = record['input_ids'].to(cfg.DEVICE), record['attention_mask'].to(cfg.DEVICE), record['target'].to(cfg.DEVICE)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # Casts operations to mixed precision\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    pred, _ = self.model(input_ids, attention_mask)\n",
    "                    mse = mse_loss(pred.flatten(), target)\n",
    "                    \n",
    "                self.scaler.scale(mse).backward()\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "                \n",
    "                if self.scheduler:\n",
    "                    self.scheduler.step()\n",
    "                    \n",
    "                if step >= last_eval_step + eval_period:\n",
    "                    elapsed_seconds = time.time() - start\n",
    "                    num_steps = step - last_eval_step\n",
    "                    print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n",
    "                    last_eval_step = step\n",
    "                    \n",
    "                    val_rmse = np.sqrt(eval_mse(self.model, self.val_loader))\n",
    "                    print(f\"Epoch: {epoch} batch_num: {batch_num}\", f\"val_rmse: {val_rmse:0.4} \", end='')\n",
    "                    \n",
    "                    eval_period = choose_eval_period(val_rmse)\n",
    "                    best_epoch, best_val_rmse = serialize_best(best_val_rmse, best_epoch, val_rmse, epoch, self.model, self.model_path)\n",
    "                    val_rmse_list.append(val_rmse)\n",
    "                    start = time.time()\n",
    "                # Finish early on condition\n",
    "                if epoch > 0 and best_val_rmse > 0.6 or (len(val_rmse_list) > 5 and np.array(val_rmse_list).mean() > 1.0):\n",
    "                    return best_val_rmse\n",
    "                \n",
    "                step += 1\n",
    "        return best_val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2692dcf2-a5b7-404f-bb07-3feecb6ec40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=cfg.NUM_FOLDS, random_state=cfg.SEED, shuffle=True)\n",
    "splits = list(kfold.split(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6380179-d1bc-4102-b82f-73b7f8f1c5aa",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61471dbf-6953-4f76-a5ed-ca322f0bc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best results\n",
    "# fold 0: {'base_lr': 4.214048623230046e-05, 'last_lr': 0.00098671139242345}. Best is trial 0 with value: 0.46920305490493774.\n",
    "# fold 1: {'base_lr': 3.4594372607385946e-05, 'last_lr': 0.0005479134338105077}. Best is trial 0 with value: 0.447492390871048\n",
    "# fold 2: {'base_lr': 1.777623134028703e-05, 'last_lr': 0.004132549020616918}. Best is trial 0 with value: 0.46756473183631897\n",
    "# fold 3: {'base_lr': 3.933402254716856e-05, 'last_lr': 0.0018473297738188957}. Best is trial 11 with value: 0.4719877541065216\n",
    "# fold 4: {'base_lr': 1.845975941382356e-05, 'last_lr': 0.0006309278277674714}. Best is trial 15 with value: 0.46920618414878845\n",
    "# fold 5: {'base_lr': 4.430444436442592e-05, 'last_lr': 0.000289231685619846}. Best is trial 6 with value: 0.4629150927066803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1561a06c-a904-4056-8079-ba5cb737567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "\n",
    "def objective(trial):\n",
    "    base_lr = trial.suggest_float(\"base_lr\", 8e-6, 1e-4, log=True)\n",
    "    last_lr = trial.suggest_float(\"last_lr\", 8e-5, 5e-3, log=True)\n",
    "    \n",
    "    print(f'##### Using fold {fold}')\n",
    "    \n",
    "    model_path = cfg.MODEL_FOLDER/f\"{cfg.model_name.replace('/', '_')}_{fold + 1}/model_{fold + 1}.pth\"\n",
    "    \n",
    "    set_random_seed(cfg.SEED + fold)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.TOKENIZER_PATH)\n",
    "    \n",
    "    train_indices, val_indices = splits[fold]\n",
    "    train_dataset = CommonLitDataset(train_df.loc[train_indices], tokenizer)    \n",
    "    val_dataset = CommonLitDataset(train_df.loc[val_indices], tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE,\n",
    "                              drop_last=False, shuffle=True, num_workers=cfg.NUM_WORKERS)    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=cfg.BATCH_SIZE,\n",
    "                            drop_last=False, shuffle=False, num_workers=cfg.NUM_WORKERS)\n",
    "    \n",
    "    set_random_seed(cfg.SEED + fold)\n",
    "    \n",
    "    model = CommonLitModel().to(cfg.DEVICE)\n",
    "    \n",
    "    optimizer = create_optimizer(model, base_lr=base_lr, last_lr=last_lr)\n",
    "    \n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                                num_training_steps=cfg.NUM_EPOCHS * len(train_loader), \n",
    "                                                num_warmup_steps=50)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    trainer = Trainer(scaler, model, model_path, train_loader, val_loader, optimizer, scheduler = scheduler)\n",
    "    rmse_val = trainer.train()\n",
    "    \n",
    "    del trainer\n",
    "    del model\n",
    "    del tokenizer\n",
    "    del scaler\n",
    "    del optimizer\n",
    "    del train_loader\n",
    "    del val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return rmse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98cd27b1-ed98-4a55-97e9-b4980bea91f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1.0, 1.2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efb49c7b-f2b8-4929-bd03-2b74c20361cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 07:41:57,336]\u001b[0m A new study created in memory with name: no-name-a881245d-7346-4862-b493-56f3f86bfd7a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804ef8d17dcf4447a3b50c1553df0d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 14.4 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8687 New best_val_rmse: 0.8687\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7013 New best_val_rmse: 0.7013\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7061 Still best_val_rmse: 0.7013 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.5789 New best_val_rmse: 0.5789\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.566 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.154 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.118 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.028 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.028 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n",
      "16 steps took 10.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 1.027 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 1.029 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 1.03 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 1.058 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 1.04 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 1.031 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 1.057 Still best_val_rmse: 0.5789 (from epoch 0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 07:47:30,223]\u001b[0m Trial 0 finished with value: 0.5788947939872742 and parameters: {'base_lr': 4.255050504122798e-05, 'last_lr': 0.0002484423780636275}. Best is trial 0 with value: 0.5788947939872742.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9d89137fd7438abebbace57f1ea445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.4 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.787 New best_val_rmse: 0.787\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7221 New best_val_rmse: 0.7221\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6812 New best_val_rmse: 0.6812\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7676 Still best_val_rmse: 0.6812 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.252 Still best_val_rmse: 0.6812 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.354 Still best_val_rmse: 0.6812 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.162 Still best_val_rmse: 0.6812 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.044 Still best_val_rmse: 0.6812 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.039 Still best_val_rmse: 0.6812 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 07:50:47,176]\u001b[0m Trial 1 finished with value: 0.6812123656272888 and parameters: {'base_lr': 5.086301579403891e-05, 'last_lr': 0.000596084702860726}. Best is trial 0 with value: 0.5788947939872742.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3faf72980b284a049215fa49a3c52a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8404 New best_val_rmse: 0.8404\n",
      "\n",
      "16 steps took 9.79 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.028 Still best_val_rmse: 0.8404 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.8851 Still best_val_rmse: 0.8404 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.03 Still best_val_rmse: 0.8404 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.044 Still best_val_rmse: 0.8404 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.068 Still best_val_rmse: 0.8404 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.072 Still best_val_rmse: 0.8404 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.056 Still best_val_rmse: 0.8404 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 07:53:39,741]\u001b[0m Trial 2 finished with value: 0.8404358625411987 and parameters: {'base_lr': 6.0245754334936586e-05, 'last_lr': 0.00043769510022136933}. Best is trial 0 with value: 0.5788947939872742.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add8daa186e547a8b533835dfac00ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.002 New best_val_rmse: 1.002\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7556 New best_val_rmse: 0.7556\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6502 New best_val_rmse: 0.6502\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6418 New best_val_rmse: 0.6418\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6452 Still best_val_rmse: 0.6418 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6082 New best_val_rmse: 0.6082\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.8292 Still best_val_rmse: 0.6082 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6088 Still best_val_rmse: 0.6082 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5609 New best_val_rmse: 0.5609\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5449 New best_val_rmse: 0.5449\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.6369 Still best_val_rmse: 0.5449 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5663 Still best_val_rmse: 0.5449 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5738 Still best_val_rmse: 0.5449 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5973 Still best_val_rmse: 0.5449 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5782 Still best_val_rmse: 0.5449 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5346 New best_val_rmse: 0.5346\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5261 New best_val_rmse: 0.5261\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.532 Still best_val_rmse: 0.5261 (from epoch 1)\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5214 New best_val_rmse: 0.5214\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5217 Still best_val_rmse: 0.5214 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.514 New best_val_rmse: 0.514\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5228 Still best_val_rmse: 0.514 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5169 Still best_val_rmse: 0.514 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.519 Still best_val_rmse: 0.514 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5171 Still best_val_rmse: 0.514 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5185 Still best_val_rmse: 0.514 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5144 Still best_val_rmse: 0.514 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 08:02:51,158]\u001b[0m Trial 3 finished with value: 0.5140185952186584 and parameters: {'base_lr': 1.8880685655133146e-05, 'last_lr': 0.0020891479410450942}. Best is trial 3 with value: 0.5140185952186584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d70098b8614b12bd2cb608f58a05fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8701 New best_val_rmse: 0.8701\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.819 New best_val_rmse: 0.819\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6294 New best_val_rmse: 0.6294\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6973 Still best_val_rmse: 0.6294 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6736 Still best_val_rmse: 0.6294 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.7084 Still best_val_rmse: 0.6294 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6055 New best_val_rmse: 0.6055\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6454 Still best_val_rmse: 0.6055 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5708 New best_val_rmse: 0.5708\n",
      "\n",
      "16 steps took 11.1 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.6986 Still best_val_rmse: 0.5708 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5916 Still best_val_rmse: 0.5708 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5761 Still best_val_rmse: 0.5708 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5529 New best_val_rmse: 0.5529\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5565 Still best_val_rmse: 0.5529 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5471 New best_val_rmse: 0.5471\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5241 New best_val_rmse: 0.5241\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5254 Still best_val_rmse: 0.5241 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.516 New best_val_rmse: 0.516\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5158 New best_val_rmse: 0.5158\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5268 Still best_val_rmse: 0.5158 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5169 Still best_val_rmse: 0.5158 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5193 Still best_val_rmse: 0.5158 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5161 Still best_val_rmse: 0.5158 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5187 Still best_val_rmse: 0.5158 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5147 New best_val_rmse: 0.5147\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.515 Still best_val_rmse: 0.5147 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.514 New best_val_rmse: 0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 08:12:03,644]\u001b[0m Trial 4 finished with value: 0.5140345096588135 and parameters: {'base_lr': 2.1352773609473673e-05, 'last_lr': 0.00031687556091188556}. Best is trial 3 with value: 0.5140185952186584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dee8e5706142c98155dea237ca3867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8358 New best_val_rmse: 0.8358\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7688 New best_val_rmse: 0.7688\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.645 New best_val_rmse: 0.645\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6582 Still best_val_rmse: 0.645 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6069 New best_val_rmse: 0.6069\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.5992 New best_val_rmse: 0.5992\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.7211 Still best_val_rmse: 0.5992 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5867 New best_val_rmse: 0.5867\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5374 New best_val_rmse: 0.5374\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5724 Still best_val_rmse: 0.5374 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.606 Still best_val_rmse: 0.5374 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5511 Still best_val_rmse: 0.5374 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5601 Still best_val_rmse: 0.5374 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5571 Still best_val_rmse: 0.5374 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5379 Still best_val_rmse: 0.5374 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5188 New best_val_rmse: 0.5188\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5145 New best_val_rmse: 0.5145\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5269 Still best_val_rmse: 0.5145 (from epoch 1)\n",
      "\n",
      "16 steps took 10.8 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5099 New best_val_rmse: 0.5099\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5168 Still best_val_rmse: 0.5099 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5099 Still best_val_rmse: 0.5099 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5134 Still best_val_rmse: 0.5099 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5121 Still best_val_rmse: 0.5099 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5134 Still best_val_rmse: 0.5099 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5133 Still best_val_rmse: 0.5099 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.514 Still best_val_rmse: 0.5099 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5097 New best_val_rmse: 0.5097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 08:21:15,187]\u001b[0m Trial 5 finished with value: 0.5097138285636902 and parameters: {'base_lr': 1.7723999353969867e-05, 'last_lr': 0.002421906900470131}. Best is trial 5 with value: 0.5097138285636902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e566838491f4df787f6420c382bf5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8128 New best_val_rmse: 0.8128\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.9141 Still best_val_rmse: 0.8128 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6866 New best_val_rmse: 0.6866\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6802 New best_val_rmse: 0.6802\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.8949 Still best_val_rmse: 0.6802 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.8077 Still best_val_rmse: 0.6802 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.7839 Still best_val_rmse: 0.6802 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6558 New best_val_rmse: 0.6558\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5799 New best_val_rmse: 0.5799\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.6037 Still best_val_rmse: 0.5799 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5938 Still best_val_rmse: 0.5799 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5441 New best_val_rmse: 0.5441\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5446 Still best_val_rmse: 0.5441 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5749 Still best_val_rmse: 0.5441 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5723 Still best_val_rmse: 0.5441 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5276 New best_val_rmse: 0.5276\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.515 New best_val_rmse: 0.515\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5053 New best_val_rmse: 0.5053\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5232 Still best_val_rmse: 0.5053 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5165 Still best_val_rmse: 0.5053 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4989 New best_val_rmse: 0.4989\n",
      "\n",
      "8 steps took 5.26 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.499 Still best_val_rmse: 0.4989 (from epoch 2)\n",
      "\n",
      "8 steps took 5.26 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.511 Still best_val_rmse: 0.4989 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4991 Still best_val_rmse: 0.4989 (from epoch 2)\n",
      "\n",
      "8 steps took 5.27 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.5077 Still best_val_rmse: 0.4989 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4987 New best_val_rmse: 0.4987\n",
      "\n",
      "8 steps took 5.23 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4976 New best_val_rmse: 0.4976\n",
      "\n",
      "8 steps took 5.27 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.5001 Still best_val_rmse: 0.4976 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.5013 Still best_val_rmse: 0.4976 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4999 Still best_val_rmse: 0.4976 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 08:30:55,644]\u001b[0m Trial 6 finished with value: 0.49761196970939636 and parameters: {'base_lr': 3.14178260845283e-05, 'last_lr': 0.0007832616260786154}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651284dd55684c5db6dd528377d28ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.287 New best_val_rmse: 1.287\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.091 New best_val_rmse: 1.091\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.059 New best_val_rmse: 1.059\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.049 New best_val_rmse: 1.049\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.036 New best_val_rmse: 1.036\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.033 New best_val_rmse: 1.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 08:33:11,986]\u001b[0m Trial 7 finished with value: 1.033320426940918 and parameters: {'base_lr': 9.442975925912978e-05, 'last_lr': 0.0012419256165480655}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2383aa284642cc96103aa7b50ae461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.862 New best_val_rmse: 0.862\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7646 New best_val_rmse: 0.7646\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6184 New best_val_rmse: 0.6184\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7037 Still best_val_rmse: 0.6184 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6187 Still best_val_rmse: 0.6184 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6593 Still best_val_rmse: 0.6184 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.7592 Still best_val_rmse: 0.6184 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5852 New best_val_rmse: 0.5852\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.548 New best_val_rmse: 0.548\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.6192 Still best_val_rmse: 0.548 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.6528 Still best_val_rmse: 0.548 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5552 Still best_val_rmse: 0.548 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5767 Still best_val_rmse: 0.548 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5851 Still best_val_rmse: 0.548 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5519 Still best_val_rmse: 0.548 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5259 New best_val_rmse: 0.5259\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5161 New best_val_rmse: 0.5161\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5391 Still best_val_rmse: 0.5161 (from epoch 1)\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5094 New best_val_rmse: 0.5094\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5222 Still best_val_rmse: 0.5094 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5117 Still best_val_rmse: 0.5094 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5151 Still best_val_rmse: 0.5094 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5137 Still best_val_rmse: 0.5094 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5135 Still best_val_rmse: 0.5094 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5114 Still best_val_rmse: 0.5094 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5116 Still best_val_rmse: 0.5094 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.509 New best_val_rmse: 0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 08:42:24,075]\u001b[0m Trial 8 finished with value: 0.5089513659477234 and parameters: {'base_lr': 1.7981249357315323e-05, 'last_lr': 0.003458101308133521}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdf0beac562417fa4cb55269747b038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.074 New best_val_rmse: 1.074\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7322 New best_val_rmse: 0.7322\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6402 New best_val_rmse: 0.6402\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6994 Still best_val_rmse: 0.6402 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.5984 New best_val_rmse: 0.5984\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6883 Still best_val_rmse: 0.5984 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.0 Still best_val_rmse: 0.5984 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6441 Still best_val_rmse: 0.5984 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.7295 Still best_val_rmse: 0.5984 (from epoch 0)\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5712 New best_val_rmse: 0.5712\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.6241 Still best_val_rmse: 0.5712 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5654 New best_val_rmse: 0.5654\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5563 New best_val_rmse: 0.5563\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5485 New best_val_rmse: 0.5485\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.542 New best_val_rmse: 0.542\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5567 Still best_val_rmse: 0.542 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5273 New best_val_rmse: 0.5273\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5169 New best_val_rmse: 0.5169\n",
      "\n",
      "16 steps took 11.1 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5414 Still best_val_rmse: 0.5169 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5066 New best_val_rmse: 0.5066\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5109 Still best_val_rmse: 0.5066 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5131 Still best_val_rmse: 0.5066 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5132 Still best_val_rmse: 0.5066 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5226 Still best_val_rmse: 0.5066 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5035 New best_val_rmse: 0.5035\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5039 Still best_val_rmse: 0.5035 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5034 New best_val_rmse: 0.5034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 08:51:37,909]\u001b[0m Trial 9 finished with value: 0.5033865571022034 and parameters: {'base_lr': 1.303402432061673e-05, 'last_lr': 0.0003378238446981118}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834d3572a4914255a52fd4e97788597a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9199 New best_val_rmse: 0.9199\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7083 New best_val_rmse: 0.7083\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7208 Still best_val_rmse: 0.7083 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.779 Still best_val_rmse: 0.7083 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6448 New best_val_rmse: 0.6448\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6162 New best_val_rmse: 0.6162\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6549 Still best_val_rmse: 0.6162 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6832 Still best_val_rmse: 0.6162 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5771 New best_val_rmse: 0.5771\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.6068 Still best_val_rmse: 0.5771 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5905 Still best_val_rmse: 0.5771 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5634 New best_val_rmse: 0.5634\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5672 Still best_val_rmse: 0.5634 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.6883 Still best_val_rmse: 0.5634 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.6025 Still best_val_rmse: 0.5634 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5791 Still best_val_rmse: 0.5634 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5421 New best_val_rmse: 0.5421\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5357 New best_val_rmse: 0.5357\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5809 Still best_val_rmse: 0.5357 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5248 New best_val_rmse: 0.5248\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5321 Still best_val_rmse: 0.5248 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5365 Still best_val_rmse: 0.5248 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5335 Still best_val_rmse: 0.5248 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.537 Still best_val_rmse: 0.5248 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5207 New best_val_rmse: 0.5207\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5206 New best_val_rmse: 0.5206\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5203 New best_val_rmse: 0.5203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 09:00:47,636]\u001b[0m Trial 10 finished with value: 0.5203080773353577 and parameters: {'base_lr': 9.389334401214135e-06, 'last_lr': 0.000865555975422473}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853bf540419e4373aa71b9f4feed99f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.119 New best_val_rmse: 1.119\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7749 New best_val_rmse: 0.7749\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6635 New best_val_rmse: 0.6635\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6594 New best_val_rmse: 0.6594\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.871 Still best_val_rmse: 0.6594 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.162 Still best_val_rmse: 0.6594 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6885 Still best_val_rmse: 0.6594 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.633 New best_val_rmse: 0.633\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5967 New best_val_rmse: 0.5967\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 1.122 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 1.061 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 1.051 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 1.019 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.9443 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.662 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.6539 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.6685 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.6313 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.6788 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.6275 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.6379 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.6004 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5962 New best_val_rmse: 0.5962\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5995 Still best_val_rmse: 0.5962 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5957 New best_val_rmse: 0.5957\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5954 New best_val_rmse: 0.5954\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5956 Still best_val_rmse: 0.5954 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 09:09:59,748]\u001b[0m Trial 11 finished with value: 0.5953845381736755 and parameters: {'base_lr': 8.36843448655206e-06, 'last_lr': 0.00011642797279204702}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d9e5f9f4664bf2a37f4f76ca49da8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.831 New best_val_rmse: 0.831\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.6968 New best_val_rmse: 0.6968\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7376 Still best_val_rmse: 0.6968 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6137 New best_val_rmse: 0.6137\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.5816 New best_val_rmse: 0.5816\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.8657 Still best_val_rmse: 0.5816 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.5834 Still best_val_rmse: 0.5816 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6438 Still best_val_rmse: 0.5816 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5594 New best_val_rmse: 0.5594\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5649 Still best_val_rmse: 0.5594 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5599 Still best_val_rmse: 0.5594 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5596 Still best_val_rmse: 0.5594 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5549 New best_val_rmse: 0.5549\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.6647 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 1.023 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 1.04 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 1.058 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 1.046 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.8 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 1.067 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 1.028 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 1.044 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 1.029 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 1.026 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 1.027 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 1.026 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 1.026 Still best_val_rmse: 0.5549 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 1.026 Still best_val_rmse: 0.5549 (from epoch 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 09:19:08,257]\u001b[0m Trial 12 finished with value: 0.5548718571662903 and parameters: {'base_lr': 3.0693004516053946e-05, 'last_lr': 0.00014550179932825466}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b577b764da4c35806d4904cba78505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9102 New best_val_rmse: 0.9102\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8067 New best_val_rmse: 0.8067\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6235 New best_val_rmse: 0.6235\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6699 Still best_val_rmse: 0.6235 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.622 New best_val_rmse: 0.622\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6411 Still best_val_rmse: 0.622 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.5861 New best_val_rmse: 0.5861\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5763 New best_val_rmse: 0.5763\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5409 New best_val_rmse: 0.5409\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5388 New best_val_rmse: 0.5388\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.636 Still best_val_rmse: 0.5388 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.534 New best_val_rmse: 0.534\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5699 Still best_val_rmse: 0.534 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5535 Still best_val_rmse: 0.534 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5556 Still best_val_rmse: 0.534 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5204 New best_val_rmse: 0.5204\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5094 New best_val_rmse: 0.5094\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5164 Still best_val_rmse: 0.5094 (from epoch 1)\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5208 Still best_val_rmse: 0.5094 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5007 New best_val_rmse: 0.5007\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.507 Still best_val_rmse: 0.5007 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5076 Still best_val_rmse: 0.5007 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5058 Still best_val_rmse: 0.5007 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5126 Still best_val_rmse: 0.5007 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5057 Still best_val_rmse: 0.5007 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5095 Still best_val_rmse: 0.5007 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5054 Still best_val_rmse: 0.5007 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 09:28:21,329]\u001b[0m Trial 13 finished with value: 0.5007190704345703 and parameters: {'base_lr': 1.2188413471472434e-05, 'last_lr': 0.0011921413039216065}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8bea61ddc0441f8f12119d340aa189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9304 New best_val_rmse: 0.9304\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.9671 Still best_val_rmse: 0.9304 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7848 New best_val_rmse: 0.7848\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7215 New best_val_rmse: 0.7215\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.7249 Still best_val_rmse: 0.7215 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6333 New best_val_rmse: 0.6333\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.8009 Still best_val_rmse: 0.6333 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.7343 Still best_val_rmse: 0.6333 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5408 New best_val_rmse: 0.5408\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5428 Still best_val_rmse: 0.5408 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.6118 Still best_val_rmse: 0.5408 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5516 Still best_val_rmse: 0.5408 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5707 Still best_val_rmse: 0.5408 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.602 Still best_val_rmse: 0.5408 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5646 Still best_val_rmse: 0.5408 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5322 New best_val_rmse: 0.5322\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5194 New best_val_rmse: 0.5194\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5443 Still best_val_rmse: 0.5194 (from epoch 1)\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5192 New best_val_rmse: 0.5192\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5253 Still best_val_rmse: 0.5192 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5142 New best_val_rmse: 0.5142\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5151 Still best_val_rmse: 0.5142 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5161 Still best_val_rmse: 0.5142 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5178 Still best_val_rmse: 0.5142 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5185 Still best_val_rmse: 0.5142 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5201 Still best_val_rmse: 0.5142 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5164 Still best_val_rmse: 0.5142 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 09:37:34,160]\u001b[0m Trial 14 finished with value: 0.5142280459403992 and parameters: {'base_lr': 3.239859397988443e-05, 'last_lr': 0.0013337413980479497}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f34903ab374b5fa11ca442458deb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8561 New best_val_rmse: 0.8561\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7683 New best_val_rmse: 0.7683\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6407 New best_val_rmse: 0.6407\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6514 Still best_val_rmse: 0.6407 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6966 Still best_val_rmse: 0.6407 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.667 Still best_val_rmse: 0.6407 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.084 Still best_val_rmse: 0.6407 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.8893 Still best_val_rmse: 0.6407 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.609 New best_val_rmse: 0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 09:40:50,150]\u001b[0m Trial 15 finished with value: 0.6090430021286011 and parameters: {'base_lr': 1.1729068389456557e-05, 'last_lr': 0.004590643888825568}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d000cc4b32543eca75f14922d52f546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8373 New best_val_rmse: 0.8373\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7753 New best_val_rmse: 0.7753\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7015 New best_val_rmse: 0.7015\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7865 Still best_val_rmse: 0.7015 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.5954 New best_val_rmse: 0.5954\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.8438 Still best_val_rmse: 0.5954 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6586 Still best_val_rmse: 0.5954 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6529 Still best_val_rmse: 0.5954 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.539 New best_val_rmse: 0.539\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5728 Still best_val_rmse: 0.539 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5742 Still best_val_rmse: 0.539 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5478 Still best_val_rmse: 0.539 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5514 Still best_val_rmse: 0.539 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5437 Still best_val_rmse: 0.539 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5454 Still best_val_rmse: 0.539 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5123 New best_val_rmse: 0.5123\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.514 Still best_val_rmse: 0.5123 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5204 Still best_val_rmse: 0.5123 (from epoch 1)\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5044 New best_val_rmse: 0.5044\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5089 Still best_val_rmse: 0.5044 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5088 Still best_val_rmse: 0.5044 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5134 Still best_val_rmse: 0.5044 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5083 Still best_val_rmse: 0.5044 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5093 Still best_val_rmse: 0.5044 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5081 Still best_val_rmse: 0.5044 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5112 Still best_val_rmse: 0.5044 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.507 Still best_val_rmse: 0.5044 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 09:50:01,190]\u001b[0m Trial 16 finished with value: 0.5043809413909912 and parameters: {'base_lr': 2.6079435553047675e-05, 'last_lr': 0.000870282691669244}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475bd303acd44f369e1c457887b87d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.787 New best_val_rmse: 0.787\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7226 New best_val_rmse: 0.7226\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6539 New best_val_rmse: 0.6539\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6722 Still best_val_rmse: 0.6539 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6055 New best_val_rmse: 0.6055\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.8401 Still best_val_rmse: 0.6055 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.989 Still best_val_rmse: 0.6055 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5762 New best_val_rmse: 0.5762\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5553 New best_val_rmse: 0.5553\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.6059 Still best_val_rmse: 0.5553 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.6414 Still best_val_rmse: 0.5553 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5735 Still best_val_rmse: 0.5553 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5505 New best_val_rmse: 0.5505\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5993 Still best_val_rmse: 0.5505 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5498 New best_val_rmse: 0.5498\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5248 New best_val_rmse: 0.5248\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.52 New best_val_rmse: 0.52\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.526 Still best_val_rmse: 0.52 (from epoch 1)\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5328 Still best_val_rmse: 0.52 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5085 New best_val_rmse: 0.5085\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5078 New best_val_rmse: 0.5078\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5122 Still best_val_rmse: 0.5078 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5088 Still best_val_rmse: 0.5078 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5111 Still best_val_rmse: 0.5078 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5094 Still best_val_rmse: 0.5078 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5108 Still best_val_rmse: 0.5078 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5076 New best_val_rmse: 0.5076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 09:59:12,274]\u001b[0m Trial 17 finished with value: 0.5076243281364441 and parameters: {'base_lr': 3.844055074213067e-05, 'last_lr': 0.0017940094678735592}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce9c131badf404ab05d764042e68df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.137 New best_val_rmse: 1.137\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.9125 New best_val_rmse: 0.9125\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7272 New best_val_rmse: 0.7272\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.868 Still best_val_rmse: 0.7272 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.066 Still best_val_rmse: 0.7272 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.069 Still best_val_rmse: 0.7272 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.066 Still best_val_rmse: 0.7272 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.06 Still best_val_rmse: 0.7272 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.062 Still best_val_rmse: 0.7272 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 10:02:27,980]\u001b[0m Trial 18 finished with value: 0.727199912071228 and parameters: {'base_lr': 6.812197197995203e-05, 'last_lr': 0.0006177222127847207}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ad5cdcad7f442f929cf585bfd76851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9003 New best_val_rmse: 0.9003\n",
      "\n",
      "16 steps took 9.76 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.9036 Still best_val_rmse: 0.9003 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6222 New best_val_rmse: 0.6222\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6597 Still best_val_rmse: 0.6222 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.7237 Still best_val_rmse: 0.6222 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6081 New best_val_rmse: 0.6081\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.7425 Still best_val_rmse: 0.6081 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6245 Still best_val_rmse: 0.6081 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5391 New best_val_rmse: 0.5391\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5571 Still best_val_rmse: 0.5391 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.6501 Still best_val_rmse: 0.5391 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5464 Still best_val_rmse: 0.5391 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5601 Still best_val_rmse: 0.5391 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.6058 Still best_val_rmse: 0.5391 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5963 Still best_val_rmse: 0.5391 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5413 Still best_val_rmse: 0.5391 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5338 New best_val_rmse: 0.5338\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5524 Still best_val_rmse: 0.5338 (from epoch 1)\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5265 New best_val_rmse: 0.5265\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.534 Still best_val_rmse: 0.5265 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5181 New best_val_rmse: 0.5181\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5334 Still best_val_rmse: 0.5181 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5271 Still best_val_rmse: 0.5181 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5292 Still best_val_rmse: 0.5181 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.519 Still best_val_rmse: 0.5181 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5212 Still best_val_rmse: 0.5181 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5192 Still best_val_rmse: 0.5181 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 10:11:37,352]\u001b[0m Trial 19 finished with value: 0.5181156396865845 and parameters: {'base_lr': 1.2917184125791566e-05, 'last_lr': 0.0010513992235207943}. Best is trial 6 with value: 0.49761196970939636.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 10:11:37,354]\u001b[0m A new study created in memory with name: no-name-9be0c3a9-5864-465d-b78c-f885c586853f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best value:  0.49761196970939636\n",
      " Best params: \n",
      "    base_lr: 3.14178260845283e-05\n",
      "    last_lr: 0.0007832616260786154\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63866dd0389047838f2b3f361adf8dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8603 New best_val_rmse: 0.8603\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8342 New best_val_rmse: 0.8342\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6234 New best_val_rmse: 0.6234\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.8374 Still best_val_rmse: 0.6234 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.5715 New best_val_rmse: 0.5715\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6035 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.8751 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.041 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.025 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 1.021 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 1.023 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 1.021 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 1.045 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 1.05 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 1.007 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 1.01 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 1.002 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 1.024 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.7 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 1.02 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 1.002 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 1.003 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 1.004 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 1.01 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 1.004 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 1.003 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 1.003 Still best_val_rmse: 0.5715 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 1.003 Still best_val_rmse: 0.5715 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 10:20:42,835]\u001b[0m Trial 0 finished with value: 0.57145756483078 and parameters: {'base_lr': 3.669916349375891e-05, 'last_lr': 0.0006030550151361043}. Best is trial 0 with value: 0.57145756483078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd8d065c170412682bee396ae1a3b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8146 New best_val_rmse: 0.8146\n",
      "\n",
      "16 steps took 10.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8639 Still best_val_rmse: 0.8146 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6156 New best_val_rmse: 0.6156\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.5909 New best_val_rmse: 0.5909\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6082 Still best_val_rmse: 0.5909 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6018 Still best_val_rmse: 0.5909 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6039 Still best_val_rmse: 0.5909 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5506 New best_val_rmse: 0.5506\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5844 Still best_val_rmse: 0.5506 (from epoch 0)\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5876 Still best_val_rmse: 0.5506 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.584 Still best_val_rmse: 0.5506 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5152 New best_val_rmse: 0.5152\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.506 New best_val_rmse: 0.506\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5554 Still best_val_rmse: 0.506 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5497 Still best_val_rmse: 0.506 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.515 Still best_val_rmse: 0.506 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5365 Still best_val_rmse: 0.506 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.4871 New best_val_rmse: 0.4871\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 1 batch_num: 144 val_rmse: 0.4947 Still best_val_rmse: 0.4871 (from epoch 1)\n",
      "\n",
      "8 steps took 5.74 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.5172 Still best_val_rmse: 0.4871 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.4812 New best_val_rmse: 0.4812\n",
      "\n",
      "4 steps took 2.6 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4893 Still best_val_rmse: 0.4812 (from epoch 2)\n",
      "\n",
      "4 steps took 2.56 seconds\n",
      "Epoch: 2 batch_num: 28 val_rmse: 0.4835 Still best_val_rmse: 0.4812 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.4841 Still best_val_rmse: 0.4812 (from epoch 2)\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.478 New best_val_rmse: 0.478\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 38 val_rmse: 0.4812 Still best_val_rmse: 0.478 (from epoch 2)\n",
      "\n",
      "4 steps took 2.6 seconds\n",
      "Epoch: 2 batch_num: 42 val_rmse: 0.4786 Still best_val_rmse: 0.478 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.477 New best_val_rmse: 0.477\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 46 val_rmse: 0.4774 Still best_val_rmse: 0.477 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4772 Still best_val_rmse: 0.477 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 50 val_rmse: 0.476 New best_val_rmse: 0.476\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4804 Still best_val_rmse: 0.476 (from epoch 2)\n",
      "\n",
      "4 steps took 2.6 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4805 Still best_val_rmse: 0.476 (from epoch 2)\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4764 Still best_val_rmse: 0.476 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 62 val_rmse: 0.4746 New best_val_rmse: 0.4746\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4742 New best_val_rmse: 0.4742\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 66 val_rmse: 0.4746 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4748 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 70 val_rmse: 0.4761 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4781 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 74 val_rmse: 0.4793 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4787 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 78 val_rmse: 0.4789 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.4773 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 82 val_rmse: 0.4761 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4749 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 86 val_rmse: 0.4744 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4742 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 90 val_rmse: 0.4747 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4744 Still best_val_rmse: 0.4742 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 94 val_rmse: 0.474 New best_val_rmse: 0.474\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4743 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 98 val_rmse: 0.4763 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4798 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 102 val_rmse: 0.4827 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "4 steps took 2.6 seconds\n",
      "Epoch: 2 batch_num: 106 val_rmse: 0.4855 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 2 batch_num: 110 val_rmse: 0.4822 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "4 steps took 2.63 seconds\n",
      "Epoch: 2 batch_num: 114 val_rmse: 0.4769 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4757 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 118 val_rmse: 0.4748 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4746 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 122 val_rmse: 0.4744 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4745 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 126 val_rmse: 0.4745 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4745 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 130 val_rmse: 0.4744 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4743 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 134 val_rmse: 0.4743 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4742 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 138 val_rmse: 0.4742 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4742 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 142 val_rmse: 0.4742 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4742 Still best_val_rmse: 0.474 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 146 val_rmse: 0.4742 Still best_val_rmse: 0.474 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 10:36:45,889]\u001b[0m Trial 1 finished with value: 0.47404229640960693 and parameters: {'base_lr': 3.121463088049813e-05, 'last_lr': 9.63463401238908e-05}. Best is trial 1 with value: 0.47404229640960693.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe8793975ba4fee849f330d4145b629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.7573 New best_val_rmse: 0.7573\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.8117 Still best_val_rmse: 0.7573 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.043 Still best_val_rmse: 0.7573 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.037 Still best_val_rmse: 0.7573 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.017 Still best_val_rmse: 0.7573 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.036 Still best_val_rmse: 0.7573 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.015 Still best_val_rmse: 0.7573 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.01 Still best_val_rmse: 0.7573 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.022 Still best_val_rmse: 0.7573 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 10:40:01,164]\u001b[0m Trial 2 finished with value: 0.7573437690734863 and parameters: {'base_lr': 7.449196393480658e-05, 'last_lr': 0.00018757085763230336}. Best is trial 1 with value: 0.47404229640960693.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339494781cfb42be80fdd948868f2deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.5 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8413 New best_val_rmse: 0.8413\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.5996 New best_val_rmse: 0.5996\n",
      "\n",
      "16 steps took 9.43 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.84 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.8863 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.201 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.105 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.024 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.099 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.051 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 1.024 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 1.021 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 1.014 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 1.078 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 1.047 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 1.064 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 1.021 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 1.017 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 1.026 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 1.013 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 1.007 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 1.008 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 1.006 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 1.008 Still best_val_rmse: 0.5996 (from epoch 0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 10:47:40,713]\u001b[0m Trial 3 finished with value: 0.599632203578949 and parameters: {'base_lr': 5.9560427890818324e-05, 'last_lr': 0.0035666771047120948}. Best is trial 1 with value: 0.47404229640960693.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24b2714dc0b4261a5f16cd18a1d87ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.7655 New best_val_rmse: 0.7655\n",
      "\n",
      "16 steps took 10.0 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.9049 Still best_val_rmse: 0.7655 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.5857 New best_val_rmse: 0.5857\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.736 Still best_val_rmse: 0.5857 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6212 Still best_val_rmse: 0.5857 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6142 Still best_val_rmse: 0.5857 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.7392 Still best_val_rmse: 0.5857 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6352 Still best_val_rmse: 0.5857 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5815 New best_val_rmse: 0.5815\n",
      "\n",
      "16 steps took 11.1 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5927 Still best_val_rmse: 0.5815 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.6476 Still best_val_rmse: 0.5815 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5801 New best_val_rmse: 0.5801\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5899 Still best_val_rmse: 0.5801 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5319 New best_val_rmse: 0.5319\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.499 New best_val_rmse: 0.499\n",
      "\n",
      "8 steps took 5.22 seconds\n",
      "Epoch: 1 batch_num: 100 val_rmse: 0.5041 Still best_val_rmse: 0.499 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 116 val_rmse: 0.5066 Still best_val_rmse: 0.499 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 132 val_rmse: 0.5196 Still best_val_rmse: 0.499 (from epoch 1)\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 2 batch_num: 0 val_rmse: 0.4751 New best_val_rmse: 0.4751\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 2 val_rmse: 0.4892 Still best_val_rmse: 0.4751 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 6 val_rmse: 0.4712 New best_val_rmse: 0.4712\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.4792 Still best_val_rmse: 0.4712 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 10 val_rmse: 0.4788 Still best_val_rmse: 0.4712 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 12 val_rmse: 0.4814 Still best_val_rmse: 0.4712 (from epoch 2)\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 16 val_rmse: 0.4984 Still best_val_rmse: 0.4712 (from epoch 2)\n",
      "\n",
      "8 steps took 5.14 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4724 Still best_val_rmse: 0.4712 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 26 val_rmse: 0.4862 Still best_val_rmse: 0.4712 (from epoch 2)\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 30 val_rmse: 0.4892 Still best_val_rmse: 0.4712 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 34 val_rmse: 0.4671 New best_val_rmse: 0.4671\n",
      "\n",
      "1 steps took 0.634 seconds\n",
      "Epoch: 2 batch_num: 35 val_rmse: 0.4696 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "1 steps took 0.639 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.4718 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 38 val_rmse: 0.4706 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4719 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 42 val_rmse: 0.4778 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4705 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 46 val_rmse: 0.4693 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 47 val_rmse: 0.4755 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 49 val_rmse: 0.4785 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 51 val_rmse: 0.4691 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "1 steps took 0.634 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4672 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "1 steps took 0.651 seconds\n",
      "Epoch: 2 batch_num: 53 val_rmse: 0.4698 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 54 val_rmse: 0.475 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4821 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "4 steps took 2.59 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4754 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 62 val_rmse: 0.4683 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "1 steps took 0.642 seconds\n",
      "Epoch: 2 batch_num: 63 val_rmse: 0.4664 New best_val_rmse: 0.4664\n",
      "\n",
      "1 steps took 0.621 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4655 New best_val_rmse: 0.4655\n",
      "\n",
      "1 steps took 0.652 seconds\n",
      "Epoch: 2 batch_num: 65 val_rmse: 0.4654 New best_val_rmse: 0.4654\n",
      "\n",
      "1 steps took 0.644 seconds\n",
      "Epoch: 2 batch_num: 66 val_rmse: 0.4654 New best_val_rmse: 0.4654\n",
      "\n",
      "1 steps took 0.641 seconds\n",
      "Epoch: 2 batch_num: 67 val_rmse: 0.4647 New best_val_rmse: 0.4647\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4644 New best_val_rmse: 0.4644\n",
      "\n",
      "1 steps took 0.629 seconds\n",
      "Epoch: 2 batch_num: 69 val_rmse: 0.4645 Still best_val_rmse: 0.4644 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 70 val_rmse: 0.4648 Still best_val_rmse: 0.4644 (from epoch 2)\n",
      "\n",
      "1 steps took 0.63 seconds\n",
      "Epoch: 2 batch_num: 71 val_rmse: 0.4651 Still best_val_rmse: 0.4644 (from epoch 2)\n",
      "\n",
      "1 steps took 0.626 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4653 Still best_val_rmse: 0.4644 (from epoch 2)\n",
      "\n",
      "1 steps took 0.643 seconds\n",
      "Epoch: 2 batch_num: 73 val_rmse: 0.4651 Still best_val_rmse: 0.4644 (from epoch 2)\n",
      "\n",
      "1 steps took 0.633 seconds\n",
      "Epoch: 2 batch_num: 74 val_rmse: 0.4647 Still best_val_rmse: 0.4644 (from epoch 2)\n",
      "\n",
      "1 steps took 0.645 seconds\n",
      "Epoch: 2 batch_num: 75 val_rmse: 0.4641 New best_val_rmse: 0.4641\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4634 New best_val_rmse: 0.4634\n",
      "\n",
      "1 steps took 0.655 seconds\n",
      "Epoch: 2 batch_num: 77 val_rmse: 0.4634 New best_val_rmse: 0.4634\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 78 val_rmse: 0.4631 New best_val_rmse: 0.4631\n",
      "\n",
      "1 steps took 0.627 seconds\n",
      "Epoch: 2 batch_num: 79 val_rmse: 0.4627 New best_val_rmse: 0.4627\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.4624 New best_val_rmse: 0.4624\n",
      "\n",
      "1 steps took 0.641 seconds\n",
      "Epoch: 2 batch_num: 81 val_rmse: 0.4621 New best_val_rmse: 0.4621\n",
      "\n",
      "1 steps took 0.641 seconds\n",
      "Epoch: 2 batch_num: 82 val_rmse: 0.462 New best_val_rmse: 0.462\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 83 val_rmse: 0.4622 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.635 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4627 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.628 seconds\n",
      "Epoch: 2 batch_num: 85 val_rmse: 0.463 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.642 seconds\n",
      "Epoch: 2 batch_num: 86 val_rmse: 0.4632 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 87 val_rmse: 0.4637 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.627 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.464 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.627 seconds\n",
      "Epoch: 2 batch_num: 89 val_rmse: 0.4643 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.633 seconds\n",
      "Epoch: 2 batch_num: 90 val_rmse: 0.4645 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.634 seconds\n",
      "Epoch: 2 batch_num: 91 val_rmse: 0.4647 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.648 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4646 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.623 seconds\n",
      "Epoch: 2 batch_num: 93 val_rmse: 0.4646 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 94 val_rmse: 0.4649 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 95 val_rmse: 0.465 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.633 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4649 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.641 seconds\n",
      "Epoch: 2 batch_num: 97 val_rmse: 0.4649 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 98 val_rmse: 0.4653 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 99 val_rmse: 0.4659 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.633 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4668 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 101 val_rmse: 0.4674 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.645 seconds\n",
      "Epoch: 2 batch_num: 102 val_rmse: 0.4678 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 103 val_rmse: 0.4679 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.624 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4677 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.626 seconds\n",
      "Epoch: 2 batch_num: 105 val_rmse: 0.4682 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 106 val_rmse: 0.469 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 107 val_rmse: 0.4692 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.631 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4691 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.642 seconds\n",
      "Epoch: 2 batch_num: 109 val_rmse: 0.469 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.642 seconds\n",
      "Epoch: 2 batch_num: 110 val_rmse: 0.469 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 111 val_rmse: 0.4688 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.643 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4684 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.635 seconds\n",
      "Epoch: 2 batch_num: 113 val_rmse: 0.468 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.641 seconds\n",
      "Epoch: 2 batch_num: 114 val_rmse: 0.4677 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 115 val_rmse: 0.4672 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.649 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4666 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.655 seconds\n",
      "Epoch: 2 batch_num: 117 val_rmse: 0.4661 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 118 val_rmse: 0.4657 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 119 val_rmse: 0.4654 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4651 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.64 seconds\n",
      "Epoch: 2 batch_num: 121 val_rmse: 0.4648 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.634 seconds\n",
      "Epoch: 2 batch_num: 122 val_rmse: 0.4645 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.635 seconds\n",
      "Epoch: 2 batch_num: 123 val_rmse: 0.4643 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.628 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4641 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 125 val_rmse: 0.464 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.627 seconds\n",
      "Epoch: 2 batch_num: 126 val_rmse: 0.4638 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.642 seconds\n",
      "Epoch: 2 batch_num: 127 val_rmse: 0.4638 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.643 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4637 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.634 seconds\n",
      "Epoch: 2 batch_num: 129 val_rmse: 0.4637 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.627 seconds\n",
      "Epoch: 2 batch_num: 130 val_rmse: 0.4637 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.64 seconds\n",
      "Epoch: 2 batch_num: 131 val_rmse: 0.4636 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.629 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4636 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.642 seconds\n",
      "Epoch: 2 batch_num: 133 val_rmse: 0.4636 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.629 seconds\n",
      "Epoch: 2 batch_num: 134 val_rmse: 0.4636 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.634 seconds\n",
      "Epoch: 2 batch_num: 135 val_rmse: 0.4635 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.648 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4635 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.633 seconds\n",
      "Epoch: 2 batch_num: 137 val_rmse: 0.4635 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.627 seconds\n",
      "Epoch: 2 batch_num: 138 val_rmse: 0.4635 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 139 val_rmse: 0.4635 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.623 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4635 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.625 seconds\n",
      "Epoch: 2 batch_num: 141 val_rmse: 0.4635 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.631 seconds\n",
      "Epoch: 2 batch_num: 142 val_rmse: 0.4635 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 143 val_rmse: 0.4635 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.649 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4635 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.643 seconds\n",
      "Epoch: 2 batch_num: 145 val_rmse: 0.4634 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 146 val_rmse: 0.4635 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "1 steps took 0.434 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 11:12:03,777]\u001b[0m Trial 4 finished with value: 0.4619826078414917 and parameters: {'base_lr': 4.632686837727199e-05, 'last_lr': 0.00026414650413977917}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 batch_num: 147 val_rmse: 0.4634 Still best_val_rmse: 0.462 (from epoch 2)\n",
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700d0f9f4a2849448e5abb6ccf99c233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9175 New best_val_rmse: 0.9175\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7837 New best_val_rmse: 0.7837\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7934 Still best_val_rmse: 0.7837 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6485 New best_val_rmse: 0.6485\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6296 New best_val_rmse: 0.6296\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6076 New best_val_rmse: 0.6076\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.8313 Still best_val_rmse: 0.6076 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6482 Still best_val_rmse: 0.6076 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5475 New best_val_rmse: 0.5475\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5339 New best_val_rmse: 0.5339\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.7845 Still best_val_rmse: 0.5339 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5142 New best_val_rmse: 0.5142\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5132 New best_val_rmse: 0.5132\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5064 New best_val_rmse: 0.5064\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5919 Still best_val_rmse: 0.5064 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5075 Still best_val_rmse: 0.5064 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5179 Still best_val_rmse: 0.5064 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.493 New best_val_rmse: 0.493\n",
      "\n",
      "8 steps took 5.67 seconds\n",
      "Epoch: 2 batch_num: 0 val_rmse: 0.4934 Still best_val_rmse: 0.493 (from epoch 1)\n",
      "\n",
      "8 steps took 5.22 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.4912 New best_val_rmse: 0.4912\n",
      "\n",
      "8 steps took 5.21 seconds\n",
      "Epoch: 2 batch_num: 16 val_rmse: 0.5104 Still best_val_rmse: 0.4912 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.4879 New best_val_rmse: 0.4879\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.4893 Still best_val_rmse: 0.4879 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4885 Still best_val_rmse: 0.4879 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4858 New best_val_rmse: 0.4858\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4896 Still best_val_rmse: 0.4858 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4928 Still best_val_rmse: 0.4858 (from epoch 2)\n",
      "\n",
      "8 steps took 5.16 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4915 Still best_val_rmse: 0.4858 (from epoch 2)\n",
      "\n",
      "8 steps took 5.23 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4882 Still best_val_rmse: 0.4858 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.491 Still best_val_rmse: 0.4858 (from epoch 2)\n",
      "\n",
      "8 steps took 5.29 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.485 New best_val_rmse: 0.485\n",
      "\n",
      "4 steps took 2.63 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4848 New best_val_rmse: 0.4848\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4849 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4849 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.59 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4852 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4869 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.487 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4887 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.63 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4896 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4885 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4878 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4867 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.63 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4857 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.485 Still best_val_rmse: 0.4848 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4845 New best_val_rmse: 0.4845\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4843 New best_val_rmse: 0.4843\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4843 New best_val_rmse: 0.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 11:24:12,130]\u001b[0m Trial 5 finished with value: 0.4842711091041565 and parameters: {'base_lr': 2.686490045871402e-05, 'last_lr': 0.0004951352446690819}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b5b6970d9a4a1a8ee12d16b1e9b6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9468 New best_val_rmse: 0.9468\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.9365 New best_val_rmse: 0.9365\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.019 Still best_val_rmse: 0.9365 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.031 Still best_val_rmse: 0.9365 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.253 Still best_val_rmse: 0.9365 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.193 Still best_val_rmse: 0.9365 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 11:26:29,356]\u001b[0m Trial 6 finished with value: 0.9365071654319763 and parameters: {'base_lr': 9.431352355984944e-05, 'last_lr': 0.0016862858041826075}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c572023ef14c779c52468811a8a3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.04 New best_val_rmse: 1.04\n",
      "\n",
      "16 steps took 9.55 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.946 New best_val_rmse: 0.946\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6791 New best_val_rmse: 0.6791\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6131 New best_val_rmse: 0.6131\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6065 New best_val_rmse: 0.6065\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.5967 New best_val_rmse: 0.5967\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6117 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.8295 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.056 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.8 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 1.02 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 1.024 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 1.014 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 1.012 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 1.007 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 1.01 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 1.004 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 1.003 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 1.003 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.7 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 1.003 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 1.004 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 1.002 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 1.003 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 1.004 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 1.004 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 1.003 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 1.003 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 1.003 Still best_val_rmse: 0.5967 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 11:35:32,621]\u001b[0m Trial 7 finished with value: 0.5967450737953186 and parameters: {'base_lr': 2.0554063391850068e-05, 'last_lr': 0.00017935091090611288}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faf5be9b8a54b6bbcfa086690d168e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8065 New best_val_rmse: 0.8065\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7268 New best_val_rmse: 0.7268\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6921 New best_val_rmse: 0.6921\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7584 Still best_val_rmse: 0.6921 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.7444 Still best_val_rmse: 0.6921 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.73 Still best_val_rmse: 0.6921 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6074 New best_val_rmse: 0.6074\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5967 New best_val_rmse: 0.5967\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.8596 Still best_val_rmse: 0.5967 (from epoch 0)\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5879 New best_val_rmse: 0.5879\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.8619 Still best_val_rmse: 0.5879 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5769 New best_val_rmse: 0.5769\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5123 New best_val_rmse: 0.5123\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5222 Still best_val_rmse: 0.5123 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.6384 Still best_val_rmse: 0.5123 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5338 Still best_val_rmse: 0.5123 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.6574 Still best_val_rmse: 0.5123 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5413 Still best_val_rmse: 0.5123 (from epoch 1)\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5097 New best_val_rmse: 0.5097\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5032 New best_val_rmse: 0.5032\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5076 Still best_val_rmse: 0.5032 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5232 Still best_val_rmse: 0.5032 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5265 Still best_val_rmse: 0.5032 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5032 New best_val_rmse: 0.5032\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.5083 Still best_val_rmse: 0.5032 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.503 New best_val_rmse: 0.503\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5008 New best_val_rmse: 0.5008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 11:44:40,373]\u001b[0m Trial 8 finished with value: 0.5008251070976257 and parameters: {'base_lr': 4.894887513975813e-05, 'last_lr': 0.000893207915654168}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f37e40866747eab518b7a57d6889ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.206 New best_val_rmse: 1.206\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.865 New best_val_rmse: 0.865\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7079 New best_val_rmse: 0.7079\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.669 New best_val_rmse: 0.669\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6388 New best_val_rmse: 0.6388\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.7639 Still best_val_rmse: 0.6388 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.7945 Still best_val_rmse: 0.6388 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6925 Still best_val_rmse: 0.6388 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.8934 Still best_val_rmse: 0.6388 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 11:47:55,770]\u001b[0m Trial 9 finished with value: 0.638764500617981 and parameters: {'base_lr': 4.889122016942339e-05, 'last_lr': 0.0008434403469402835}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f308662f315c4222b9199f335ab73f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.6 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.044 New best_val_rmse: 1.044\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.771 New best_val_rmse: 0.771\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7348 New best_val_rmse: 0.7348\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6346 New best_val_rmse: 0.6346\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.5641 New best_val_rmse: 0.5641\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.5838 Still best_val_rmse: 0.5641 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.7381 Still best_val_rmse: 0.5641 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6073 Still best_val_rmse: 0.5641 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5459 New best_val_rmse: 0.5459\n",
      "\n",
      "16 steps took 11.1 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5498 Still best_val_rmse: 0.5459 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5579 Still best_val_rmse: 0.5459 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.521 New best_val_rmse: 0.521\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5627 Still best_val_rmse: 0.521 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5069 New best_val_rmse: 0.5069\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5195 Still best_val_rmse: 0.5069 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5029 New best_val_rmse: 0.5029\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5279 Still best_val_rmse: 0.5029 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.4892 New best_val_rmse: 0.4892\n",
      "\n",
      "4 steps took 2.64 seconds\n",
      "Epoch: 1 batch_num: 144 val_rmse: 0.486 New best_val_rmse: 0.486\n",
      "\n",
      "4 steps took 3.13 seconds\n",
      "Epoch: 2 batch_num: 0 val_rmse: 0.4855 New best_val_rmse: 0.4855\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.4938 Still best_val_rmse: 0.4855 (from epoch 2)\n",
      "\n",
      "8 steps took 5.16 seconds\n",
      "Epoch: 2 batch_num: 12 val_rmse: 0.4819 New best_val_rmse: 0.4819\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 16 val_rmse: 0.4853 Still best_val_rmse: 0.4819 (from epoch 2)\n",
      "\n",
      "4 steps took 2.63 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.4981 Still best_val_rmse: 0.4819 (from epoch 2)\n",
      "\n",
      "8 steps took 5.17 seconds\n",
      "Epoch: 2 batch_num: 28 val_rmse: 0.4923 Still best_val_rmse: 0.4819 (from epoch 2)\n",
      "\n",
      "8 steps took 5.27 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.4862 Still best_val_rmse: 0.4819 (from epoch 2)\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4834 Still best_val_rmse: 0.4819 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4816 New best_val_rmse: 0.4816\n",
      "\n",
      "4 steps took 2.59 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4814 New best_val_rmse: 0.4814\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4852 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4837 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4845 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4832 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4828 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.63 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4829 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4828 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.63 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.485 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4877 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4847 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4827 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4829 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4843 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4884 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4922 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "8 steps took 5.25 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4866 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.6 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4847 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4837 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4833 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.6 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4829 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4828 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.63 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4827 Still best_val_rmse: 0.4814 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4827 Still best_val_rmse: 0.4814 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 12:00:47,854]\u001b[0m Trial 10 finished with value: 0.48139688372612 and parameters: {'base_lr': 1.2930170413311317e-05, 'last_lr': 0.000263568725665429}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c5a890b817410ea0e301b378c43646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8363 New best_val_rmse: 0.8363\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.6378 New best_val_rmse: 0.6378\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6731 Still best_val_rmse: 0.6378 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.5879 New best_val_rmse: 0.5879\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.5599 New best_val_rmse: 0.5599\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.5512 New best_val_rmse: 0.5512\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.5267 New best_val_rmse: 0.5267\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5229 New best_val_rmse: 0.5229\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.6139 Still best_val_rmse: 0.5229 (from epoch 0)\n",
      "\n",
      "16 steps took 11.2 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5571 Still best_val_rmse: 0.5229 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.7249 Still best_val_rmse: 0.5229 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5186 New best_val_rmse: 0.5186\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.4915 New best_val_rmse: 0.4915\n",
      "\n",
      "8 steps took 5.3 seconds\n",
      "Epoch: 1 batch_num: 68 val_rmse: 0.5253 Still best_val_rmse: 0.4915 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 84 val_rmse: 0.5055 Still best_val_rmse: 0.4915 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 100 val_rmse: 0.4999 Still best_val_rmse: 0.4915 (from epoch 1)\n",
      "\n",
      "8 steps took 5.27 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.4885 New best_val_rmse: 0.4885\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 1 batch_num: 112 val_rmse: 0.495 Still best_val_rmse: 0.4885 (from epoch 1)\n",
      "\n",
      "8 steps took 5.22 seconds\n",
      "Epoch: 1 batch_num: 120 val_rmse: 0.4975 Still best_val_rmse: 0.4885 (from epoch 1)\n",
      "\n",
      "8 steps took 5.26 seconds\n",
      "Epoch: 1 batch_num: 128 val_rmse: 0.4904 Still best_val_rmse: 0.4885 (from epoch 1)\n",
      "\n",
      "8 steps took 5.18 seconds\n",
      "Epoch: 1 batch_num: 136 val_rmse: 0.4969 Still best_val_rmse: 0.4885 (from epoch 1)\n",
      "\n",
      "8 steps took 5.18 seconds\n",
      "Epoch: 1 batch_num: 144 val_rmse: 0.4825 New best_val_rmse: 0.4825\n",
      "\n",
      "4 steps took 3.09 seconds\n",
      "Epoch: 2 batch_num: 0 val_rmse: 0.4806 New best_val_rmse: 0.4806\n",
      "\n",
      "4 steps took 2.64 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.5012 Still best_val_rmse: 0.4806 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.485 Still best_val_rmse: 0.4806 (from epoch 2)\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4941 Still best_val_rmse: 0.4806 (from epoch 2)\n",
      "\n",
      "8 steps took 5.27 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.504 Still best_val_rmse: 0.4806 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.5214 Still best_val_rmse: 0.4806 (from epoch 2)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4779 New best_val_rmse: 0.4779\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 66 val_rmse: 0.4831 Still best_val_rmse: 0.4779 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 70 val_rmse: 0.4838 Still best_val_rmse: 0.4779 (from epoch 2)\n",
      "\n",
      "4 steps took 2.63 seconds\n",
      "Epoch: 2 batch_num: 74 val_rmse: 0.4756 New best_val_rmse: 0.4756\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4761 Still best_val_rmse: 0.4756 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 78 val_rmse: 0.4755 New best_val_rmse: 0.4755\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.4756 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 82 val_rmse: 0.4763 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4779 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 86 val_rmse: 0.4789 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.479 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 90 val_rmse: 0.4793 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4797 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 94 val_rmse: 0.4808 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "4 steps took 2.65 seconds\n",
      "Epoch: 2 batch_num: 98 val_rmse: 0.4815 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 102 val_rmse: 0.4804 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "4 steps took 2.57 seconds\n",
      "Epoch: 2 batch_num: 106 val_rmse: 0.4788 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4782 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 110 val_rmse: 0.4777 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4775 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 114 val_rmse: 0.4774 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4774 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 118 val_rmse: 0.4776 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4777 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 122 val_rmse: 0.478 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4782 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 126 val_rmse: 0.4785 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4786 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 130 val_rmse: 0.4787 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4788 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 134 val_rmse: 0.4789 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4789 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 138 val_rmse: 0.4789 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4789 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 142 val_rmse: 0.4788 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4789 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 146 val_rmse: 0.4789 Still best_val_rmse: 0.4755 (from epoch 2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 12:15:34,838]\u001b[0m Trial 11 finished with value: 0.47545260190963745 and parameters: {'base_lr': 1.8677414766053934e-05, 'last_lr': 8.112483853801161e-05}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38e5928bc434594b6cc5e1cd2f80eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.7581 New best_val_rmse: 0.7581\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.6192 New best_val_rmse: 0.6192\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6198 Still best_val_rmse: 0.6192 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.5909 New best_val_rmse: 0.5909\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.562 New best_val_rmse: 0.562\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6 Still best_val_rmse: 0.562 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6093 Still best_val_rmse: 0.562 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.617 Still best_val_rmse: 0.562 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5846 Still best_val_rmse: 0.562 (from epoch 0)\n",
      "\n",
      "16 steps took 11.1 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5122 New best_val_rmse: 0.5122\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.6334 Still best_val_rmse: 0.5122 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5679 Still best_val_rmse: 0.5122 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5635 Still best_val_rmse: 0.5122 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5579 Still best_val_rmse: 0.5122 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5266 Still best_val_rmse: 0.5122 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.49 New best_val_rmse: 0.49\n",
      "\n",
      "8 steps took 5.29 seconds\n",
      "Epoch: 1 batch_num: 116 val_rmse: 0.4957 Still best_val_rmse: 0.49 (from epoch 1)\n",
      "\n",
      "8 steps took 5.23 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5381 Still best_val_rmse: 0.49 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.4871 New best_val_rmse: 0.4871\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 1 batch_num: 144 val_rmse: 0.4809 New best_val_rmse: 0.4809\n",
      "\n",
      "4 steps took 3.04 seconds\n",
      "Epoch: 2 batch_num: 0 val_rmse: 0.4756 New best_val_rmse: 0.4756\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 2 val_rmse: 0.4748 New best_val_rmse: 0.4748\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.4762 Still best_val_rmse: 0.4748 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 6 val_rmse: 0.475 Still best_val_rmse: 0.4748 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.4731 New best_val_rmse: 0.4731\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 10 val_rmse: 0.4719 New best_val_rmse: 0.4719\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 12 val_rmse: 0.4843 Still best_val_rmse: 0.4719 (from epoch 2)\n",
      "\n",
      "4 steps took 2.59 seconds\n",
      "Epoch: 2 batch_num: 16 val_rmse: 0.4844 Still best_val_rmse: 0.4719 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.4902 Still best_val_rmse: 0.4719 (from epoch 2)\n",
      "\n",
      "8 steps took 5.22 seconds\n",
      "Epoch: 2 batch_num: 28 val_rmse: 0.501 Still best_val_rmse: 0.4719 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4783 Still best_val_rmse: 0.4719 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 46 val_rmse: 0.4678 New best_val_rmse: 0.4678\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 47 val_rmse: 0.4675 New best_val_rmse: 0.4675\n",
      "\n",
      "1 steps took 0.635 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4689 Still best_val_rmse: 0.4675 (from epoch 2)\n",
      "\n",
      "1 steps took 0.639 seconds\n",
      "Epoch: 2 batch_num: 49 val_rmse: 0.4716 Still best_val_rmse: 0.4675 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 51 val_rmse: 0.4715 Still best_val_rmse: 0.4675 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 53 val_rmse: 0.4656 New best_val_rmse: 0.4656\n",
      "\n",
      "1 steps took 0.643 seconds\n",
      "Epoch: 2 batch_num: 54 val_rmse: 0.4657 Still best_val_rmse: 0.4656 (from epoch 2)\n",
      "\n",
      "1 steps took 0.627 seconds\n",
      "Epoch: 2 batch_num: 55 val_rmse: 0.4678 Still best_val_rmse: 0.4656 (from epoch 2)\n",
      "\n",
      "1 steps took 0.648 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4696 Still best_val_rmse: 0.4656 (from epoch 2)\n",
      "\n",
      "1 steps took 0.633 seconds\n",
      "Epoch: 2 batch_num: 57 val_rmse: 0.4693 Still best_val_rmse: 0.4656 (from epoch 2)\n",
      "\n",
      "1 steps took 0.643 seconds\n",
      "Epoch: 2 batch_num: 58 val_rmse: 0.4672 Still best_val_rmse: 0.4656 (from epoch 2)\n",
      "\n",
      "1 steps took 0.628 seconds\n",
      "Epoch: 2 batch_num: 59 val_rmse: 0.4654 New best_val_rmse: 0.4654\n",
      "\n",
      "1 steps took 0.644 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4656 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.629 seconds\n",
      "Epoch: 2 batch_num: 61 val_rmse: 0.4675 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.64 seconds\n",
      "Epoch: 2 batch_num: 62 val_rmse: 0.4699 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.634 seconds\n",
      "Epoch: 2 batch_num: 63 val_rmse: 0.4706 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 65 val_rmse: 0.4698 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.633 seconds\n",
      "Epoch: 2 batch_num: 66 val_rmse: 0.4676 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.642 seconds\n",
      "Epoch: 2 batch_num: 67 val_rmse: 0.4663 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4659 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.625 seconds\n",
      "Epoch: 2 batch_num: 69 val_rmse: 0.4675 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.646 seconds\n",
      "Epoch: 2 batch_num: 70 val_rmse: 0.4701 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4745 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 74 val_rmse: 0.4772 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.32 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4762 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 78 val_rmse: 0.4719 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.4688 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.64 seconds\n",
      "Epoch: 2 batch_num: 81 val_rmse: 0.4682 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 82 val_rmse: 0.4677 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.642 seconds\n",
      "Epoch: 2 batch_num: 83 val_rmse: 0.4675 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.64 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4674 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.629 seconds\n",
      "Epoch: 2 batch_num: 85 val_rmse: 0.4673 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.631 seconds\n",
      "Epoch: 2 batch_num: 86 val_rmse: 0.4675 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.627 seconds\n",
      "Epoch: 2 batch_num: 87 val_rmse: 0.4675 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4676 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.646 seconds\n",
      "Epoch: 2 batch_num: 89 val_rmse: 0.4676 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.64 seconds\n",
      "Epoch: 2 batch_num: 90 val_rmse: 0.4679 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.633 seconds\n",
      "Epoch: 2 batch_num: 91 val_rmse: 0.4678 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.633 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4681 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.655 seconds\n",
      "Epoch: 2 batch_num: 93 val_rmse: 0.4681 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.641 seconds\n",
      "Epoch: 2 batch_num: 94 val_rmse: 0.4682 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.64 seconds\n",
      "Epoch: 2 batch_num: 95 val_rmse: 0.4678 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4676 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 97 val_rmse: 0.4672 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.648 seconds\n",
      "Epoch: 2 batch_num: 98 val_rmse: 0.4669 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.649 seconds\n",
      "Epoch: 2 batch_num: 99 val_rmse: 0.4668 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.64 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4668 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.646 seconds\n",
      "Epoch: 2 batch_num: 101 val_rmse: 0.4669 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 102 val_rmse: 0.467 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.653 seconds\n",
      "Epoch: 2 batch_num: 103 val_rmse: 0.467 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.64 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4669 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.629 seconds\n",
      "Epoch: 2 batch_num: 105 val_rmse: 0.4669 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.641 seconds\n",
      "Epoch: 2 batch_num: 106 val_rmse: 0.467 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.633 seconds\n",
      "Epoch: 2 batch_num: 107 val_rmse: 0.4672 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.645 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4676 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.64 seconds\n",
      "Epoch: 2 batch_num: 109 val_rmse: 0.4682 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 110 val_rmse: 0.4688 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 111 val_rmse: 0.4695 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4699 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 113 val_rmse: 0.4707 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 115 val_rmse: 0.4718 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 117 val_rmse: 0.4723 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 119 val_rmse: 0.472 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 121 val_rmse: 0.4718 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 123 val_rmse: 0.4712 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 125 val_rmse: 0.4707 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 127 val_rmse: 0.4702 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 129 val_rmse: 0.4697 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.628 seconds\n",
      "Epoch: 2 batch_num: 130 val_rmse: 0.4695 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 131 val_rmse: 0.4693 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4692 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.635 seconds\n",
      "Epoch: 2 batch_num: 133 val_rmse: 0.4691 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.648 seconds\n",
      "Epoch: 2 batch_num: 134 val_rmse: 0.469 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 135 val_rmse: 0.4689 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.625 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4689 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.629 seconds\n",
      "Epoch: 2 batch_num: 137 val_rmse: 0.4688 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 138 val_rmse: 0.4688 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.645 seconds\n",
      "Epoch: 2 batch_num: 139 val_rmse: 0.4688 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4687 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 141 val_rmse: 0.4687 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.645 seconds\n",
      "Epoch: 2 batch_num: 142 val_rmse: 0.4687 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.656 seconds\n",
      "Epoch: 2 batch_num: 143 val_rmse: 0.4687 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4686 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 145 val_rmse: 0.4686 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 146 val_rmse: 0.4686 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "1 steps took 0.445 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 12:38:01,556]\u001b[0m Trial 12 finished with value: 0.4653574228286743 and parameters: {'base_lr': 3.475219107014157e-05, 'last_lr': 9.010301899938123e-05}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 batch_num: 147 val_rmse: 0.4686 Still best_val_rmse: 0.4654 (from epoch 2)\n",
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610ba664dc0a4cb5a7615697f3ec7356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.001 New best_val_rmse: 1.001\n",
      "\n",
      "16 steps took 9.98 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.6704 New best_val_rmse: 0.6704\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.5915 New best_val_rmse: 0.5915\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.9807 Still best_val_rmse: 0.5915 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.019 Still best_val_rmse: 0.5915 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.281 Still best_val_rmse: 0.5915 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.051 Still best_val_rmse: 0.5915 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.015 Still best_val_rmse: 0.5915 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.7974 Still best_val_rmse: 0.5915 (from epoch 0)\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.6335 Still best_val_rmse: 0.5915 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.7435 Still best_val_rmse: 0.5915 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5546 New best_val_rmse: 0.5546\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5403 New best_val_rmse: 0.5403\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.7759 Still best_val_rmse: 0.5403 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5565 Still best_val_rmse: 0.5403 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5959 Still best_val_rmse: 0.5403 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5462 Still best_val_rmse: 0.5403 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.5145 New best_val_rmse: 0.5145\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5165 Still best_val_rmse: 0.5145 (from epoch 1)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5047 New best_val_rmse: 0.5047\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5094 Still best_val_rmse: 0.5047 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4981 New best_val_rmse: 0.4981\n",
      "\n",
      "8 steps took 5.23 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4999 Still best_val_rmse: 0.4981 (from epoch 2)\n",
      "\n",
      "8 steps took 5.22 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4957 New best_val_rmse: 0.4957\n",
      "\n",
      "8 steps took 5.2 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.4934 New best_val_rmse: 0.4934\n",
      "\n",
      "8 steps took 5.23 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4925 New best_val_rmse: 0.4925\n",
      "\n",
      "8 steps took 5.15 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.492 New best_val_rmse: 0.492\n",
      "\n",
      "8 steps took 5.12 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4977 Still best_val_rmse: 0.492 (from epoch 2)\n",
      "\n",
      "8 steps took 5.13 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4983 Still best_val_rmse: 0.492 (from epoch 2)\n",
      "\n",
      "8 steps took 5.18 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.495 Still best_val_rmse: 0.492 (from epoch 2)\n",
      "\n",
      "8 steps took 5.23 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4924 Still best_val_rmse: 0.492 (from epoch 2)\n",
      "\n",
      "8 steps took 5.23 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4914 New best_val_rmse: 0.4914\n",
      "\n",
      "8 steps took 5.19 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4911 New best_val_rmse: 0.4911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 12:48:02,919]\u001b[0m Trial 13 finished with value: 0.49111634492874146 and parameters: {'base_lr': 4.1184497044999124e-05, 'last_lr': 0.00012046859191646102}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59fd8aa23304c2faf5b3585df8a5e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.9 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.037 New best_val_rmse: 1.037\n",
      "\n",
      "16 steps took 9.77 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7393 New best_val_rmse: 0.7393\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6034 New best_val_rmse: 0.6034\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.8605 Still best_val_rmse: 0.6034 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6659 Still best_val_rmse: 0.6034 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.6046 Still best_val_rmse: 0.6034 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.5769 New best_val_rmse: 0.5769\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6442 Still best_val_rmse: 0.5769 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5661 New best_val_rmse: 0.5661\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5655 New best_val_rmse: 0.5655\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.9174 Still best_val_rmse: 0.5655 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5562 New best_val_rmse: 0.5562\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5414 New best_val_rmse: 0.5414\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.4966 New best_val_rmse: 0.4966\n",
      "\n",
      "8 steps took 5.21 seconds\n",
      "Epoch: 1 batch_num: 84 val_rmse: 0.4939 New best_val_rmse: 0.4939\n",
      "\n",
      "8 steps took 5.2 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5372 Still best_val_rmse: 0.4939 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.4807 New best_val_rmse: 0.4807\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 1 batch_num: 112 val_rmse: 0.479 New best_val_rmse: 0.479\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 1 batch_num: 114 val_rmse: 0.4871 Still best_val_rmse: 0.479 (from epoch 1)\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 1 batch_num: 118 val_rmse: 0.4787 New best_val_rmse: 0.4787\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 1 batch_num: 120 val_rmse: 0.5035 Still best_val_rmse: 0.4787 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 136 val_rmse: 0.492 Still best_val_rmse: 0.4787 (from epoch 1)\n",
      "\n",
      "8 steps took 5.2 seconds\n",
      "Epoch: 1 batch_num: 144 val_rmse: 0.4809 Still best_val_rmse: 0.4787 (from epoch 1)\n",
      "\n",
      "4 steps took 3.03 seconds\n",
      "Epoch: 2 batch_num: 0 val_rmse: 0.4865 Still best_val_rmse: 0.4787 (from epoch 1)\n",
      "\n",
      "4 steps took 2.56 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.4816 Still best_val_rmse: 0.4787 (from epoch 1)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.4781 New best_val_rmse: 0.4781\n",
      "\n",
      "2 steps took 1.26 seconds\n",
      "Epoch: 2 batch_num: 10 val_rmse: 0.4801 Still best_val_rmse: 0.4781 (from epoch 2)\n",
      "\n",
      "4 steps took 2.6 seconds\n",
      "Epoch: 2 batch_num: 14 val_rmse: 0.4849 Still best_val_rmse: 0.4781 (from epoch 2)\n",
      "\n",
      "4 steps took 2.56 seconds\n",
      "Epoch: 2 batch_num: 18 val_rmse: 0.4772 New best_val_rmse: 0.4772\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.4775 Still best_val_rmse: 0.4772 (from epoch 2)\n",
      "\n",
      "2 steps took 1.26 seconds\n",
      "Epoch: 2 batch_num: 22 val_rmse: 0.4814 Still best_val_rmse: 0.4772 (from epoch 2)\n",
      "\n",
      "4 steps took 2.56 seconds\n",
      "Epoch: 2 batch_num: 26 val_rmse: 0.4957 Still best_val_rmse: 0.4772 (from epoch 2)\n",
      "\n",
      "8 steps took 5.13 seconds\n",
      "Epoch: 2 batch_num: 34 val_rmse: 0.4834 Still best_val_rmse: 0.4772 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 38 val_rmse: 0.4786 Still best_val_rmse: 0.4772 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4723 New best_val_rmse: 0.4723\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 42 val_rmse: 0.47 New best_val_rmse: 0.47\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4712 Still best_val_rmse: 0.47 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 46 val_rmse: 0.4715 Still best_val_rmse: 0.47 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4709 Still best_val_rmse: 0.47 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 50 val_rmse: 0.4714 Still best_val_rmse: 0.47 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4701 Still best_val_rmse: 0.47 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 54 val_rmse: 0.4754 Still best_val_rmse: 0.47 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4935 Still best_val_rmse: 0.47 (from epoch 2)\n",
      "\n",
      "8 steps took 5.17 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4695 New best_val_rmse: 0.4695\n",
      "\n",
      "1 steps took 0.64 seconds\n",
      "Epoch: 2 batch_num: 65 val_rmse: 0.4682 New best_val_rmse: 0.4682\n",
      "\n",
      "1 steps took 0.639 seconds\n",
      "Epoch: 2 batch_num: 66 val_rmse: 0.4702 Still best_val_rmse: 0.4682 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4721 Still best_val_rmse: 0.4682 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 70 val_rmse: 0.4699 Still best_val_rmse: 0.4682 (from epoch 2)\n",
      "\n",
      "1 steps took 0.628 seconds\n",
      "Epoch: 2 batch_num: 71 val_rmse: 0.4681 New best_val_rmse: 0.4681\n",
      "\n",
      "1 steps took 0.628 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4675 New best_val_rmse: 0.4675\n",
      "\n",
      "1 steps took 0.621 seconds\n",
      "Epoch: 2 batch_num: 73 val_rmse: 0.4687 Still best_val_rmse: 0.4675 (from epoch 2)\n",
      "\n",
      "1 steps took 0.628 seconds\n",
      "Epoch: 2 batch_num: 74 val_rmse: 0.4712 Still best_val_rmse: 0.4675 (from epoch 2)\n",
      "\n",
      "2 steps took 1.26 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4769 Still best_val_rmse: 0.4675 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 78 val_rmse: 0.4838 Still best_val_rmse: 0.4675 (from epoch 2)\n",
      "\n",
      "4 steps took 2.54 seconds\n",
      "Epoch: 2 batch_num: 82 val_rmse: 0.4779 Still best_val_rmse: 0.4675 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4701 Still best_val_rmse: 0.4675 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 86 val_rmse: 0.4671 New best_val_rmse: 0.4671\n",
      "\n",
      "1 steps took 0.623 seconds\n",
      "Epoch: 2 batch_num: 87 val_rmse: 0.4677 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "1 steps took 0.626 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4695 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 89 val_rmse: 0.4715 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 91 val_rmse: 0.4737 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 93 val_rmse: 0.4727 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 95 val_rmse: 0.4697 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "1 steps took 0.63 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4678 Still best_val_rmse: 0.4671 (from epoch 2)\n",
      "\n",
      "1 steps took 0.63 seconds\n",
      "Epoch: 2 batch_num: 97 val_rmse: 0.4667 New best_val_rmse: 0.4667\n",
      "\n",
      "1 steps took 0.635 seconds\n",
      "Epoch: 2 batch_num: 98 val_rmse: 0.4664 New best_val_rmse: 0.4664\n",
      "\n",
      "1 steps took 0.634 seconds\n",
      "Epoch: 2 batch_num: 99 val_rmse: 0.4664 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.631 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4669 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.641 seconds\n",
      "Epoch: 2 batch_num: 101 val_rmse: 0.4679 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.639 seconds\n",
      "Epoch: 2 batch_num: 102 val_rmse: 0.4691 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.624 seconds\n",
      "Epoch: 2 batch_num: 103 val_rmse: 0.4697 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.62 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4699 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.634 seconds\n",
      "Epoch: 2 batch_num: 105 val_rmse: 0.4697 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.638 seconds\n",
      "Epoch: 2 batch_num: 106 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 107 val_rmse: 0.469 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.639 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4685 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.625 seconds\n",
      "Epoch: 2 batch_num: 109 val_rmse: 0.4683 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.623 seconds\n",
      "Epoch: 2 batch_num: 110 val_rmse: 0.4681 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 111 val_rmse: 0.4681 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.628 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4682 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.627 seconds\n",
      "Epoch: 2 batch_num: 113 val_rmse: 0.4683 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.623 seconds\n",
      "Epoch: 2 batch_num: 114 val_rmse: 0.4686 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.642 seconds\n",
      "Epoch: 2 batch_num: 115 val_rmse: 0.4689 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.629 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4691 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.648 seconds\n",
      "Epoch: 2 batch_num: 117 val_rmse: 0.4692 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.628 seconds\n",
      "Epoch: 2 batch_num: 118 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.633 seconds\n",
      "Epoch: 2 batch_num: 119 val_rmse: 0.4694 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4695 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.644 seconds\n",
      "Epoch: 2 batch_num: 121 val_rmse: 0.4695 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.625 seconds\n",
      "Epoch: 2 batch_num: 122 val_rmse: 0.4694 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.636 seconds\n",
      "Epoch: 2 batch_num: 123 val_rmse: 0.4694 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.628 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 125 val_rmse: 0.4694 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.623 seconds\n",
      "Epoch: 2 batch_num: 126 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.629 seconds\n",
      "Epoch: 2 batch_num: 127 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.639 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.644 seconds\n",
      "Epoch: 2 batch_num: 129 val_rmse: 0.4694 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.626 seconds\n",
      "Epoch: 2 batch_num: 130 val_rmse: 0.4695 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.625 seconds\n",
      "Epoch: 2 batch_num: 131 val_rmse: 0.4695 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.629 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4694 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 133 val_rmse: 0.4694 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.637 seconds\n",
      "Epoch: 2 batch_num: 134 val_rmse: 0.4694 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.629 seconds\n",
      "Epoch: 2 batch_num: 135 val_rmse: 0.4694 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.627 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.628 seconds\n",
      "Epoch: 2 batch_num: 137 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.63 seconds\n",
      "Epoch: 2 batch_num: 138 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.632 seconds\n",
      "Epoch: 2 batch_num: 139 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.623 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.63 seconds\n",
      "Epoch: 2 batch_num: 141 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.634 seconds\n",
      "Epoch: 2 batch_num: 142 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.63 seconds\n",
      "Epoch: 2 batch_num: 143 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.622 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.622 seconds\n",
      "Epoch: 2 batch_num: 145 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.621 seconds\n",
      "Epoch: 2 batch_num: 146 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "1 steps took 0.448 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:10:08,244]\u001b[0m Trial 14 finished with value: 0.4663567543029785 and parameters: {'base_lr': 2.3466777487829995e-05, 'last_lr': 0.0003372539806389599}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 batch_num: 147 val_rmse: 0.4693 Still best_val_rmse: 0.4664 (from epoch 2)\n",
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4a37120685438caed9e71fe6c83e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.8 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9224 New best_val_rmse: 0.9224\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7665 New best_val_rmse: 0.7665\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6246 New best_val_rmse: 0.6246\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6257 Still best_val_rmse: 0.6246 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.7237 Still best_val_rmse: 0.6246 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.5543 New best_val_rmse: 0.5543\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.5695 Still best_val_rmse: 0.5543 (from epoch 0)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6019 Still best_val_rmse: 0.5543 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5081 New best_val_rmse: 0.5081\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.531 Still best_val_rmse: 0.5081 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.5418 Still best_val_rmse: 0.5081 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5083 Still best_val_rmse: 0.5081 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5173 Still best_val_rmse: 0.5081 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.4901 New best_val_rmse: 0.4901\n",
      "\n",
      "8 steps took 5.2 seconds\n",
      "Epoch: 1 batch_num: 84 val_rmse: 0.4949 Still best_val_rmse: 0.4901 (from epoch 1)\n",
      "\n",
      "8 steps took 5.25 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.523 Still best_val_rmse: 0.4901 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.4941 Still best_val_rmse: 0.4901 (from epoch 1)\n",
      "\n",
      "8 steps took 5.14 seconds\n",
      "Epoch: 1 batch_num: 116 val_rmse: 0.4839 New best_val_rmse: 0.4839\n",
      "\n",
      "4 steps took 2.6 seconds\n",
      "Epoch: 1 batch_num: 120 val_rmse: 0.4952 Still best_val_rmse: 0.4839 (from epoch 1)\n",
      "\n",
      "8 steps took 5.24 seconds\n",
      "Epoch: 1 batch_num: 128 val_rmse: 0.4946 Still best_val_rmse: 0.4839 (from epoch 1)\n",
      "\n",
      "8 steps took 5.14 seconds\n",
      "Epoch: 1 batch_num: 136 val_rmse: 0.4931 Still best_val_rmse: 0.4839 (from epoch 1)\n",
      "\n",
      "8 steps took 5.23 seconds\n",
      "Epoch: 1 batch_num: 144 val_rmse: 0.4872 Still best_val_rmse: 0.4839 (from epoch 1)\n",
      "\n",
      "4 steps took 3.12 seconds\n",
      "Epoch: 2 batch_num: 0 val_rmse: 0.4889 Still best_val_rmse: 0.4839 (from epoch 1)\n",
      "\n",
      "4 steps took 2.63 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.4796 New best_val_rmse: 0.4796\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 6 val_rmse: 0.4895 Still best_val_rmse: 0.4796 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 10 val_rmse: 0.4827 Still best_val_rmse: 0.4796 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 14 val_rmse: 0.4833 Still best_val_rmse: 0.4796 (from epoch 2)\n",
      "\n",
      "4 steps took 2.56 seconds\n",
      "Epoch: 2 batch_num: 18 val_rmse: 0.4887 Still best_val_rmse: 0.4796 (from epoch 2)\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 2 batch_num: 22 val_rmse: 0.4936 Still best_val_rmse: 0.4796 (from epoch 2)\n",
      "\n",
      "8 steps took 5.15 seconds\n",
      "Epoch: 2 batch_num: 30 val_rmse: 0.5305 Still best_val_rmse: 0.4796 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 46 val_rmse: 0.5213 Still best_val_rmse: 0.4796 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 62 val_rmse: 0.4809 Still best_val_rmse: 0.4796 (from epoch 2)\n",
      "\n",
      "4 steps took 2.6 seconds\n",
      "Epoch: 2 batch_num: 66 val_rmse: 0.4782 New best_val_rmse: 0.4782\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.485 Still best_val_rmse: 0.4782 (from epoch 2)\n",
      "\n",
      "4 steps took 2.62 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4811 Still best_val_rmse: 0.4782 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4737 New best_val_rmse: 0.4737\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 78 val_rmse: 0.4739 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.32 seconds\n",
      "Epoch: 2 batch_num: 80 val_rmse: 0.474 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 82 val_rmse: 0.4743 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4751 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 86 val_rmse: 0.4751 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4748 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 90 val_rmse: 0.4751 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4752 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 94 val_rmse: 0.4763 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4771 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 98 val_rmse: 0.4781 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4785 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 102 val_rmse: 0.478 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4775 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 106 val_rmse: 0.4768 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 108 val_rmse: 0.4762 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 110 val_rmse: 0.476 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4761 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 114 val_rmse: 0.4762 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 116 val_rmse: 0.4763 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 118 val_rmse: 0.4765 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4767 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 122 val_rmse: 0.477 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4773 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 126 val_rmse: 0.4776 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.28 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4778 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 130 val_rmse: 0.4779 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.31 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.4779 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 134 val_rmse: 0.478 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4779 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 138 val_rmse: 0.4779 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.27 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4779 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 142 val_rmse: 0.4779 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.3 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4779 Still best_val_rmse: 0.4737 (from epoch 2)\n",
      "\n",
      "2 steps took 1.29 seconds\n",
      "Epoch: 2 batch_num: 146 val_rmse: 0.4779 Still best_val_rmse: 0.4737 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:25:45,551]\u001b[0m Trial 15 finished with value: 0.47370725870132446 and parameters: {'base_lr': 9.710180232439892e-06, 'last_lr': 0.00014711880438815592}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4c4772ac624d7e90b2a585d0882c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.5 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.6608 New best_val_rmse: 0.6608\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.071 Still best_val_rmse: 0.6608 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7146 Still best_val_rmse: 0.6608 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.8363 Still best_val_rmse: 0.6608 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.476 Still best_val_rmse: 0.6608 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.016 Still best_val_rmse: 0.6608 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.101 Still best_val_rmse: 0.6608 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.017 Still best_val_rmse: 0.6608 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.008 Still best_val_rmse: 0.6608 (from epoch 0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:29:00,687]\u001b[0m Trial 16 finished with value: 0.6608344912528992 and parameters: {'base_lr': 9.927962549018632e-05, 'last_lr': 0.00027107786810968537}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404e14ce163e4f1db42127bc6ed7070e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9054 New best_val_rmse: 0.9054\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.6363 New best_val_rmse: 0.6363\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.065 Still best_val_rmse: 0.6363 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 1.008 Still best_val_rmse: 0.6363 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 1.048 Still best_val_rmse: 0.6363 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 1.024 Still best_val_rmse: 0.6363 (from epoch 0)\n",
      "\n",
      "16 steps took 10.1 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 1.017 Still best_val_rmse: 0.6363 (from epoch 0)\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 1.012 Still best_val_rmse: 0.6363 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 1.015 Still best_val_rmse: 0.6363 (from epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:32:15,723]\u001b[0m Trial 17 finished with value: 0.6363370418548584 and parameters: {'base_lr': 6.791879903120003e-05, 'last_lr': 8.101574591234945e-05}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d244a35b3e1b4eeb9fc2fe67720313a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.4 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.213 New best_val_rmse: 1.213\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7203 New best_val_rmse: 0.7203\n",
      "\n",
      "16 steps took 10.2 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.7696 Still best_val_rmse: 0.7203 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7822 Still best_val_rmse: 0.7203 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.587 New best_val_rmse: 0.587\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.5701 New best_val_rmse: 0.5701\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6693 Still best_val_rmse: 0.5701 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.5386 New best_val_rmse: 0.5386\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.6401 Still best_val_rmse: 0.5386 (from epoch 0)\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5437 Still best_val_rmse: 0.5386 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.7161 Still best_val_rmse: 0.5386 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.5197 New best_val_rmse: 0.5197\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5225 Still best_val_rmse: 0.5197 (from epoch 1)\n",
      "\n",
      "16 steps took 10.6 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5332 Still best_val_rmse: 0.5197 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.5069 New best_val_rmse: 0.5069\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5114 Still best_val_rmse: 0.5069 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.5387 Still best_val_rmse: 0.5069 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.4955 New best_val_rmse: 0.4955\n",
      "\n",
      "8 steps took 5.77 seconds\n",
      "Epoch: 2 batch_num: 0 val_rmse: 0.4851 New best_val_rmse: 0.4851\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 4 val_rmse: 0.4893 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.6 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.4967 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "8 steps took 5.24 seconds\n",
      "Epoch: 2 batch_num: 16 val_rmse: 0.5004 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.4875 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.4976 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "8 steps took 5.25 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4859 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.59 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4866 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.56 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4928 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "8 steps took 5.2 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4933 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "8 steps took 5.22 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4913 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "8 steps took 5.23 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.491 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "8 steps took 5.16 seconds\n",
      "Epoch: 2 batch_num: 84 val_rmse: 0.4869 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.4866 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 92 val_rmse: 0.4864 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.61 seconds\n",
      "Epoch: 2 batch_num: 96 val_rmse: 0.4861 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.56 seconds\n",
      "Epoch: 2 batch_num: 100 val_rmse: 0.4894 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.64 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.4926 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "8 steps took 5.14 seconds\n",
      "Epoch: 2 batch_num: 112 val_rmse: 0.4921 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "8 steps took 5.14 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.4884 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 124 val_rmse: 0.4875 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 128 val_rmse: 0.4872 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.55 seconds\n",
      "Epoch: 2 batch_num: 132 val_rmse: 0.487 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.56 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.4868 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.56 seconds\n",
      "Epoch: 2 batch_num: 140 val_rmse: 0.4867 Still best_val_rmse: 0.4851 (from epoch 2)\n",
      "\n",
      "4 steps took 2.58 seconds\n",
      "Epoch: 2 batch_num: 144 val_rmse: 0.4867 Still best_val_rmse: 0.4851 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:43:53,070]\u001b[0m Trial 18 finished with value: 0.48513227701187134 and parameters: {'base_lr': 1.6005986598016256e-05, 'last_lr': 0.00036490724142937235}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Using fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cd6c9d06f7478cb5fcd95a0572e69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.3 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.956 New best_val_rmse: 0.956\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 1.009 Still best_val_rmse: 0.956 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 1.061 Still best_val_rmse: 0.956 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.876 New best_val_rmse: 0.876\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.7 New best_val_rmse: 0.7\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 0.7432 Still best_val_rmse: 0.7 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 112 val_rmse: 0.6748 New best_val_rmse: 0.6748\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 0.6787 Still best_val_rmse: 0.6748 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 0 batch_num: 144 val_rmse: 0.5244 New best_val_rmse: 0.5244\n",
      "\n",
      "16 steps took 11.0 seconds\n",
      "Epoch: 1 batch_num: 12 val_rmse: 0.5746 Still best_val_rmse: 0.5244 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 28 val_rmse: 0.7551 Still best_val_rmse: 0.5244 (from epoch 0)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 44 val_rmse: 0.6225 Still best_val_rmse: 0.5244 (from epoch 0)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 1 batch_num: 60 val_rmse: 0.5097 New best_val_rmse: 0.5097\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 76 val_rmse: 0.5079 New best_val_rmse: 0.5079\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 92 val_rmse: 0.6291 Still best_val_rmse: 0.5079 (from epoch 1)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 1 batch_num: 108 val_rmse: 0.5445 Still best_val_rmse: 0.5079 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 124 val_rmse: 0.6641 Still best_val_rmse: 0.5079 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 1 batch_num: 140 val_rmse: 0.549 Still best_val_rmse: 0.5079 (from epoch 1)\n",
      "\n",
      "16 steps took 10.9 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.5112 Still best_val_rmse: 0.5079 (from epoch 1)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.5068 New best_val_rmse: 0.5068\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.5178 Still best_val_rmse: 0.5068 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.5196 Still best_val_rmse: 0.5068 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.5144 Still best_val_rmse: 0.5068 (from epoch 2)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 2 batch_num: 88 val_rmse: 0.5009 New best_val_rmse: 0.5009\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 104 val_rmse: 0.507 Still best_val_rmse: 0.5009 (from epoch 2)\n",
      "\n",
      "16 steps took 10.4 seconds\n",
      "Epoch: 2 batch_num: 120 val_rmse: 0.5033 Still best_val_rmse: 0.5009 (from epoch 2)\n",
      "\n",
      "16 steps took 10.3 seconds\n",
      "Epoch: 2 batch_num: 136 val_rmse: 0.5011 Still best_val_rmse: 0.5009 (from epoch 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:53:00,176]\u001b[0m Trial 19 finished with value: 0.5008856058120728 and parameters: {'base_lr': 3.241166689201171e-05, 'last_lr': 0.0014840194444766435}. Best is trial 4 with value: 0.4619826078414917.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:53:00,179]\u001b[0m A new study created in memory with name: no-name-3500d17d-d3f4-4fdb-8bb5-cf1dde7da241\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best value:  0.4619826078414917\n",
      " Best params: \n",
      "    base_lr: 4.632686837727199e-05\n",
      "    last_lr: 0.00026414650413977917\n",
      "##### Using fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b43394570f14967b03b4f88652253c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 11.7 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.135 New best_val_rmse: 1.135\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7497 New best_val_rmse: 0.7497\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6417 New best_val_rmse: 0.6417\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7204 Still best_val_rmse: 0.6417 (from epoch 0)\n",
      "\n",
      "16 steps took 10.5 seconds\n",
      "Epoch: 0 batch_num: 80 val_rmse: 0.6216 New best_val_rmse: 0.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4502da8940>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1297, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    399\u001b[0m             )\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-22ac78aeb8c7>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mrmse_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-696fe3be0c5a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Casts operations to mixed precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-f321fc89f4a5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlast_layer_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_hidden_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_layer_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlast_layer_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         )\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             output_states = layer_module(\n\u001b[0m\u001b[1;32m    460\u001b[0m                 \u001b[0mnext_kv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, return_att, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     ):\n\u001b[0;32m--> 321\u001b[0;31m         attention_output = self.attention(\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, return_att, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     ):\n\u001b[0;32m--> 252\u001b[0;31m         self_output = self.self(\n\u001b[0m\u001b[1;32m    253\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, return_att, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m             rel_att = self.disentangled_attention_bias(\n\u001b[0m\u001b[1;32m    661\u001b[0m                 \u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mdisentangled_attention_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0matt_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ebd_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0mrelative_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ebd_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0matt_span\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ebd_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0matt_span\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(0, len(list(splits))):\n",
    "    fold = i\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    print(\" Best value: \", study.best_trial.value)\n",
    "    print(\" Best params: \")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a69a20-e7bd-4426-8394-9fe92ff4ceba",
   "metadata": {},
   "source": [
    "### Verify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1d2f26d-f0bc-4d35-b970-a18b100c97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "820cfbb0-36c6-41e7-b98e-d5ecc379c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model_offset = 0\n",
    "cfg.model_limit = 6\n",
    "cfg.n_folds = 5\n",
    "cfg.svm_kernels = ['rbf']\n",
    "cfg.svm_c = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34fe3330-3d2c-49c5-be98-69a13cf2a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = int(np.ceil(np.log2(len(train_df))))\n",
    "train_df['bins'] = pd.cut(train_df['target'], bins=num_bins, labels=False)\n",
    "bins = train_df['bins'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508c0ef-984f-4af5-a283-88498c1dcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "inference_models = []\n",
    "for i in range(1, cfg.NUM_FOLDS + 1):\n",
    "    print(f'Model {i}')\n",
    "    inference_model = CommonLitModel()\n",
    "    inference_model = inference_model.cuda()\n",
    "    inference_model.load_state_dict(torch.load(str(MODELS_PATH/f\"{cfg.model_name.replace('/', '_')}_{i}/model_{i}.pth\")))\n",
    "    inference_model.eval();\n",
    "    inference_models.append(inference_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a6b85-3e21-44c5-bbe1-347c12d4c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizers = []\n",
    "for i in range(1, cfg.NUM_FOLDS):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(MODELS_PATH/f\"{cfg.model_name.replace('/', '_')}_{i}\")\n",
    "    tokenizers.append(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6479666-2703-4691-831c-6a1a493924b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_embeddings(dl, transformer_model):\n",
    "    cls_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for input_features in tqdm(dl, total=len(dl)):\n",
    "            output, context_vector = transformer_model(input_features['input_ids'].cuda(), input_features['attention_mask'].cuda())\n",
    "#             cls_embeddings.extend(output['last_hidden_state'][:,0,:].detach().cpu().numpy())\n",
    "            embedding_out = context_vector.detach().cpu().numpy()\n",
    "            cls_embeddings.extend(embedding_out)\n",
    "    return np.array(cls_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0cd48-b89a-4be9-b3f8-75f79133292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_score(X, y):\n",
    "    return np.sqrt(mean_squared_error(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29dc0cb-b3d7-448c-8166-0716b76860c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(t):\n",
    "    return t.flatten().long()\n",
    "\n",
    "class CommonLitDataset(nn.Module):\n",
    "    def __init__(self, text, test_id, tokenizer, max_len=128):\n",
    "        self.excerpt = text\n",
    "        self.test_id = test_id\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],\n",
    "                                return_tensors='pt',\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length',\n",
    "                                truncation=True)\n",
    "        return {'input_ids': convert_to_list(encode['input_ids']),\n",
    "                'attention_mask': convert_to_list(encode['attention_mask']),\n",
    "                'id': self.test_id[idx]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69fc14c-d0c9-486c-b15c-1aa2d81ad424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dl(df, tokenizer):\n",
    "    text = df['excerpt'].values\n",
    "    ids = df['id'].values\n",
    "    ds = CommonLitDataset(text, ids, tokenizer, max_len=cfg.MAX_LEN)\n",
    "    return DataLoader(ds, \n",
    "                      batch_size = cfg.BATCH_SIZE,\n",
    "                      shuffle=False,\n",
    "                      num_workers = 1,\n",
    "                      pin_memory=True,\n",
    "                      drop_last=False\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7052da7-31ff-4863-a4bf-ff6bb5829873",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH/'train-orig.csv')\n",
    "test_df = pd.read_csv(DATA_PATH/'test.csv')\n",
    "remove_unnecessary(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f88ec-0471-4d1a-8270-f610141382b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_mean = train_df['target'].mean()\n",
    "train_target_std = train_df['target'].std()\n",
    "train_df['normalized_target'] = (train_df['target'] - train_target_mean) / train_target_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb532e-9f76-406b-ba60-c8991851faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_target = train_df['normalized_target'].values\n",
    "\n",
    "def calc_mean(scores):\n",
    "    return np.mean(np.array(scores), axis=0)\n",
    "\n",
    "final_scores = []\n",
    "final_rmse = []\n",
    "kernel_rmse_score_mean = []\n",
    "final_kernel_predictions_means = []\n",
    "for j, (inference_model, tokenizer) in enumerate(zip(inference_models, tokenizers)):\n",
    "    print('Model', j)\n",
    "    test_dl = create_dl(test_df, tokenizer)\n",
    "    train_dl = create_dl(train_df, tokenizer)\n",
    "    transformer_model = inference_model\n",
    "    transformer_model.cuda()\n",
    "    X = get_cls_embeddings(train_dl, transformer_model)\n",
    "    \n",
    "    y = train_target\n",
    "    X_test = get_cls_embeddings(test_dl, transformer_model)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=cfg.NUM_FOLDS)\n",
    "    scores = []\n",
    "    rmse_scores = []\n",
    "    kernel_predictions_means = []\n",
    "    for kernel in cfg.svm_kernels:\n",
    "        print('Kernel', kernel)\n",
    "        kernel_scores = []\n",
    "        kernel_rmse_scores = []\n",
    "        kernel_predictions = []\n",
    "        for k, (train_idx, valid_idx) in enumerate(kfold.split(X, bins)):\n",
    "\n",
    "            print('Fold', k, train_idx.shape, valid_idx.shape)\n",
    "            model = SVR(C=cfg.svm_c, kernel=kernel, gamma='auto')\n",
    "\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            prediction = model.predict(X_valid)\n",
    "            kernel_predictions.append(prediction)\n",
    "            kernel_rmse_scores.append(rmse_score(prediction, y_valid))\n",
    "            print('rmse_score', kernel_rmse_scores[k])\n",
    "            kernel_scores.append(model.predict(X_test))\n",
    "        kernel_predictions_means.append(np.array([np.mean(kp) for kp in kernel_predictions]).mean())\n",
    "        scores.append(calc_mean(kernel_scores))\n",
    "        kernel_rmse_score = calc_mean(kernel_rmse_scores)\n",
    "        kernel_rmse_score_mean.append(kernel_rmse_score)\n",
    "        rmse_scores.append(kernel_rmse_score)\n",
    "    final_kernel_predictions_means.append(kernel_predictions_means)\n",
    "    final_scores.append(calc_mean(scores))\n",
    "    final_rmse.append(calc_mean(rmse_scores))\n",
    "print('FINAL RMSE score', np.mean(np.array(final_rmse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ac2d7-605a-4cc7-8bd0-8eec0ec6f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_kernel_predictions_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b649aa-784d-4dbf-83e4-252ca3f2bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_df['target'] - cfg.train_target_mean) / cfg.train_target_std\n",
    "final_scores_normalized = np.array(final_scores) * train_target_std + train_target_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd46e8-1542-4a71-82ca-d6d4838d7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_rmse_score_mean_array = np.array(kernel_rmse_score_mean)\n",
    "kernel_rmse_score_mean_sum = np.sum(kernel_rmse_score_mean_array)\n",
    "prop_losses = kernel_rmse_score_mean_array / kernel_rmse_score_mean_sum\n",
    "prop_losses_sum = (1 - prop_losses).sum()\n",
    "weights = (1 - prop_losses) / prop_losses_sum\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b9381-2a90-4183-b305-59f6d233017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(scores, weights=weights):\n",
    "    return np.average(np.array(scores), weights=weights, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c0f5a2-7e63-4799-ad55-1a733b24a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mean = train_df['target'].mean()\n",
    "final_scores_flat = calc_mean(final_scores_normalized).flatten()\n",
    "final_scores_mean = final_scores_flat.mean()\n",
    "target_mean, np.array(final_scores_normalized).mean()\n",
    "# (-0.9579984513405823, -0.8029817438292849)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a4669-2c5d-49e6-8dec-f9abb9cd8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4614a6c5-af82-4b2c-bf5a-f1180109426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = target_mean - final_scores_mean\n",
    "mean_diff, mean_diff / len(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd92a7-a55f-422a-bfae-7f475bd5f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['target'] = final_scores_flat + mean_diff\n",
    "# sample_df['target'] = len(final_scores) / np.sum(1 / np.array(final_scores), axis=0) # harmonic mean\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c995ca-ff1f-4b43-a41c-28d6ec11fa97",
   "metadata": {},
   "source": [
    "### Prepare Packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c5d5b-b293-4d59-b2e7-53131745079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993d2b0-3c68-4241-b15d-c51e10ee788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_FOLDER = MODELS_PATH/cfg.model_name/'best'\n",
    "!rm -rf {BEST_MODEL_FOLDER}\n",
    "!mkdir -p {BEST_MODEL_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3faa7c-7b90-4fe2-aebf-cf9733a3674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44851d5-e456-4abd-972c-0838dd792714",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.NUM_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30572a-121f-4432-a83d-f49c6fa5e815",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodels = [MODELS_PATH/f'{cfg.model_name}_{i + 1}' for i in range(0, cfg.NUM_FOLDS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cf4b3-862c-4676-bc1d-875cd32ce7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f114e7-7e75-43d8-8c4c-6889f6393b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "def normalize_name(path_name):\n",
    "    return path_name.replace('', '')\n",
    "\n",
    "for i, best_model in enumerate(bestmodels):\n",
    "    print(f'Processing {i}th model')\n",
    "    i = i + 1\n",
    "    best_model_file = f'{best_model}/model_{i}.pth'\n",
    "    if Path(best_model_file).exists():\n",
    "        copyfile(best_model_file, f'{BEST_MODEL_FOLDER}/{i}_pytorch_model.bin')\n",
    "        tokenizer_path = Path(BEST_MODEL_FOLDER/f'tokenizer-{i}')\n",
    "        tokenizer_path.mkdir(parents=True, exist_ok=True)\n",
    "        assert tokenizer_path.exists()\n",
    "\n",
    "        tokenizer_json = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}_{i}/tokenizer_config.json'))\n",
    "        assert tokenizer_json.exists(), f'{tokenizer_json} does not exist'\n",
    "        copyfile(tokenizer_json, tokenizer_path/'tokenizer.json')\n",
    "\n",
    "        vocab_txt = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}_{i}/vocab.json'))\n",
    "        assert vocab_txt.exists(), f'{vocab_txt} does not exist'\n",
    "        copyfile(vocab_txt, tokenizer_path/'vocab.json')\n",
    "\n",
    "        merges = Path(normalize_name(f'{MODELS_PATH/cfg.model_name}_{i}/merges.txt'))\n",
    "        assert merges.exists()\n",
    "        copyfile(merges, tokenizer_path/'merges.txt')\n",
    "    else:\n",
    "        print(f'{best_model_file} is missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc422f71-d671-4eca-82f4-0dd059b1200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(MODELS_PATH/cfg.model_name/'best_models', 'zip', BEST_MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d2659-6041-47d9-ba4c-a8ecade644a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf7473-d8fd-4ff4-8b51-67028bc5d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv {MODELS_PATH}/{cfg.model_name}.yaml {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bdcbd8-bed2-4ac9-91a0-93b35b0d2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model.transformer_model.save_pretrained(save_directory=f'{MODELS_PATH/cfg.model_name}/lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5088d-df35-4b54-8de6-9c8a3bdc5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h {MODELS_PATH/cfg.model_name}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a2e2d-e325-4b5f-ab68-71b1cc9d3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(MODELS_PATH/cfg.model_name/'lm', 'zip', f'{MODELS_PATH/cfg.model_name}/lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616c042-2877-470a-b227-948606188b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets init -p {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6984b-07d9-49e6-89b2-6066503bda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json_path = Path(MODELS_PATH/cfg.model_name/'dataset-metadata.json')\n",
    "assert dataset_json_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa049c-faa9-45da-af4f-554a2000f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {str(dataset_json_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf108e8-c48c-4134-809b-6c775ef5b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_json_path, 'r') as f:\n",
    "    dataset_json = f.read()\n",
    "    dataset_json = dataset_json.replace('INSERT_TITLE_HERE', f'commonlit-{cfg.model_name}-light').replace('INSERT_SLUG_HERE', f'commonlit-{cfg.model_name}-light')\n",
    "    print(dataset_json)\n",
    "with(open(dataset_json_path, 'w')) as f:\n",
    "    f.write(dataset_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9877c0cb-0d80-43d6-a064-f929ad92b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {MODELS_PATH/cfg.model_name}/best\n",
    "!rm -rf {MODELS_PATH/cfg.model_name}/lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851185dc-f532-4920-bfc0-39f36f0224bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets create -p {MODELS_PATH/cfg.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19f40a-df46-4f1d-b247-c627e7cf091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets version -p {MODELS_PATH/cfg.model_name} -m \"Version with merges.txt\" -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffe0ba-8412-4616-a0a4-78c0b4552f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(str(MODELS_PATH/f'distilroberta-0/checkpoint-105/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e77de-3b71-408f-8d6c-25bae3e60f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = CommonLitModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de19b9-2d6b-41c1-a765-5c39551fe176",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859231b7-d595-463e-8ab7-1ac150193306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
